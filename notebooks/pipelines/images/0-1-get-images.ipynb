{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:04.720425100Z",
     "start_time": "2023-06-10T17:12:00.684745Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "display(\"==== Starting 0-1 Image Acquisition ====\")\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw.models import ListingGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.captioning.caption import BlipCaption\n",
    "from common.schemas.pyarrow_schema import schema\n",
    "from common.storage.azure_file_storage import AzureFileStorageAdapter\n",
    "from common.functions.functions import Functions\n",
    "\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "file_system = AzureFileStorageAdapter('data').get_file_storage()\n",
    "\n",
    "functions: Functions = Functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:04.759425600Z",
     "start_time": "2023-06-10T17:12:04.718422500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# \"memes\",\"CityPorn\", \"EarthPorn\", \"spaceporn\",\t\"itookapicture\", \"trippinthroughtime\"\n",
    "subs = [\n",
    "\t\"SFWRedheads\",\n",
    "\t\"sfwpetite\",\n",
    "\t\"SFWNextDoorGirls\",\n",
    "\t\"fatsquirrelhate\",\n",
    "\t\"realasians\",\n",
    "\t\"KoreanHotties\",\n",
    "\t\"prettyasiangirls\",\n",
    "\t\"AsianOfficeLady\",\n",
    "\t\"mildlypenis\",\n",
    "\t\"AsianInvasion\",\n",
    "\t\"sexygirls\",\n",
    "\t\"PrettyGirls\",\n",
    "\t\"gentlemanboners\",\n",
    "\t\"hotofficegirls\",\n",
    "\t\"tightdresses\",\n",
    "\t\"DLAH\",\n",
    "\t\"bathandbodyworks\",\n",
    "\t\"AesPleasingAsianGirls\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:04.773429500Z",
     "start_time": "2023-06-10T17:12:04.732424900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sources = [\n",
    "\t{\"name\": \"CityDiffusion\", \"data\": [\"CityPorn\"]},\n",
    "\t{\"name\": \"NatureDiffusion\", \"data\": [\"EarthPorn\"]},\n",
    "\t{\"name\": \"CosmicDiffusion\", \"data\": [\"spaceporn\"]},\n",
    "\t{\"name\": \"ITAPDiffusion\", \"data\": [\"itookapicture\"]},\n",
    "\t{\"name\": \"MemeDiffusion\", \"data\": [\"memes\"]},\n",
    "\t{\"name\": \"TTTDiffusion\", \"data\": [\"trippinthroughtime\"]},\n",
    "\t{\"name\": \"WallStreetDiffusion\", \"data\": [\"wallstreetbets\"]},\n",
    "\t{\"name\": \"SexyDiffusion\", \"data\": [\"selfies\", \"Amicute\", \"amihot\", \"AmIhotAF\", \"HotGirlNextDoor\"]},\n",
    "\t{\"name\": \"FatSquirrelDiffusion\", \"data\": [\"fatsquirrelhate\"]},\n",
    "\t{\"name\": \"CelebrityDiffusion\", \"data\": [\"celebrities\"]},\n",
    "\t{\"name\": \"OldLadyDiffusion\", \"data\": [\"oldladiesbakingpies\"]},\n",
    "\t{\"name\": \"SWFPetite\", \"data\": [\"sfwpetite\"]},\n",
    "\t{\"name\": \"SFWMilfs\", \"data\": [\"cougars_and_milfs_sfw\"]},\n",
    "\t{\"name\": \"RedHeadDiffusion\", \"data\": [\"SFWRedheads\"]},\n",
    "\t{\"name\": \"NextDoorGirlsDiffusion\", \"data\": [\"SFWNextDoorGirls\"]},\n",
    "\t{\"name\": \"SexyAsianDiffusion\",\"data\": [\"realasians\", \"KoreanHotties\", \"prettyasiangirls\", \"AsianOfficeLady\", \"AsianInvasion\",\"AesPleasingAsianGirls\"]},\n",
    "\t{\"name\": \"MildlyPenisDiffusion\", \"data\": [\"mildlypenis\"]},\n",
    "\t{\"name\": \"PrettyGirlDiffusion\",\"data\": [\"sexygirls\", \"PrettyGirls\", \"gentlemanboners\" \"hotofficegirls\", \"tightdresses\", \"DLAH\"]},{\"name\": \"CandleDiffusion\", \"data\": [\"bathandbodyworks\"]}\n",
    "]\n",
    "sources_df = pd.DataFrame.from_records(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:05.738856Z",
     "start_time": "2023-06-10T17:12:04.764424900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "extant_data = pandas.read_parquet(\"data/processed_raw_data.parquet\", engine='pyarrow', filesystem=file_system,\n",
    "\t\t\t\t\t\t\t\t  schema=schema)\n",
    "extant_data.set_index('id', inplace=True)\n",
    "display(extant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:06.545595700Z",
     "start_time": "2023-06-10T17:12:05.741859900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "curated_data = pandas.read_parquet(\"data/parquet/primary_caption.parquet\", engine='pyarrow', filesystem=file_system, schema=schema)\n",
    "curated_data.set_index('id', inplace=True)\n",
    "\n",
    "display(\"==== CURATED DATA ====\")\n",
    "display(curated_data.shape)\n",
    "display(curated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:09.791728100Z",
     "start_time": "2023-06-10T17:12:06.496599600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "extant_data.update(curated_data)\n",
    "extant_data.drop_duplicates(subset=['id'], inplace=True, keep='last')\n",
    "updated_extant_data = extant_data.reset_index()\n",
    "\n",
    "display(\"==== UPDATED EXTANT DATA ====\")\n",
    "display(updated_extant_data.shape)\n",
    "display(updated_extant_data)\n",
    "updated_extant_data.to_parquet(\"data/processed_raw_data.parquet\", engine='pyarrow', filesystem=file_system, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:09.904256500Z",
     "start_time": "2023-06-10T17:12:09.761726100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "reddit: praw.Reddit = praw.Reddit(client_id='5hVavL0PIRyM_1JSvqT6UQ', client_secret='BjD2kS3WNLnJc59RKY-JJUuc_Z9-JA', user_agent='script:%(bot_name)s:v%(bot_version)s (by /u/%(bot_author)s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:12:09.984271Z",
     "start_time": "2023-06-10T17:12:09.888252200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sub in tqdm(subs, total=len(subs), desc=\"Creating Temp Dir For Subs...\"):\n",
    "\ttemp_dir_path_ = f\"temp/{sub}\"\n",
    "\tif not os.path.exists(temp_dir_path_):\n",
    "\t\tos.makedirs(temp_dir_path_)\n",
    "\tos.makedirs(temp_dir_path_, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:18:05.138007500Z",
     "start_time": "2023-06-10T17:12:09.915251700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('log.txt', 'a') as f:\n",
    "\tfor time_filter in ['week', 'day']:\n",
    "\t\ts = tqdm(subs, desc=f\"{time_filter}\", total=len(subs))\n",
    "\t\tfor sub in s:\n",
    "\t\t# for sub in tqdm(subs, desc=f\"{time_filter}\", total=len(subs)):\n",
    "\t\t\ttemp_dir_path = f\"temp/{sub}\"\n",
    "\t\t\ttry:\n",
    "\t\t\t\tsubreddit_stream: ListingGenerator = reddit.subreddit(display_name=sub).top(limit=100, time_filter=time_filter)\n",
    "\t\t\t\tsubreddit_stream = list(subreddit_stream)\n",
    "\t\t\t\tp = tqdm(subreddit_stream, total=len(subreddit_stream), desc=f\"Posts - {sub} - {time_filter}\")\n",
    "\t\t\t\tfor submission in p:\n",
    "\t\t\t\t\tif submission is None:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif submission.id in extant_data.index.values:\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tauthor_name = 'Unknown'\n",
    "\t\t\t\t\t\tsubreddit_name = sub\n",
    "\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\tauthor_name = submission.author.name\n",
    "\t\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\t\tauthor_name = 'Unknown'\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\tp = {\n",
    "\t\t\t\t\t\t\t'id': submission.id,\n",
    "\t\t\t\t\t\t\t'subreddit': subreddit_name,\n",
    "\t\t\t\t\t\t\t'author': author_name,\n",
    "\t\t\t\t\t\t\t'title': submission.title,\n",
    "\t\t\t\t\t\t\t'caption': '',\n",
    "\t\t\t\t\t\t\t'hash': '',\n",
    "\t\t\t\t\t\t\t'permalink': submission.permalink,\n",
    "\t\t\t\t\t\t\t'original_url': submission.url,\n",
    "\t\t\t\t\t\t\t'image_name': '',\n",
    "\t\t\t\t\t\t\t'path': '',\n",
    "\t\t\t\t\t\t\t'thumbnail_path': '',\n",
    "\t\t\t\t\t\t\t'exists': False,\n",
    "\t\t\t\t\t\t\t'curated': False,\n",
    "\t\t\t\t\t\t\t'Tags': ['']\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\tpd.DataFrame([p]).to_parquet(f\"{temp_dir_path}/{submission.id}.parquet\")\n",
    "\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\tlog = functions.write_log_message(submission.id, sub, \"Error Writing Post\", e)\n",
    "\t\t\t\t\t\tf.write(log)\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tlog = functions.write_log_message(submission.id, sub, f\"Error Getting Posts For SubReddit\", e)\n",
    "\t\t\t\tf.write(log)\n",
    "\t\t\t\tcontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:18:17.327427300Z",
     "start_time": "2023-06-10T17:18:05.141003900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = []\n",
    "for sub in tqdm(subs, desc=\"Reading Temp Dir For Subs...\"):\n",
    "\tdf = pandas.read_parquet(f\"temp/{sub}\", schema=schema, engine='pyarrow')\n",
    "\trecords = df.to_dict(orient='records')\n",
    "\tdata.extend(records)\n",
    "\n",
    "temp_data = pandas.DataFrame(data)\n",
    "\n",
    "for i, r in temp_data.iterrows():\n",
    "\ttemp_data.loc[i, 'image_name'] = r.id + \".jpg\"\n",
    "\ttemp_data.loc[i, 'path'] = \"\"\n",
    "\ttemp_data.loc[i, 'hash'] = \"\"\n",
    "\ttemp_data.loc[i, 'caption'] = \"\"\n",
    "\ttemp_data.loc[i, 'model'] = \"\"\n",
    "\ttemp_data.loc[i, 'exists'] = False\n",
    "\ttemp_data.loc[i, 'curated'] = False\n",
    "\ttemp_data.loc[i, 'accept'] = False\n",
    "\ttemp_data.loc[i, 'tags'] = ['']\n",
    "\n",
    "temp_data.set_index('id', inplace=True, drop=False)\n",
    "\n",
    "display(\"==== TEMP DATA ====\")\n",
    "display(temp_data.shape)\n",
    "display(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:18:17.491945100Z",
     "start_time": "2023-06-10T17:18:17.328427400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered = temp_data[~temp_data['id'].isin(extant_data.index.values) & temp_data['original_url'].str.endswith('.jpg') & (~temp_data['id'].isin(curated_data.index.values))]\n",
    "\n",
    "filtered.dropna(axis=1, how='all')\n",
    "\n",
    "filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "filtered.set_index('id', inplace=True, drop=False)\n",
    "\n",
    "display(\"==== FILTERED DATA ====\")\n",
    "\n",
    "display(filtered.shape)\n",
    "\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:18:17.622983600Z",
     "start_time": "2023-06-10T17:18:17.386425500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered['model'] = filtered.progress_apply(lambda x: functions.add_source(x, sources), axis=1)\n",
    "\n",
    "display(\"== Filtered Data With Model ==\")\n",
    "display(filtered.shape)\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:27:55.544966700Z",
     "start_time": "2023-06-10T17:18:17.428434800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_list = file_system.ls(\"data/image\")\n",
    "\n",
    "filtered['path'] = filtered.progress_apply(lambda x: functions.fetch_image(x, file_list, file_system), axis=1)\n",
    "\n",
    "display(\"== Filtered Data With Path ==\")\n",
    "display(filtered.shape)\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:27:55.764540100Z",
     "start_time": "2023-06-10T17:27:55.505975500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered['exists'] = filtered.progress_apply(lambda x: functions.set_exists(x), axis=1)\n",
    "\n",
    "display(\"== Filtered Data With Exists ==\")\n",
    "display(filtered.shape)\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:27:57.327199400Z",
     "start_time": "2023-06-10T17:27:55.648965200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered['hash'] = filtered.progress_apply(lambda x: functions.set_hash(x), axis=1)\n",
    "\n",
    "display(\"== Filtered Data With Hash ==\")\n",
    "display(filtered.shape)\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:27:58.398198400Z",
     "start_time": "2023-06-10T17:27:57.326199500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = datetime.today().timestamp()\n",
    "\n",
    "exists = filtered.loc[filtered['exists'] == True]\n",
    "exists.dropna(axis=1, how='all')\n",
    "exists.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_records_to_process = exists.copy()\n",
    "del exists\n",
    "\n",
    "new_records_to_process.reset_index(drop=True, inplace=True)\n",
    "display(new_records_to_process)\n",
    "\n",
    "out_name = f\"data/temp/caption/primary/{ts}_new_records_to_process.parquet\"\n",
    "new_records_to_process.to_parquet(out_name, engine='pyarrow', filesystem=file_system, schema=schema)\n",
    "del new_records_to_process\n",
    "\n",
    "new_df = pandas.read_parquet(out_name, engine='pyarrow', filesystem=file_system, schema=schema)\n",
    "\n",
    "display(\"== New Records To Process ==\")\n",
    "display(new_df.shape)\n",
    "display(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T17:27:58.398198400Z",
     "start_time": "2023-06-10T17:27:57.979540300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(f\"Total Number Of New Images - {new_df.shape[0]}\")\n",
    "display(\"0-1 Image Acquisition Complete - Writing new output and Shutting Down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
