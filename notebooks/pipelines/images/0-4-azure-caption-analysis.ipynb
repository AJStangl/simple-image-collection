{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import pandas\n",
    "import requests\n",
    "from PIL import Image\n",
    "from adlfs import AzureBlobFileSystem\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.captioning.azure_descriptions import AzureCaption\n",
    "from common.schemas.pyarrow_schema import tagging_schema\n",
    "from common.storage.azure_file_storage import AzureFileStorageAdapter\n",
    "\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "file_system: AzureBlobFileSystem = AzureFileStorageAdapter('data').get_file_storage()\n",
    "\n",
    "from common.functions.functions import Functions\n",
    "\n",
    "functions: Functions = Functions()\n",
    "\n",
    "caption: AzureCaption = AzureCaption(file_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "#\n",
    "# curated_df = pandas.read_parquet('data/parquet/primary_caption.parquet', filesystem=file_system, engine='pyarrow')\n",
    "#\n",
    "# accepted = curated_df.loc[curated_df[\"accept\"] == True]\n",
    "#\n",
    "# dropped = accepted.dropna()\n",
    "# dropped.reset_index(inplace=True, drop=True)\n",
    "#\n",
    "# del accepted\n",
    "#\n",
    "# accepted = dropped.copy()\n",
    "# del dropped\n",
    "#\n",
    "# display(accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "#\n",
    "#\n",
    "# display(\"=== Obtaining Caption Files List ===\")\n",
    "# current_captions = file_system.ls(\"data/caption\")\n",
    "# display(f\"current caption files: {len(current_captions)}\")\n",
    "#\n",
    "# all_data = []\n",
    "# filtered_data = []\n",
    "# for caption_file in tqdm(current_captions, total=len(current_captions), desc='Reading caption files'):\n",
    "# \timage_id = caption_file.split('/')[-1].split('.')[0]\n",
    "# \ttry:\n",
    "# \t\tfile_size = file_system.size(caption_file)\n",
    "# \t\tif file_size == 0:\n",
    "# \t\t\tdisplay(f'Empty file -- removing {image_id}', clear=True)\n",
    "# \t\t\tfile_system.rm(caption_file)\n",
    "# \t\t\tcontinue\n",
    "# \t\tcaption_data = json.loads(file_system.read_text(caption_file, encoding='utf-8'))\n",
    "# \t\tcaption_data[\"id\"] = image_id\n",
    "# \t\tdense_caption_result = caption_data.get('denseCaptionsResult')\n",
    "# \t\tmetadata = caption_data.get('metadata')\n",
    "# \t\ttags_result = caption_data.get('tagsResult')\n",
    "# \t\tsmart_crop_result = caption_data.get('smartCropsResult')\n",
    "# \t\tbasic_caption = caption_data.get('captionResult')\n",
    "# \t\t_filtered_data = {\n",
    "# \t\t\t\"id\": image_id,\n",
    "# \t\t\t\"captions\": [basic_caption],\n",
    "# \t\t\t\"dense_captions\": dense_caption_result['values'],\n",
    "# \t\t\t\"meta\": [metadata],\n",
    "# \t\t\t\"tags\": tags_result['values'],\n",
    "# \t\t\t\"smart_crop\": smart_crop_result['values']\n",
    "# \t\t}\n",
    "# \t\tall_data.append(caption_data)\n",
    "# \t\tfiltered_data.append(_filtered_data)\n",
    "# \texcept Exception as e:\n",
    "# \t\tdisplay(f\" Exception {e} for {image_id}\", clear=True)\n",
    "# \t\tcontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "#\n",
    "# all_data_from_captions = pandas.DataFrame(data=all_data)\n",
    "# filtered_data_from_captions = pandas.DataFrame(data=filtered_data)\n",
    "#\n",
    "# display(all_data_from_captions)\n",
    "# display(filtered_data_from_captions)\n",
    "#\n",
    "# all_data_from_captions.to_parquet(\"data/parquet/all_data_from_captions.parquet\", engine='pyarrow',\n",
    "# \t\t\t\t\t\t\t\t  filesystem=file_system)\n",
    "#\n",
    "# filtered_data_from_captions.to_parquet(\"data/parquet/filtered_data_from_captions.parquet\", engine='pyarrow',\n",
    "# \t\t\t\t\t\t\t\t\t   filesystem=file_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_from_captions = pandas.read_parquet(\"data/parquet/all_data_from_captions.parquet\", engine='pyarrow', filesystem=file_system)\n",
    "display(all_data_from_captions)\n",
    "filtered_data_from_captions = pandas.read_parquet(\"data/parquet/filtered_data_from_captions.parquet\", engine='pyarrow', filesystem=file_system)\n",
    "display(filtered_data_from_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tags = pandas.DataFrame({'id': filtered_data_from_captions.id, 'tags': filtered_data_from_captions.tags})\n",
    "out = []\n",
    "for i,r in tqdm(tags.iterrows(), total=len(tags)):\n",
    "\tif r['tags'] is None:\n",
    "\t\t\tcontinue\n",
    "\ttag = pandas.json_normalize(r['tags'])\n",
    "\ttag['id'] = r['id']\n",
    "\td = tag.to_dict(orient='records')\n",
    "\tout.extend(d)\n",
    "converted_tags = pandas.DataFrame(data=out)\n",
    "display(converted_tags)\n",
    "converted_tags.to_parquet(\"data/parquet/tags.parquet\", engine='pyarrow', filesystem=file_system)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dense = pandas.DataFrame({'id': filtered_data_from_captions.id, 'dense_captions': filtered_data_from_captions.dense_captions})\n",
    "\n",
    "out = []\n",
    "for i,r in tqdm(dense.iterrows(), total=len(dense)):\n",
    "\tif r['dense_captions'] is None:\n",
    "\t\t\tcontinue\n",
    "\tdense_caption = pandas.json_normalize(r['dense_captions'])\n",
    "\tdense_caption['id'] = r['id']\n",
    "\td = dense_caption.to_dict(orient='records')\n",
    "\tout.extend(d)\n",
    "\n",
    "converted = pandas.DataFrame(data=out)\n",
    "display(converted)\n",
    "converted.to_parquet(\"data/parquet/dense_captions.parquet\", engine='pyarrow', filesystem=file_system)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_caption_data = pandas.DataFrame(\n",
    "# \t{\n",
    "# \t\t'id': all_data_from_captions['id'],\n",
    "# \t\t'azure_caption': [item['text'] for item in all_data_from_captions['captionResult']],\n",
    "# \t\t'tags': [[foo['name'] for foo in item['values']] for item in all_data_from_captions['tagsResult']]\n",
    "# \t})\n",
    "#\n",
    "#\n",
    "# single_caption_data_indexed = single_caption_data.set_index(\"id\")\n",
    "#\n",
    "# accepted_indexed = accepted.set_index(\"id\")\n",
    "#\n",
    "# for index, row in accepted_indexed.iterrows():\n",
    "# \taccepted_indexed.at[index, 'azure_caption'] = \"\"\n",
    "# \taccepted_indexed.at[index, 'thumbnail_path'] = \"\"\n",
    "# \taccepted_indexed.at[index, 'thumbnail_exists'] = False\n",
    "# \taccepted_indexed.at[index, 'thumbnail_curated'] = False\n",
    "# \taccepted_indexed.at[index, 'thumbnail_accept'] = False\n",
    "#\taccepted_indexed.at[index, 'additional_captions'] = ['']\n",
    "#\n",
    "# accepted_indexed.update(single_caption_data_indexed)\n",
    "#\n",
    "# accepted_final = accepted_indexed.reset_index()\n",
    "#\n",
    "# display(\"== Updated With Basic Captions ==\")\n",
    "# display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted_final.to_parquet(\"data/parquet/curation_2.parquet\", engine='pyarrow', filesystem=file_system, schema=tagging_schema)\n",
    "# del accepted_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accepted_final = pandas.read_parquet(\"data/parquet/curation_2.parquet\", engine='pyarrow', filesystem=file_system, schema=tagging_schema)\n",
    "display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_aspect_ratio(x: object):\n",
    "\treturn x['crops'][0]['aspectRatio']\n",
    "def get_bounding_box(x: object):\n",
    "\treturn x['crops'][0]['boundingBox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropping = pandas.DataFrame({'id': filtered_data_from_captions['id'], 'crops': filtered_data_from_captions['smart_crop']}).set_index('id', drop=False)\n",
    "\n",
    "cropping['aspectRatio'] = cropping.progress_apply(lambda x: get_aspect_ratio(x), axis=1)\n",
    "cropping['bounding_box'] = cropping.progress_apply(lambda x: get_bounding_box(x), axis=1)\n",
    "cropping['x'] = cropping.progress_apply(lambda x: x['bounding_box']['x'], axis=1)\n",
    "cropping['y'] = cropping.progress_apply(lambda x: x['bounding_box']['y'], axis=1)\n",
    "cropping['w'] = cropping.progress_apply(lambda x: x['bounding_box']['w'], axis=1)\n",
    "cropping['h'] = cropping.progress_apply(lambda x: x['bounding_box']['h'], axis=1)\n",
    "\n",
    "display(cropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thumbnail(target_image_id: str, file_names: list, crops: pandas.DataFrame, curated_data: pandas.DataFrame):\n",
    "\t_file_system: AzureBlobFileSystem = AzureFileStorageAdapter('data').get_file_storage()\n",
    "\n",
    "\tout_path = f\"data/image/thumbnail/{target_image_id}.jpg\"\n",
    "\ttry:\n",
    "\t\tif target_image_id is None or out_path in file_names:\n",
    "\t\t\t# print(f'Image {target_image_id} already exists, skipping')\n",
    "\t\t\treturn out_path\n",
    "\n",
    "\t\tcropping_information = cropping.loc[crops['id'] == target_image_id]\n",
    "\t\tif cropping_information is None or len(cropping_information) == 0:\n",
    "\t\t\t# print(f'No cropping information for {target_image_id}, skipping')\n",
    "\t\t\treturn \"/data/nope\"\n",
    "\n",
    "\t\trecord = curated_data.loc[curated_data['id'] == target_image_id]\n",
    "\t\trecord_path = record.to_dict(orient='records')[0]['path']\n",
    "\t\timage_url = file_system.url(record_path)\n",
    "\t\toriginal_image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\t\tcopied_image = original_image.copy()\n",
    "\t\toriginal_image.close()\n",
    "\n",
    "\t\tcropped = copied_image.crop((cropping_information['x'].values[0],\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['y'].values[0],\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['x'].values[0] +\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['w'].values[0],\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['y'].values[0] +\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['h'].values[0]))\n",
    "\t\tcopied_image.close()\n",
    "\n",
    "\t\tresized = cropped.resize((512, 512), 1)\n",
    "\t\tresized.save('temp.jpg')\n",
    "\t\tresized.close()\n",
    "\t\tfile_system.upload('temp.jpg', out_path, overwrite=True)\n",
    "\t\tprint(f'Thumbnail created for {target_image_id}')\n",
    "\t\treturn out_path\n",
    "\n",
    "\texcept Exception as ex:\n",
    "\t\tprint(f'Error creating thumbnail for {target_image_id}: {ex}')\n",
    "\t\treturn \"/data/nope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = file_system.ls('data/image/thumbnail')\n",
    "\n",
    "accepted_final['thumbnail_path'] = accepted_final.progress_apply(lambda x: create_thumbnail(x['id'], file_names, cropping, accepted_final), axis=1)\n",
    "\n",
    "display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accepted_final['thumbnail_exists'] = accepted_final.progress_apply(lambda x: file_system.exists(x['thumbnail_path']), axis=1)\n",
    "\n",
    "display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accepted_copy = accepted_final.copy()\n",
    "\n",
    "accepted_copy['additional_captions'] = accepted_copy.progress_apply(lambda x: [], axis=1)\n",
    "\n",
    "accepted_slice = accepted_copy.loc[accepted_copy['thumbnail_exists'] == True, tagging_schema.names]\n",
    "\n",
    "accepted_slice.dropna(inplace=True)\n",
    "\n",
    "accepted_slice.reset_index(inplace=True, drop=True)\n",
    "\n",
    "display(accepted_slice)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: Only update the this accepted slice if there are new captions, we don't want to overwrite the curated data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_system.cp('data/parquet/thumbnail_curation.parquet', 'data/parquet/thumbnail_curation.parquet.bak')\n",
    "\n",
    "# accepted_slice.to_parquet(\"data/parquet/thumbnail_curation.parquet\", engine='pyarrow', filesystem=file_system, schema=tagging_schema)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(accepted_slice)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
