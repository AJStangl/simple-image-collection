{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-10T18:51:18.802894500Z",
     "start_time": "2023-06-10T18:51:15.582738200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.03 s\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas\n",
    "import requests\n",
    "from PIL import Image\n",
    "from adlfs import AzureBlobFileSystem\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.captioning.azure_descriptions import AzureCaption\n",
    "from common.schemas.pyarrow_schema import tagging_schema\n",
    "from common.storage.azure_file_storage import AzureFileStorageAdapter\n",
    "\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "file_system: AzureBlobFileSystem = AzureFileStorageAdapter('data').get_file_storage()\n",
    "\n",
    "from common.functions.functions import Functions\n",
    "\n",
    "functions: Functions = Functions()\n",
    "\n",
    "caption: AzureCaption = AzureCaption(file_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-10T18:51:22.704152300Z",
     "start_time": "2023-06-10T18:51:21.620266600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            id              subreddit                author   \n0      1013bdt               AmIhotAF           RaulDea9286  \\\n1      105mekt               AmIhotAF              lindaniz   \n2      105qvgl               AmIhotAF           CaitVLove11   \n3      105rpcj               AmIhotAF       Flashy-Desk1858   \n4      105styc               AmIhotAF          Gizzygirl127   \n...        ...                    ...                   ...   \n20472  13oersw  AesPleasingAsianGirls               angizni   \n20473  13oxx2r  AesPleasingAsianGirls         theowuriwufoa   \n20474  13qlj64  AesPleasingAsianGirls  throwaway83736365372   \n20475  13qmsn4  AesPleasingAsianGirls          yummybanchan   \n20476  13zq92j            SFWRedheads         Sofia_Red_Fox   \n\n                                                title   \n0                                       36F - ITALIAN  \\\n1      interesting in good forward relationship (f24)   \n2                           Laughing is my favorite ðŸ˜†   \n3            [f22] What do you think when you see me?   \n4                            Low keyâ€¦ still bangable?   \n...                                               ...   \n20472                                         Glitter   \n20473                                    Green outfit   \n20474                                           Habin   \n20475                                      Song Yu Qi   \n20476                     Did I catch your attention?   \n\n                                                 caption   \n0                arafed image of a woman in a bikini top  \\\n1      a close up of a woman with red hair and a whit...   \n2      a woman in a blue tank top and shorts is smili...   \n3        a woman in a blue bikini top and a blue bra top   \n4      smiling woman sitting on couch with remote con...   \n...                                                  ...   \n20472  three women in sequin dresses posing for a pic...   \n20473  araffe woman sitting on a couch in a green outfit   \n20474   araffe woman in a pink bikini standing in a pool   \n20475  there is a woman with a bouquet of flowers in ...   \n20476  arafed woman with long red hair posing for a p...   \n\n                                   hash   \n0      7c0d158cba8654ef1c635cbc5471d597  \\\n1      ba4a0962cca2266a741e1e1700589c04   \n2      27bfe82c37314a0bcf02ab72eaf3a9e5   \n3      329eb42b8267fa1cc2980da8e48bcef1   \n4      6d555943be4fbc21ff92417c6f582298   \n...                                 ...   \n20472  cbd83e4de946b42ce318e93d14d78776   \n20473  aa460440886847369e59fa8ac2b91f2b   \n20474  e1244a45a5018d6d35e487217a489db2   \n20475  a2189d7026d58082336ddcad3667161e   \n20476  6eb93984fae6a72846fcd6322d3d0c91   \n\n                                               permalink   \n0              /r/AmIhotAF/comments/1013bdt/36f_italian/  \\\n1      /r/AmIhotAF/comments/105mekt/interesting_in_go...   \n2      /r/AmIhotAF/comments/105qvgl/laughing_is_my_fa...   \n3      /r/AmIhotAF/comments/105rpcj/f22_what_do_you_t...   \n4      /r/AmIhotAF/comments/105styc/low_key_still_ban...   \n...                                                  ...   \n20472  /r/AesPleasingAsianGirls/comments/13oersw/glit...   \n20473  /r/AesPleasingAsianGirls/comments/13oxx2r/gree...   \n20474   /r/AesPleasingAsianGirls/comments/13qlj64/habin/   \n20475  /r/AesPleasingAsianGirls/comments/13qmsn4/song...   \n20476  /r/SFWRedheads/comments/13zq92j/did_i_catch_yo...   \n\n                              original_url   image_name   \n0      https://i.redd.it/bg0wwdlt5k9a1.jpg  1013bdt.jpg  \\\n1      https://i.redd.it/4avjshsz8naa1.jpg  105mekt.jpg   \n2      https://i.redd.it/2pulzr0lxmaa1.jpg  105qvgl.jpg   \n3      https://i.redd.it/rz68pf934naa1.jpg  105rpcj.jpg   \n4      https://i.redd.it/aiaxxoz9uoaa1.jpg  105styc.jpg   \n...                                    ...          ...   \n20472  https://i.redd.it/zvr3dt5occ1b1.jpg  13oersw.jpg   \n20473  https://i.redd.it/vvy28ulupg1b1.jpg  13oxx2r.jpg   \n20474  https://i.redd.it/29soeuf3nt1b1.jpg  13qlj64.jpg   \n20475  https://i.redd.it/cdj3scvnvt1b1.jpg  13qmsn4.jpg   \n20476  https://i.redd.it/f74fbalefv3b1.jpg  13zq92j.jpg   \n\n                         path               model  exists  curated  accept   \n0      data/image/1013bdt.jpg       SexyDiffusion    True     True    True  \\\n1      data/image/105mekt.jpg       SexyDiffusion    True     True    True   \n2      data/image/105qvgl.jpg       SexyDiffusion    True     True    True   \n3      data/image/105rpcj.jpg       SexyDiffusion    True     True    True   \n4      data/image/105styc.jpg       SexyDiffusion    True     True    True   \n...                       ...                 ...     ...      ...     ...   \n20472  data/image/13oersw.jpg  SexyAsianDiffusion    True     True    True   \n20473  data/image/13oxx2r.jpg  SexyAsianDiffusion    True     True    True   \n20474  data/image/13qlj64.jpg  SexyAsianDiffusion    True     True    True   \n20475  data/image/13qmsn4.jpg  SexyAsianDiffusion    True     True    True   \n20476  data/image/13zq92j.jpg    RedHeadDiffusion    True     True    True   \n\n      tags  \n0       []  \n1       []  \n2       []  \n3       []  \n4       []  \n...    ...  \n20472   []  \n20473   []  \n20474   []  \n20475   []  \n20476   []  \n\n[20477 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>subreddit</th>\n      <th>author</th>\n      <th>title</th>\n      <th>caption</th>\n      <th>hash</th>\n      <th>permalink</th>\n      <th>original_url</th>\n      <th>image_name</th>\n      <th>path</th>\n      <th>model</th>\n      <th>exists</th>\n      <th>curated</th>\n      <th>accept</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1013bdt</td>\n      <td>AmIhotAF</td>\n      <td>RaulDea9286</td>\n      <td>36F - ITALIAN</td>\n      <td>arafed image of a woman in a bikini top</td>\n      <td>7c0d158cba8654ef1c635cbc5471d597</td>\n      <td>/r/AmIhotAF/comments/1013bdt/36f_italian/</td>\n      <td>https://i.redd.it/bg0wwdlt5k9a1.jpg</td>\n      <td>1013bdt.jpg</td>\n      <td>data/image/1013bdt.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>105mekt</td>\n      <td>AmIhotAF</td>\n      <td>lindaniz</td>\n      <td>interesting in good forward relationship (f24)</td>\n      <td>a close up of a woman with red hair and a whit...</td>\n      <td>ba4a0962cca2266a741e1e1700589c04</td>\n      <td>/r/AmIhotAF/comments/105mekt/interesting_in_go...</td>\n      <td>https://i.redd.it/4avjshsz8naa1.jpg</td>\n      <td>105mekt.jpg</td>\n      <td>data/image/105mekt.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>105qvgl</td>\n      <td>AmIhotAF</td>\n      <td>CaitVLove11</td>\n      <td>Laughing is my favorite ðŸ˜†</td>\n      <td>a woman in a blue tank top and shorts is smili...</td>\n      <td>27bfe82c37314a0bcf02ab72eaf3a9e5</td>\n      <td>/r/AmIhotAF/comments/105qvgl/laughing_is_my_fa...</td>\n      <td>https://i.redd.it/2pulzr0lxmaa1.jpg</td>\n      <td>105qvgl.jpg</td>\n      <td>data/image/105qvgl.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105rpcj</td>\n      <td>AmIhotAF</td>\n      <td>Flashy-Desk1858</td>\n      <td>[f22] What do you think when you see me?</td>\n      <td>a woman in a blue bikini top and a blue bra top</td>\n      <td>329eb42b8267fa1cc2980da8e48bcef1</td>\n      <td>/r/AmIhotAF/comments/105rpcj/f22_what_do_you_t...</td>\n      <td>https://i.redd.it/rz68pf934naa1.jpg</td>\n      <td>105rpcj.jpg</td>\n      <td>data/image/105rpcj.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>105styc</td>\n      <td>AmIhotAF</td>\n      <td>Gizzygirl127</td>\n      <td>Low keyâ€¦ still bangable?</td>\n      <td>smiling woman sitting on couch with remote con...</td>\n      <td>6d555943be4fbc21ff92417c6f582298</td>\n      <td>/r/AmIhotAF/comments/105styc/low_key_still_ban...</td>\n      <td>https://i.redd.it/aiaxxoz9uoaa1.jpg</td>\n      <td>105styc.jpg</td>\n      <td>data/image/105styc.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20472</th>\n      <td>13oersw</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>angizni</td>\n      <td>Glitter</td>\n      <td>three women in sequin dresses posing for a pic...</td>\n      <td>cbd83e4de946b42ce318e93d14d78776</td>\n      <td>/r/AesPleasingAsianGirls/comments/13oersw/glit...</td>\n      <td>https://i.redd.it/zvr3dt5occ1b1.jpg</td>\n      <td>13oersw.jpg</td>\n      <td>data/image/13oersw.jpg</td>\n      <td>SexyAsianDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20473</th>\n      <td>13oxx2r</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>theowuriwufoa</td>\n      <td>Green outfit</td>\n      <td>araffe woman sitting on a couch in a green outfit</td>\n      <td>aa460440886847369e59fa8ac2b91f2b</td>\n      <td>/r/AesPleasingAsianGirls/comments/13oxx2r/gree...</td>\n      <td>https://i.redd.it/vvy28ulupg1b1.jpg</td>\n      <td>13oxx2r.jpg</td>\n      <td>data/image/13oxx2r.jpg</td>\n      <td>SexyAsianDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20474</th>\n      <td>13qlj64</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>throwaway83736365372</td>\n      <td>Habin</td>\n      <td>araffe woman in a pink bikini standing in a pool</td>\n      <td>e1244a45a5018d6d35e487217a489db2</td>\n      <td>/r/AesPleasingAsianGirls/comments/13qlj64/habin/</td>\n      <td>https://i.redd.it/29soeuf3nt1b1.jpg</td>\n      <td>13qlj64.jpg</td>\n      <td>data/image/13qlj64.jpg</td>\n      <td>SexyAsianDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20475</th>\n      <td>13qmsn4</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>yummybanchan</td>\n      <td>Song Yu Qi</td>\n      <td>there is a woman with a bouquet of flowers in ...</td>\n      <td>a2189d7026d58082336ddcad3667161e</td>\n      <td>/r/AesPleasingAsianGirls/comments/13qmsn4/song...</td>\n      <td>https://i.redd.it/cdj3scvnvt1b1.jpg</td>\n      <td>13qmsn4.jpg</td>\n      <td>data/image/13qmsn4.jpg</td>\n      <td>SexyAsianDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20476</th>\n      <td>13zq92j</td>\n      <td>SFWRedheads</td>\n      <td>Sofia_Red_Fox</td>\n      <td>Did I catch your attention?</td>\n      <td>arafed woman with long red hair posing for a p...</td>\n      <td>6eb93984fae6a72846fcd6322d3d0c91</td>\n      <td>/r/SFWRedheads/comments/13zq92j/did_i_catch_yo...</td>\n      <td>https://i.redd.it/f74fbalefv3b1.jpg</td>\n      <td>13zq92j.jpg</td>\n      <td>data/image/13zq92j.jpg</td>\n      <td>RedHeadDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>20477 rows Ã— 15 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 438 ms\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "#\n",
    "# curated_df = pandas.read_parquet('data/parquet/primary_caption.parquet', filesystem=file_system, engine='pyarrow')\n",
    "#\n",
    "# accepted = curated_df.loc[curated_df[\"accept\"] == True]\n",
    "#\n",
    "# dropped = accepted.dropna()\n",
    "# dropped.reset_index(inplace=True, drop=True)\n",
    "#\n",
    "# del accepted\n",
    "#\n",
    "# accepted = dropped.copy()\n",
    "# del dropped\n",
    "#\n",
    "# display(accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-10T18:51:47.108369400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'=== Obtaining Caption Files List ==='"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'current caption files: 18789'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading caption files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18789/18789 [27:56<00:00, 11.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 39s\n",
      "Wall time: 28min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "#\n",
    "#\n",
    "# display(\"=== Obtaining Caption Files List ===\")\n",
    "# current_captions = file_system.ls(\"data/caption\")\n",
    "# display(f\"current caption files: {len(current_captions)}\")\n",
    "#\n",
    "# all_data = []\n",
    "# filtered_data = []\n",
    "# for caption_file in tqdm(current_captions, total=len(current_captions), desc='Reading caption files'):\n",
    "# \timage_id = caption_file.split('/')[-1].split('.')[0]\n",
    "# \ttry:\n",
    "# \t\tfile_size = file_system.size(caption_file)\n",
    "# \t\tif file_size == 0:\n",
    "# \t\t\tdisplay(f'Empty file -- removing {image_id}', clear=True)\n",
    "# \t\t\tfile_system.rm(caption_file)\n",
    "# \t\t\tcontinue\n",
    "# \t\tcaption_data = json.loads(file_system.read_text(caption_file, encoding='utf-8'))\n",
    "# \t\tcaption_data[\"id\"] = image_id\n",
    "# \t\tdense_caption_result = caption_data.get('denseCaptionsResult')\n",
    "# \t\tmetadata = caption_data.get('metadata')\n",
    "# \t\ttags_result = caption_data.get('tagsResult')\n",
    "# \t\tsmart_crop_result = caption_data.get('smartCropsResult')\n",
    "# \t\tbasic_caption = caption_data.get('captionResult')\n",
    "# \t\t_filtered_data = {\n",
    "# \t\t\t\"id\": image_id,\n",
    "# \t\t\t\"captions\": [basic_caption],\n",
    "# \t\t\t\"dense_captions\": dense_caption_result['values'],\n",
    "# \t\t\t\"meta\": [metadata],\n",
    "# \t\t\t\"tags\": tags_result['values'],\n",
    "# \t\t\t\"smart_crop\": smart_crop_result['values']\n",
    "# \t\t}\n",
    "# \t\tall_data.append(caption_data)\n",
    "# \t\tfiltered_data.append(_filtered_data)\n",
    "# \texcept Exception as e:\n",
    "# \t\tdisplay(f\" Exception {e} for {image_id}\", clear=True)\n",
    "# \t\tcontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                           captionResult   \n0      {'text': 'a lizard on a helmet on a football f...  \\\n1      {'text': 'a black and white photo of a hallway...   \n2      {'text': 'a hand holding a red and white flowe...   \n3      {'text': 'a boat on the shore with green and p...   \n4      {'text': 'a woman painting a picture on a beac...   \n...                                                  ...   \n18784  {'text': 'ducks swimming in a pond', 'confiden...   \n18785  {'text': 'a river running through a forest', '...   \n18786  {'text': 'a group of chairs outside a blue hou...   \n18787  {'text': 'a rock formation in a desert', 'conf...   \n18788  {'text': 'a bird sitting on a branch', 'confid...   \n\n                                           objectsResult   \n0      {'values': [{'boundingBox': {'x': 2654, 'y': 2...  \\\n1                                         {'values': []}   \n2      {'values': [{'boundingBox': {'x': 457, 'y': 69...   \n3      {'values': [{'boundingBox': {'x': 261, 'y': 44...   \n4      {'values': [{'boundingBox': {'x': 1229, 'y': 4...   \n...                                                  ...   \n18784                                     {'values': []}   \n18785                                     {'values': []}   \n18786  {'values': [{'boundingBox': {'x': 515, 'y': 20...   \n18787                                     {'values': []}   \n18788  {'values': [{'boundingBox': {'x': 524, 'y': 10...   \n\n                                              readResult   \n0      {'stringIndexType': 'TextElements', 'content':...  \\\n1      {'stringIndexType': 'TextElements', 'content':...   \n2      {'stringIndexType': 'TextElements', 'content':...   \n3      {'stringIndexType': 'TextElements', 'content':...   \n4      {'stringIndexType': 'TextElements', 'content':...   \n...                                                  ...   \n18784  {'stringIndexType': 'TextElements', 'content':...   \n18785  {'stringIndexType': 'TextElements', 'content':...   \n18786  {'stringIndexType': 'TextElements', 'content':...   \n18787  {'stringIndexType': 'TextElements', 'content':...   \n18788  {'stringIndexType': 'TextElements', 'content':...   \n\n                                     denseCaptionsResult        modelVersion   \n0      {'values': [{'text': 'a close-up of a sign', '...  2023-02-01-preview  \\\n1      {'values': [{'text': 'a white archways with a ...  2023-02-01-preview   \n2      {'values': [{'text': 'a close up of a flower',...  2023-02-01-preview   \n3      {'values': [{'text': 'a boat on the shore with...  2023-02-01-preview   \n4      {'values': [{'text': 'a woman painting a pictu...  2023-02-01-preview   \n...                                                  ...                 ...   \n18784  {'values': [{'text': 'ducks swimming in a pond...  2023-02-01-preview   \n18785  {'values': [{'text': 'a river running through ...  2023-02-01-preview   \n18786  {'values': [{'text': 'a chair with a broken fr...  2023-02-01-preview   \n18787  {'values': [{'text': 'a bush in the desert', '...  2023-02-01-preview   \n18788  {'values': [{'text': 'close up of a bird's fee...  2023-02-01-preview   \n\n                              metadata   \n0      {'width': 7407, 'height': 5068}  \\\n1      {'width': 1440, 'height': 1800}   \n2      {'width': 3024, 'height': 4032}   \n3       {'width': 1110, 'height': 743}   \n4      {'width': 4032, 'height': 2268}   \n...                                ...   \n18784  {'width': 4032, 'height': 3024}   \n18785  {'width': 2000, 'height': 1500}   \n18786  {'width': 1080, 'height': 1080}   \n18787  {'width': 4032, 'height': 1960}   \n18788  {'width': 2369, 'height': 2369}   \n\n                                              tagsResult   \n0      {'values': [{'name': 'grass', 'confidence': 0....  \\\n1      {'values': [{'name': 'black and white', 'confi...   \n2      {'values': [{'name': 'flower', 'confidence': 0...   \n3      {'values': [{'name': 'sky', 'confidence': 0.98...   \n4      {'values': [{'name': 'outdoor', 'confidence': ...   \n...                                                  ...   \n18784  {'values': [{'name': 'outdoor', 'confidence': ...   \n18785  {'values': [{'name': 'outdoor', 'confidence': ...   \n18786  {'values': [{'name': 'furniture', 'confidence'...   \n18787  {'values': [{'name': 'cloud', 'confidence': 0....   \n18788  {'values': [{'name': 'bird', 'confidence': 0.9...   \n\n                                        smartCropsResult   \n0      {'values': [{'aspectRatio': 1.0, 'boundingBox'...  \\\n1      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n2      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n3      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n4      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n...                                                  ...   \n18784  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18785  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18786  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18787  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18788  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n\n                                            peopleResult       id  \n0      {'values': [{'boundingBox': {'x': 5113, 'y': 2...  10006iy  \n1                                         {'values': []}  1000cng  \n2      {'values': [{'boundingBox': {'x': 1420, 'y': 2...  1000hda  \n3      {'values': [{'boundingBox': {'x': 958, 'y': 43...  1000qpd  \n4      {'values': [{'boundingBox': {'x': 1163, 'y': 3...  1000xd6  \n...                                                  ...      ...  \n18784  {'values': [{'boundingBox': {'x': 1706, 'y': 2...   zzzmli  \n18785                                     {'values': []}   zzzoel  \n18786  {'values': [{'boundingBox': {'x': 81, 'y': 612...   zzztxl  \n18787  {'values': [{'boundingBox': {'x': 1761, 'y': 1...   zzzwub  \n18788  {'values': [{'boundingBox': {'x': 1008, 'y': 2...   zzzyty  \n\n[18789 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>captionResult</th>\n      <th>objectsResult</th>\n      <th>readResult</th>\n      <th>denseCaptionsResult</th>\n      <th>modelVersion</th>\n      <th>metadata</th>\n      <th>tagsResult</th>\n      <th>smartCropsResult</th>\n      <th>peopleResult</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'text': 'a lizard on a helmet on a football f...</td>\n      <td>{'values': [{'boundingBox': {'x': 2654, 'y': 2...</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a close-up of a sign', '...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 7407, 'height': 5068}</td>\n      <td>{'values': [{'name': 'grass', 'confidence': 0....</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 5113, 'y': 2...</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'text': 'a black and white photo of a hallway...</td>\n      <td>{'values': []}</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a white archways with a ...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 1440, 'height': 1800}</td>\n      <td>{'values': [{'name': 'black and white', 'confi...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': []}</td>\n      <td>1000cng</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'text': 'a hand holding a red and white flowe...</td>\n      <td>{'values': [{'boundingBox': {'x': 457, 'y': 69...</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a close up of a flower',...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 3024, 'height': 4032}</td>\n      <td>{'values': [{'name': 'flower', 'confidence': 0...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 1420, 'y': 2...</td>\n      <td>1000hda</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'text': 'a boat on the shore with green and p...</td>\n      <td>{'values': [{'boundingBox': {'x': 261, 'y': 44...</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a boat on the shore with...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 1110, 'height': 743}</td>\n      <td>{'values': [{'name': 'sky', 'confidence': 0.98...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 958, 'y': 43...</td>\n      <td>1000qpd</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'text': 'a woman painting a picture on a beac...</td>\n      <td>{'values': [{'boundingBox': {'x': 1229, 'y': 4...</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a woman painting a pictu...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 4032, 'height': 2268}</td>\n      <td>{'values': [{'name': 'outdoor', 'confidence': ...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 1163, 'y': 3...</td>\n      <td>1000xd6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18784</th>\n      <td>{'text': 'ducks swimming in a pond', 'confiden...</td>\n      <td>{'values': []}</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'ducks swimming in a pond...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 4032, 'height': 3024}</td>\n      <td>{'values': [{'name': 'outdoor', 'confidence': ...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 1706, 'y': 2...</td>\n      <td>zzzmli</td>\n    </tr>\n    <tr>\n      <th>18785</th>\n      <td>{'text': 'a river running through a forest', '...</td>\n      <td>{'values': []}</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a river running through ...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 2000, 'height': 1500}</td>\n      <td>{'values': [{'name': 'outdoor', 'confidence': ...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': []}</td>\n      <td>zzzoel</td>\n    </tr>\n    <tr>\n      <th>18786</th>\n      <td>{'text': 'a group of chairs outside a blue hou...</td>\n      <td>{'values': [{'boundingBox': {'x': 515, 'y': 20...</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a chair with a broken fr...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 1080, 'height': 1080}</td>\n      <td>{'values': [{'name': 'furniture', 'confidence'...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 81, 'y': 612...</td>\n      <td>zzztxl</td>\n    </tr>\n    <tr>\n      <th>18787</th>\n      <td>{'text': 'a rock formation in a desert', 'conf...</td>\n      <td>{'values': []}</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'a bush in the desert', '...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 4032, 'height': 1960}</td>\n      <td>{'values': [{'name': 'cloud', 'confidence': 0....</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 1761, 'y': 1...</td>\n      <td>zzzwub</td>\n    </tr>\n    <tr>\n      <th>18788</th>\n      <td>{'text': 'a bird sitting on a branch', 'confid...</td>\n      <td>{'values': [{'boundingBox': {'x': 524, 'y': 10...</td>\n      <td>{'stringIndexType': 'TextElements', 'content':...</td>\n      <td>{'values': [{'text': 'close up of a bird's fee...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'width': 2369, 'height': 2369}</td>\n      <td>{'values': [{'name': 'bird', 'confidence': 0.9...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'x': 1008, 'y': 2...</td>\n      <td>zzzyty</td>\n    </tr>\n  </tbody>\n</table>\n<p>18789 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "            id                                           captions   \n0      10006iy  [{'text': 'a lizard on a helmet on a football ...  \\\n1      1000cng  [{'text': 'a black and white photo of a hallwa...   \n2      1000hda  [{'text': 'a hand holding a red and white flow...   \n3      1000qpd  [{'text': 'a boat on the shore with green and ...   \n4      1000xd6  [{'text': 'a woman painting a picture on a bea...   \n...        ...                                                ...   \n18784   zzzmli  [{'text': 'ducks swimming in a pond', 'confide...   \n18785   zzzoel  [{'text': 'a river running through a forest', ...   \n18786   zzztxl  [{'text': 'a group of chairs outside a blue ho...   \n18787   zzzwub  [{'text': 'a rock formation in a desert', 'con...   \n18788   zzzyty  [{'text': 'a bird sitting on a branch', 'confi...   \n\n                                          dense_captions   \n0      [{'text': 'a close-up of a sign', 'confidence'...  \\\n1      [{'text': 'a white archways with a brick floor...   \n2      [{'text': 'a close up of a flower', 'confidenc...   \n3      [{'text': 'a boat on the shore with green and ...   \n4      [{'text': 'a woman painting a picture on a bea...   \n...                                                  ...   \n18784  [{'text': 'ducks swimming in a pond', 'confide...   \n18785  [{'text': 'a river running through a forest', ...   \n18786  [{'text': 'a chair with a broken frame', 'conf...   \n18787  [{'text': 'a bush in the desert', 'confidence'...   \n18788  [{'text': 'close up of a bird's feet', 'confid...   \n\n                                    meta   \n0      [{'width': 7407, 'height': 5068}]  \\\n1      [{'width': 1440, 'height': 1800}]   \n2      [{'width': 3024, 'height': 4032}]   \n3       [{'width': 1110, 'height': 743}]   \n4      [{'width': 4032, 'height': 2268}]   \n...                                  ...   \n18784  [{'width': 4032, 'height': 3024}]   \n18785  [{'width': 2000, 'height': 1500}]   \n18786  [{'width': 1080, 'height': 1080}]   \n18787  [{'width': 4032, 'height': 1960}]   \n18788  [{'width': 2369, 'height': 2369}]   \n\n                                                    tags   \n0      [{'name': 'grass', 'confidence': 0.98760414123...  \\\n1      [{'name': 'black and white', 'confidence': 0.9...   \n2      [{'name': 'flower', 'confidence': 0.9986068606...   \n3      [{'name': 'sky', 'confidence': 0.9853595495223...   \n4      [{'name': 'outdoor', 'confidence': 0.997976720...   \n...                                                  ...   \n18784  [{'name': 'outdoor', 'confidence': 0.999208092...   \n18785  [{'name': 'outdoor', 'confidence': 0.999588847...   \n18786  [{'name': 'furniture', 'confidence': 0.9758070...   \n18787  [{'name': 'cloud', 'confidence': 0.99515521526...   \n18788  [{'name': 'bird', 'confidence': 0.998412191867...   \n\n                                              smart_crop  \n0      [{'aspectRatio': 1.0, 'boundingBox': {'x': 115...  \n1      [{'aspectRatio': 1.0, 'boundingBox': {'x': 0, ...  \n2      [{'aspectRatio': 1.0, 'boundingBox': {'x': 142...  \n3      [{'aspectRatio': 1.0, 'boundingBox': {'x': 173...  \n4      [{'aspectRatio': 1.0, 'boundingBox': {'x': 702...  \n...                                                  ...  \n18784  [{'aspectRatio': 1.0, 'boundingBox': {'x': 344...  \n18785  [{'aspectRatio': 1.0, 'boundingBox': {'x': 443...  \n18786  [{'aspectRatio': 1.0, 'boundingBox': {'x': 51,...  \n18787  [{'aspectRatio': 1.0, 'boundingBox': {'x': 425...  \n18788  [{'aspectRatio': 1.0, 'boundingBox': {'x': 111...  \n\n[18789 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>captions</th>\n      <th>dense_captions</th>\n      <th>meta</th>\n      <th>tags</th>\n      <th>smart_crop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10006iy</td>\n      <td>[{'text': 'a lizard on a helmet on a football ...</td>\n      <td>[{'text': 'a close-up of a sign', 'confidence'...</td>\n      <td>[{'width': 7407, 'height': 5068}]</td>\n      <td>[{'name': 'grass', 'confidence': 0.98760414123...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 115...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000cng</td>\n      <td>[{'text': 'a black and white photo of a hallwa...</td>\n      <td>[{'text': 'a white archways with a brick floor...</td>\n      <td>[{'width': 1440, 'height': 1800}]</td>\n      <td>[{'name': 'black and white', 'confidence': 0.9...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000hda</td>\n      <td>[{'text': 'a hand holding a red and white flow...</td>\n      <td>[{'text': 'a close up of a flower', 'confidenc...</td>\n      <td>[{'width': 3024, 'height': 4032}]</td>\n      <td>[{'name': 'flower', 'confidence': 0.9986068606...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 142...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000qpd</td>\n      <td>[{'text': 'a boat on the shore with green and ...</td>\n      <td>[{'text': 'a boat on the shore with green and ...</td>\n      <td>[{'width': 1110, 'height': 743}]</td>\n      <td>[{'name': 'sky', 'confidence': 0.9853595495223...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 173...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000xd6</td>\n      <td>[{'text': 'a woman painting a picture on a bea...</td>\n      <td>[{'text': 'a woman painting a picture on a bea...</td>\n      <td>[{'width': 4032, 'height': 2268}]</td>\n      <td>[{'name': 'outdoor', 'confidence': 0.997976720...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 702...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18784</th>\n      <td>zzzmli</td>\n      <td>[{'text': 'ducks swimming in a pond', 'confide...</td>\n      <td>[{'text': 'ducks swimming in a pond', 'confide...</td>\n      <td>[{'width': 4032, 'height': 3024}]</td>\n      <td>[{'name': 'outdoor', 'confidence': 0.999208092...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 344...</td>\n    </tr>\n    <tr>\n      <th>18785</th>\n      <td>zzzoel</td>\n      <td>[{'text': 'a river running through a forest', ...</td>\n      <td>[{'text': 'a river running through a forest', ...</td>\n      <td>[{'width': 2000, 'height': 1500}]</td>\n      <td>[{'name': 'outdoor', 'confidence': 0.999588847...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 443...</td>\n    </tr>\n    <tr>\n      <th>18786</th>\n      <td>zzztxl</td>\n      <td>[{'text': 'a group of chairs outside a blue ho...</td>\n      <td>[{'text': 'a chair with a broken frame', 'conf...</td>\n      <td>[{'width': 1080, 'height': 1080}]</td>\n      <td>[{'name': 'furniture', 'confidence': 0.9758070...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 51,...</td>\n    </tr>\n    <tr>\n      <th>18787</th>\n      <td>zzzwub</td>\n      <td>[{'text': 'a rock formation in a desert', 'con...</td>\n      <td>[{'text': 'a bush in the desert', 'confidence'...</td>\n      <td>[{'width': 4032, 'height': 1960}]</td>\n      <td>[{'name': 'cloud', 'confidence': 0.99515521526...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 425...</td>\n    </tr>\n    <tr>\n      <th>18788</th>\n      <td>zzzyty</td>\n      <td>[{'text': 'a bird sitting on a branch', 'confi...</td>\n      <td>[{'text': 'close up of a bird's feet', 'confid...</td>\n      <td>[{'width': 2369, 'height': 2369}]</td>\n      <td>[{'name': 'bird', 'confidence': 0.998412191867...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'x': 111...</td>\n    </tr>\n  </tbody>\n</table>\n<p>18789 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.81 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "#\n",
    "# all_data_from_captions = pandas.DataFrame(data=all_data)\n",
    "# filtered_data_from_captions = pandas.DataFrame(data=filtered_data)\n",
    "#\n",
    "# display(all_data_from_captions)\n",
    "# display(filtered_data_from_captions)\n",
    "#\n",
    "# all_data_from_captions.to_parquet(\"data/parquet/all_data_from_captions.parquet\", engine='pyarrow',\n",
    "# \t\t\t\t\t\t\t\t  filesystem=file_system)\n",
    "#\n",
    "# filtered_data_from_captions.to_parquet(\"data/parquet/filtered_data_from_captions.parquet\", engine='pyarrow',\n",
    "# \t\t\t\t\t\t\t\t\t   filesystem=file_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                           captionResult   \n0      {'confidence': 0.5599533319473267, 'text': 'a ...  \\\n1      {'confidence': 0.4056971073150635, 'text': 'a ...   \n2      {'confidence': 0.6252590417861938, 'text': 'a ...   \n3      {'confidence': 0.43016329407691956, 'text': 'a...   \n4      {'confidence': 0.4159470796585083, 'text': 'a ...   \n...                                                  ...   \n18784  {'confidence': 0.5420117974281311, 'text': 'du...   \n18785  {'confidence': 0.4528125524520874, 'text': 'a ...   \n18786  {'confidence': 0.3901562988758087, 'text': 'a ...   \n18787  {'confidence': 0.39278653264045715, 'text': 'a...   \n18788  {'confidence': 0.6049655079841614, 'text': 'a ...   \n\n                                           objectsResult   \n0      {'values': [{'boundingBox': {'h': 825, 'w': 14...  \\\n1                                         {'values': []}   \n2      {'values': [{'boundingBox': {'h': 2233, 'w': 2...   \n3      {'values': [{'boundingBox': {'h': 228, 'w': 56...   \n4      {'values': [{'boundingBox': {'h': 1761, 'w': 7...   \n...                                                  ...   \n18784                                     {'values': []}   \n18785                                     {'values': []}   \n18786  {'values': [{'boundingBox': {'h': 595, 'w': 31...   \n18787                                     {'values': []}   \n18788  {'values': [{'boundingBox': {'h': 352, 'w': 53...   \n\n                                              readResult   \n0      {'content': 'pepsi\nLite\n000\nAT&T STADIUM', 'mo...  \\\n1      {'content': '', 'modelVersion': '2022-04-30', ...   \n2      {'content': '', 'modelVersion': '2022-04-30', ...   \n3      {'content': '@ Adam Woodworth', 'modelVersion'...   \n4      {'content': '', 'modelVersion': '2022-04-30', ...   \n...                                                  ...   \n18784  {'content': '', 'modelVersion': '2022-04-30', ...   \n18785  {'content': '', 'modelVersion': '2022-04-30', ...   \n18786  {'content': '', 'modelVersion': '2022-04-30', ...   \n18787  {'content': '', 'modelVersion': '2022-04-30', ...   \n18788  {'content': '', 'modelVersion': '2022-04-30', ...   \n\n                                     denseCaptionsResult        modelVersion   \n0      {'values': [{'boundingBox': {'h': 311, 'w': 11...  2023-02-01-preview  \\\n1      {'values': [{'boundingBox': {'h': 1768, 'w': 1...  2023-02-01-preview   \n2      {'values': [{'boundingBox': {'h': 1828, 'w': 1...  2023-02-01-preview   \n3      {'values': [{'boundingBox': {'h': 743, 'w': 11...  2023-02-01-preview   \n4      {'values': [{'boundingBox': {'h': 2268, 'w': 4...  2023-02-01-preview   \n...                                                  ...                 ...   \n18784  {'values': [{'boundingBox': {'h': 3024, 'w': 4...  2023-02-01-preview   \n18785  {'values': [{'boundingBox': {'h': 1500, 'w': 2...  2023-02-01-preview   \n18786  {'values': [{'boundingBox': {'h': 346, 'w': 23...  2023-02-01-preview   \n18787  {'values': [{'boundingBox': {'h': 111, 'w': 10...  2023-02-01-preview   \n18788  {'values': [{'boundingBox': {'h': 119, 'w': 20...  2023-02-01-preview   \n\n                              metadata   \n0      {'height': 5068, 'width': 7407}  \\\n1      {'height': 1800, 'width': 1440}   \n2      {'height': 4032, 'width': 3024}   \n3       {'height': 743, 'width': 1110}   \n4      {'height': 2268, 'width': 4032}   \n...                                ...   \n18784  {'height': 3024, 'width': 4032}   \n18785  {'height': 1500, 'width': 2000}   \n18786  {'height': 1080, 'width': 1080}   \n18787  {'height': 1960, 'width': 4032}   \n18788  {'height': 2369, 'width': 2369}   \n\n                                              tagsResult   \n0      {'values': [{'confidence': 0.9876041412353516,...  \\\n1      {'values': [{'confidence': 0.9922141432762146,...   \n2      {'values': [{'confidence': 0.9986068606376648,...   \n3      {'values': [{'confidence': 0.9853595495223999,...   \n4      {'values': [{'confidence': 0.9979767203330994,...   \n...                                                  ...   \n18784  {'values': [{'confidence': 0.9992080926895142,...   \n18785  {'values': [{'confidence': 0.9995888471603394,...   \n18786  {'values': [{'confidence': 0.9758070707321167,...   \n18787  {'values': [{'confidence': 0.9951552152633667,...   \n18788  {'values': [{'confidence': 0.9984121918678284,...   \n\n                                        smartCropsResult   \n0      {'values': [{'aspectRatio': 1.0, 'boundingBox'...  \\\n1      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n2      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n3      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n4      {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n...                                                  ...   \n18784  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18785  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18786  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18787  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n18788  {'values': [{'aspectRatio': 1.0, 'boundingBox'...   \n\n                                            peopleResult       id  \n0      {'values': [{'boundingBox': {'h': 283, 'w': 12...  10006iy  \n1                                         {'values': []}  1000cng  \n2      {'values': [{'boundingBox': {'h': 1824, 'w': 1...  1000hda  \n3      {'values': [{'boundingBox': {'h': 37, 'w': 14,...  1000qpd  \n4      {'values': [{'boundingBox': {'h': 1898, 'w': 8...  1000xd6  \n...                                                  ...      ...  \n18784  {'values': [{'boundingBox': {'h': 76, 'w': 35,...   zzzmli  \n18785                                     {'values': []}   zzzoel  \n18786  {'values': [{'boundingBox': {'h': 17, 'w': 9, ...   zzztxl  \n18787  {'values': [{'boundingBox': {'h': 47, 'w': 31,...   zzzwub  \n18788  {'values': [{'boundingBox': {'h': 215, 'w': 87...   zzzyty  \n\n[18789 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>captionResult</th>\n      <th>objectsResult</th>\n      <th>readResult</th>\n      <th>denseCaptionsResult</th>\n      <th>modelVersion</th>\n      <th>metadata</th>\n      <th>tagsResult</th>\n      <th>smartCropsResult</th>\n      <th>peopleResult</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'confidence': 0.5599533319473267, 'text': 'a ...</td>\n      <td>{'values': [{'boundingBox': {'h': 825, 'w': 14...</td>\n      <td>{'content': 'pepsi\nLite\n000\nAT&amp;T STADIUM', 'mo...</td>\n      <td>{'values': [{'boundingBox': {'h': 311, 'w': 11...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 5068, 'width': 7407}</td>\n      <td>{'values': [{'confidence': 0.9876041412353516,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 283, 'w': 12...</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'confidence': 0.4056971073150635, 'text': 'a ...</td>\n      <td>{'values': []}</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 1768, 'w': 1...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 1800, 'width': 1440}</td>\n      <td>{'values': [{'confidence': 0.9922141432762146,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': []}</td>\n      <td>1000cng</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'confidence': 0.6252590417861938, 'text': 'a ...</td>\n      <td>{'values': [{'boundingBox': {'h': 2233, 'w': 2...</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 1828, 'w': 1...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 4032, 'width': 3024}</td>\n      <td>{'values': [{'confidence': 0.9986068606376648,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 1824, 'w': 1...</td>\n      <td>1000hda</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'confidence': 0.43016329407691956, 'text': 'a...</td>\n      <td>{'values': [{'boundingBox': {'h': 228, 'w': 56...</td>\n      <td>{'content': '@ Adam Woodworth', 'modelVersion'...</td>\n      <td>{'values': [{'boundingBox': {'h': 743, 'w': 11...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 743, 'width': 1110}</td>\n      <td>{'values': [{'confidence': 0.9853595495223999,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 37, 'w': 14,...</td>\n      <td>1000qpd</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'confidence': 0.4159470796585083, 'text': 'a ...</td>\n      <td>{'values': [{'boundingBox': {'h': 1761, 'w': 7...</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 2268, 'w': 4...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 2268, 'width': 4032}</td>\n      <td>{'values': [{'confidence': 0.9979767203330994,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 1898, 'w': 8...</td>\n      <td>1000xd6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18784</th>\n      <td>{'confidence': 0.5420117974281311, 'text': 'du...</td>\n      <td>{'values': []}</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 3024, 'w': 4...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 3024, 'width': 4032}</td>\n      <td>{'values': [{'confidence': 0.9992080926895142,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 76, 'w': 35,...</td>\n      <td>zzzmli</td>\n    </tr>\n    <tr>\n      <th>18785</th>\n      <td>{'confidence': 0.4528125524520874, 'text': 'a ...</td>\n      <td>{'values': []}</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 1500, 'w': 2...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 1500, 'width': 2000}</td>\n      <td>{'values': [{'confidence': 0.9995888471603394,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': []}</td>\n      <td>zzzoel</td>\n    </tr>\n    <tr>\n      <th>18786</th>\n      <td>{'confidence': 0.3901562988758087, 'text': 'a ...</td>\n      <td>{'values': [{'boundingBox': {'h': 595, 'w': 31...</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 346, 'w': 23...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 1080, 'width': 1080}</td>\n      <td>{'values': [{'confidence': 0.9758070707321167,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 17, 'w': 9, ...</td>\n      <td>zzztxl</td>\n    </tr>\n    <tr>\n      <th>18787</th>\n      <td>{'confidence': 0.39278653264045715, 'text': 'a...</td>\n      <td>{'values': []}</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 111, 'w': 10...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 1960, 'width': 4032}</td>\n      <td>{'values': [{'confidence': 0.9951552152633667,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 47, 'w': 31,...</td>\n      <td>zzzwub</td>\n    </tr>\n    <tr>\n      <th>18788</th>\n      <td>{'confidence': 0.6049655079841614, 'text': 'a ...</td>\n      <td>{'values': [{'boundingBox': {'h': 352, 'w': 53...</td>\n      <td>{'content': '', 'modelVersion': '2022-04-30', ...</td>\n      <td>{'values': [{'boundingBox': {'h': 119, 'w': 20...</td>\n      <td>2023-02-01-preview</td>\n      <td>{'height': 2369, 'width': 2369}</td>\n      <td>{'values': [{'confidence': 0.9984121918678284,...</td>\n      <td>{'values': [{'aspectRatio': 1.0, 'boundingBox'...</td>\n      <td>{'values': [{'boundingBox': {'h': 215, 'w': 87...</td>\n      <td>zzzyty</td>\n    </tr>\n  </tbody>\n</table>\n<p>18789 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "            id                                           captions   \n0      10006iy  [{'confidence': 0.5599533319473267, 'text': 'a...  \\\n1      1000cng  [{'confidence': 0.4056971073150635, 'text': 'a...   \n2      1000hda  [{'confidence': 0.6252590417861938, 'text': 'a...   \n3      1000qpd  [{'confidence': 0.43016329407691956, 'text': '...   \n4      1000xd6  [{'confidence': 0.4159470796585083, 'text': 'a...   \n...        ...                                                ...   \n18784   zzzmli  [{'confidence': 0.5420117974281311, 'text': 'd...   \n18785   zzzoel  [{'confidence': 0.4528125524520874, 'text': 'a...   \n18786   zzztxl  [{'confidence': 0.3901562988758087, 'text': 'a...   \n18787   zzzwub  [{'confidence': 0.39278653264045715, 'text': '...   \n18788   zzzyty  [{'confidence': 0.6049655079841614, 'text': 'a...   \n\n                                          dense_captions   \n0      [{'boundingBox': {'h': 311, 'w': 1196, 'x': 12...  \\\n1      [{'boundingBox': {'h': 1768, 'w': 1209, 'x': 1...   \n2      [{'boundingBox': {'h': 1828, 'w': 1186, 'x': 1...   \n3      [{'boundingBox': {'h': 743, 'w': 1110, 'x': 0,...   \n4      [{'boundingBox': {'h': 2268, 'w': 4032, 'x': 0...   \n...                                                  ...   \n18784  [{'boundingBox': {'h': 3024, 'w': 4032, 'x': 0...   \n18785  [{'boundingBox': {'h': 1500, 'w': 2000, 'x': 0...   \n18786  [{'boundingBox': {'h': 346, 'w': 236, 'x': 395...   \n18787  [{'boundingBox': {'h': 111, 'w': 105, 'x': 242...   \n18788  [{'boundingBox': {'h': 119, 'w': 208, 'x': 731...   \n\n                                    meta   \n0      [{'height': 5068, 'width': 7407}]  \\\n1      [{'height': 1800, 'width': 1440}]   \n2      [{'height': 4032, 'width': 3024}]   \n3       [{'height': 743, 'width': 1110}]   \n4      [{'height': 2268, 'width': 4032}]   \n...                                  ...   \n18784  [{'height': 3024, 'width': 4032}]   \n18785  [{'height': 1500, 'width': 2000}]   \n18786  [{'height': 1080, 'width': 1080}]   \n18787  [{'height': 1960, 'width': 4032}]   \n18788  [{'height': 2369, 'width': 2369}]   \n\n                                                    tags   \n0      [{'confidence': 0.9876041412353516, 'name': 'g...  \\\n1      [{'confidence': 0.9922141432762146, 'name': 'b...   \n2      [{'confidence': 0.9986068606376648, 'name': 'f...   \n3      [{'confidence': 0.9853595495223999, 'name': 's...   \n4      [{'confidence': 0.9979767203330994, 'name': 'o...   \n...                                                  ...   \n18784  [{'confidence': 0.9992080926895142, 'name': 'o...   \n18785  [{'confidence': 0.9995888471603394, 'name': 'o...   \n18786  [{'confidence': 0.9758070707321167, 'name': 'f...   \n18787  [{'confidence': 0.9951552152633667, 'name': 'c...   \n18788  [{'confidence': 0.9984121918678284, 'name': 'b...   \n\n                                              smart_crop  \n0      [{'aspectRatio': 1.0, 'boundingBox': {'h': 458...  \n1      [{'aspectRatio': 1.0, 'boundingBox': {'h': 136...  \n2      [{'aspectRatio': 1.0, 'boundingBox': {'h': 280...  \n3      [{'aspectRatio': 1.0, 'boundingBox': {'h': 740...  \n4      [{'aspectRatio': 1.0, 'boundingBox': {'h': 225...  \n...                                                  ...  \n18784  [{'aspectRatio': 1.0, 'boundingBox': {'h': 287...  \n18785  [{'aspectRatio': 1.0, 'boundingBox': {'h': 139...  \n18786  [{'aspectRatio': 1.0, 'boundingBox': {'h': 974...  \n18787  [{'aspectRatio': 1.0, 'boundingBox': {'h': 190...  \n18788  [{'aspectRatio': 1.0, 'boundingBox': {'h': 202...  \n\n[18789 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>captions</th>\n      <th>dense_captions</th>\n      <th>meta</th>\n      <th>tags</th>\n      <th>smart_crop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10006iy</td>\n      <td>[{'confidence': 0.5599533319473267, 'text': 'a...</td>\n      <td>[{'boundingBox': {'h': 311, 'w': 1196, 'x': 12...</td>\n      <td>[{'height': 5068, 'width': 7407}]</td>\n      <td>[{'confidence': 0.9876041412353516, 'name': 'g...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 458...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000cng</td>\n      <td>[{'confidence': 0.4056971073150635, 'text': 'a...</td>\n      <td>[{'boundingBox': {'h': 1768, 'w': 1209, 'x': 1...</td>\n      <td>[{'height': 1800, 'width': 1440}]</td>\n      <td>[{'confidence': 0.9922141432762146, 'name': 'b...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 136...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000hda</td>\n      <td>[{'confidence': 0.6252590417861938, 'text': 'a...</td>\n      <td>[{'boundingBox': {'h': 1828, 'w': 1186, 'x': 1...</td>\n      <td>[{'height': 4032, 'width': 3024}]</td>\n      <td>[{'confidence': 0.9986068606376648, 'name': 'f...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 280...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000qpd</td>\n      <td>[{'confidence': 0.43016329407691956, 'text': '...</td>\n      <td>[{'boundingBox': {'h': 743, 'w': 1110, 'x': 0,...</td>\n      <td>[{'height': 743, 'width': 1110}]</td>\n      <td>[{'confidence': 0.9853595495223999, 'name': 's...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 740...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000xd6</td>\n      <td>[{'confidence': 0.4159470796585083, 'text': 'a...</td>\n      <td>[{'boundingBox': {'h': 2268, 'w': 4032, 'x': 0...</td>\n      <td>[{'height': 2268, 'width': 4032}]</td>\n      <td>[{'confidence': 0.9979767203330994, 'name': 'o...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 225...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18784</th>\n      <td>zzzmli</td>\n      <td>[{'confidence': 0.5420117974281311, 'text': 'd...</td>\n      <td>[{'boundingBox': {'h': 3024, 'w': 4032, 'x': 0...</td>\n      <td>[{'height': 3024, 'width': 4032}]</td>\n      <td>[{'confidence': 0.9992080926895142, 'name': 'o...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 287...</td>\n    </tr>\n    <tr>\n      <th>18785</th>\n      <td>zzzoel</td>\n      <td>[{'confidence': 0.4528125524520874, 'text': 'a...</td>\n      <td>[{'boundingBox': {'h': 1500, 'w': 2000, 'x': 0...</td>\n      <td>[{'height': 1500, 'width': 2000}]</td>\n      <td>[{'confidence': 0.9995888471603394, 'name': 'o...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 139...</td>\n    </tr>\n    <tr>\n      <th>18786</th>\n      <td>zzztxl</td>\n      <td>[{'confidence': 0.3901562988758087, 'text': 'a...</td>\n      <td>[{'boundingBox': {'h': 346, 'w': 236, 'x': 395...</td>\n      <td>[{'height': 1080, 'width': 1080}]</td>\n      <td>[{'confidence': 0.9758070707321167, 'name': 'f...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 974...</td>\n    </tr>\n    <tr>\n      <th>18787</th>\n      <td>zzzwub</td>\n      <td>[{'confidence': 0.39278653264045715, 'text': '...</td>\n      <td>[{'boundingBox': {'h': 111, 'w': 105, 'x': 242...</td>\n      <td>[{'height': 1960, 'width': 4032}]</td>\n      <td>[{'confidence': 0.9951552152633667, 'name': 'c...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 190...</td>\n    </tr>\n    <tr>\n      <th>18788</th>\n      <td>zzzyty</td>\n      <td>[{'confidence': 0.6049655079841614, 'text': 'a...</td>\n      <td>[{'boundingBox': {'h': 119, 'w': 208, 'x': 731...</td>\n      <td>[{'height': 2369, 'width': 2369}]</td>\n      <td>[{'confidence': 0.9984121918678284, 'name': 'b...</td>\n      <td>[{'aspectRatio': 1.0, 'boundingBox': {'h': 202...</td>\n    </tr>\n  </tbody>\n</table>\n<p>18789 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data_from_captions = pandas.read_parquet(\"data/parquet/all_data_from_captions.parquet\", engine='pyarrow',\n",
    "\t\t\t\t\t\t\t\t\t\t\t filesystem=file_system)\n",
    "display(all_data_from_captions)\n",
    "filtered_data_from_captions = pandas.read_parquet(\"data/parquet/filtered_data_from_captions.parquet\", engine='pyarrow',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  filesystem=file_system)\n",
    "display(filtered_data_from_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18789/18789 [00:16<00:00, 1171.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        confidence              name       id\n0         0.987604             grass  10006iy\n1         0.923687           outdoor  10006iy\n2         0.915661   artificial turf  10006iy\n3         0.912514           stadium  10006iy\n4         0.880675  sports equipment  10006iy\n...            ...               ...      ...\n277531    0.903520            yellow   zzzyty\n277532    0.859668              twig   zzzyty\n277533    0.815015              leaf   zzzyty\n277534    0.783504           sitting   zzzyty\n277535    0.588859          wildlife   zzzyty\n\n[277536 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>confidence</th>\n      <th>name</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.987604</td>\n      <td>grass</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.923687</td>\n      <td>outdoor</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.915661</td>\n      <td>artificial turf</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.912514</td>\n      <td>stadium</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.880675</td>\n      <td>sports equipment</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>277531</th>\n      <td>0.903520</td>\n      <td>yellow</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>277532</th>\n      <td>0.859668</td>\n      <td>twig</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>277533</th>\n      <td>0.815015</td>\n      <td>leaf</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>277534</th>\n      <td>0.783504</td>\n      <td>sitting</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>277535</th>\n      <td>0.588859</td>\n      <td>wildlife</td>\n      <td>zzzyty</td>\n    </tr>\n  </tbody>\n</table>\n<p>277536 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.6 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tags = pandas.DataFrame({'id': filtered_data_from_captions.id, 'tags': filtered_data_from_captions.tags})\n",
    "out = []\n",
    "for i, r in tqdm(tags.iterrows(), total=len(tags)):\n",
    "\tif r['tags'] is None:\n",
    "\t\tcontinue\n",
    "\ttag = pandas.json_normalize(r['tags'])\n",
    "\ttag['id'] = r['id']\n",
    "\td = tag.to_dict(orient='records')\n",
    "\tout.extend(d)\n",
    "converted_tags = pandas.DataFrame(data=out)\n",
    "display(converted_tags)\n",
    "converted_tags.to_parquet(\"data/parquet/tags.parquet\", engine='pyarrow', filesystem=file_system)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18789/18789 [00:21<00:00, 884.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        confidence                                      text  boundingBox.h   \n0         0.481536                      a close-up of a sign            311  \\\n1         0.485781                a football helmet on grass           1853   \n2         0.559779  a lizard on a helmet on a football field           5068   \n3         0.519275                        a lizard on a ball            935   \n4         0.660839             a lizard on a football helmet           2190   \n...            ...                                       ...            ...   \n155425    0.459575                     a blurry green object            145   \n155426    0.583457               a close up of a bird's face            184   \n155427    0.628157                      a close-up of a leaf            215   \n155428    0.458817                     a close up of a plant            785   \n155429    0.579009                      a close up of a bird            182   \n\n        boundingBox.w  boundingBox.x  boundingBox.y       id  \n0                1196           1209           1542  10006iy  \n1                7329              0           3068  10006iy  \n2                7407              0              0  10006iy  \n3                1461           2609           2192  10006iy  \n4                2613           2380           2685  10006iy  \n...               ...            ...            ...      ...  \n155425            206           1395            145   zzzyty  \n155426            331            609           1096   zzzyty  \n155427            367           1346           2143   zzzyty  \n155428           1045           1291           1553   zzzyty  \n155429            301            650           1157   zzzyty  \n\n[155430 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>confidence</th>\n      <th>text</th>\n      <th>boundingBox.h</th>\n      <th>boundingBox.w</th>\n      <th>boundingBox.x</th>\n      <th>boundingBox.y</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.481536</td>\n      <td>a close-up of a sign</td>\n      <td>311</td>\n      <td>1196</td>\n      <td>1209</td>\n      <td>1542</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.485781</td>\n      <td>a football helmet on grass</td>\n      <td>1853</td>\n      <td>7329</td>\n      <td>0</td>\n      <td>3068</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.559779</td>\n      <td>a lizard on a helmet on a football field</td>\n      <td>5068</td>\n      <td>7407</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.519275</td>\n      <td>a lizard on a ball</td>\n      <td>935</td>\n      <td>1461</td>\n      <td>2609</td>\n      <td>2192</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.660839</td>\n      <td>a lizard on a football helmet</td>\n      <td>2190</td>\n      <td>2613</td>\n      <td>2380</td>\n      <td>2685</td>\n      <td>10006iy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>155425</th>\n      <td>0.459575</td>\n      <td>a blurry green object</td>\n      <td>145</td>\n      <td>206</td>\n      <td>1395</td>\n      <td>145</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>155426</th>\n      <td>0.583457</td>\n      <td>a close up of a bird's face</td>\n      <td>184</td>\n      <td>331</td>\n      <td>609</td>\n      <td>1096</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>155427</th>\n      <td>0.628157</td>\n      <td>a close-up of a leaf</td>\n      <td>215</td>\n      <td>367</td>\n      <td>1346</td>\n      <td>2143</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>155428</th>\n      <td>0.458817</td>\n      <td>a close up of a plant</td>\n      <td>785</td>\n      <td>1045</td>\n      <td>1291</td>\n      <td>1553</td>\n      <td>zzzyty</td>\n    </tr>\n    <tr>\n      <th>155429</th>\n      <td>0.579009</td>\n      <td>a close up of a bird</td>\n      <td>182</td>\n      <td>301</td>\n      <td>650</td>\n      <td>1157</td>\n      <td>zzzyty</td>\n    </tr>\n  </tbody>\n</table>\n<p>155430 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 21.8 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dense = pandas.DataFrame(\n",
    "\t{'id': filtered_data_from_captions.id, 'dense_captions': filtered_data_from_captions.dense_captions})\n",
    "\n",
    "out = []\n",
    "for i, r in tqdm(dense.iterrows(), total=len(dense)):\n",
    "\tif r['dense_captions'] is None:\n",
    "\t\tcontinue\n",
    "\tdense_caption = pandas.json_normalize(r['dense_captions'])\n",
    "\tdense_caption['id'] = r['id']\n",
    "\td = dense_caption.to_dict(orient='records')\n",
    "\tout.extend(d)\n",
    "\n",
    "converted = pandas.DataFrame(data=out)\n",
    "display(converted)\n",
    "converted.to_parquet(\"data/parquet/dense_captions.parquet\", engine='pyarrow', filesystem=file_system)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'== Updated With Basic Captions =='"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "            id              subreddit                author   \n0      1013bdt               AmIhotAF           RaulDea9286  \\\n1      105mekt               AmIhotAF              lindaniz   \n2      105qvgl               AmIhotAF           CaitVLove11   \n3      105rpcj               AmIhotAF       Flashy-Desk1858   \n4      105styc               AmIhotAF          Gizzygirl127   \n...        ...                    ...                   ...   \n20472  13oersw  AesPleasingAsianGirls               angizni   \n20473  13oxx2r  AesPleasingAsianGirls         theowuriwufoa   \n20474  13qlj64  AesPleasingAsianGirls  throwaway83736365372   \n20475  13qmsn4  AesPleasingAsianGirls          yummybanchan   \n20476  13zq92j            SFWRedheads         Sofia_Red_Fox   \n\n                                                title   \n0                                       36F - ITALIAN  \\\n1      interesting in good forward relationship (f24)   \n2                           Laughing is my favorite ðŸ˜†   \n3            [f22] What do you think when you see me?   \n4                            Low keyâ€¦ still bangable?   \n...                                               ...   \n20472                                         Glitter   \n20473                                    Green outfit   \n20474                                           Habin   \n20475                                      Song Yu Qi   \n20476                     Did I catch your attention?   \n\n                                                 caption   \n0                arafed image of a woman in a bikini top  \\\n1      a close up of a woman with red hair and a whit...   \n2      a woman in a blue tank top and shorts is smili...   \n3        a woman in a blue bikini top and a blue bra top   \n4      smiling woman sitting on couch with remote con...   \n...                                                  ...   \n20472  three women in sequin dresses posing for a pic...   \n20473  araffe woman sitting on a couch in a green outfit   \n20474   araffe woman in a pink bikini standing in a pool   \n20475  there is a woman with a bouquet of flowers in ...   \n20476  arafed woman with long red hair posing for a p...   \n\n                                   hash   \n0      7c0d158cba8654ef1c635cbc5471d597  \\\n1      ba4a0962cca2266a741e1e1700589c04   \n2      27bfe82c37314a0bcf02ab72eaf3a9e5   \n3      329eb42b8267fa1cc2980da8e48bcef1   \n4      6d555943be4fbc21ff92417c6f582298   \n...                                 ...   \n20472  cbd83e4de946b42ce318e93d14d78776   \n20473  aa460440886847369e59fa8ac2b91f2b   \n20474  e1244a45a5018d6d35e487217a489db2   \n20475  a2189d7026d58082336ddcad3667161e   \n20476  6eb93984fae6a72846fcd6322d3d0c91   \n\n                                               permalink   \n0              /r/AmIhotAF/comments/1013bdt/36f_italian/  \\\n1      /r/AmIhotAF/comments/105mekt/interesting_in_go...   \n2      /r/AmIhotAF/comments/105qvgl/laughing_is_my_fa...   \n3      /r/AmIhotAF/comments/105rpcj/f22_what_do_you_t...   \n4      /r/AmIhotAF/comments/105styc/low_key_still_ban...   \n...                                                  ...   \n20472  /r/AesPleasingAsianGirls/comments/13oersw/glit...   \n20473  /r/AesPleasingAsianGirls/comments/13oxx2r/gree...   \n20474   /r/AesPleasingAsianGirls/comments/13qlj64/habin/   \n20475  /r/AesPleasingAsianGirls/comments/13qmsn4/song...   \n20476  /r/SFWRedheads/comments/13zq92j/did_i_catch_yo...   \n\n                              original_url   image_name   \n0      https://i.redd.it/bg0wwdlt5k9a1.jpg  1013bdt.jpg  \\\n1      https://i.redd.it/4avjshsz8naa1.jpg  105mekt.jpg   \n2      https://i.redd.it/2pulzr0lxmaa1.jpg  105qvgl.jpg   \n3      https://i.redd.it/rz68pf934naa1.jpg  105rpcj.jpg   \n4      https://i.redd.it/aiaxxoz9uoaa1.jpg  105styc.jpg   \n...                                    ...          ...   \n20472  https://i.redd.it/zvr3dt5occ1b1.jpg  13oersw.jpg   \n20473  https://i.redd.it/vvy28ulupg1b1.jpg  13oxx2r.jpg   \n20474  https://i.redd.it/29soeuf3nt1b1.jpg  13qlj64.jpg   \n20475  https://i.redd.it/cdj3scvnvt1b1.jpg  13qmsn4.jpg   \n20476  https://i.redd.it/f74fbalefv3b1.jpg  13zq92j.jpg   \n\n                         path  ... exists  curated  accept   \n0      data/image/1013bdt.jpg  ...   True     True    True  \\\n1      data/image/105mekt.jpg  ...   True     True    True   \n2      data/image/105qvgl.jpg  ...   True     True    True   \n3      data/image/105rpcj.jpg  ...   True     True    True   \n4      data/image/105styc.jpg  ...   True     True    True   \n...                       ...  ...    ...      ...     ...   \n20472  data/image/13oersw.jpg  ...   True     True    True   \n20473  data/image/13oxx2r.jpg  ...   True     True    True   \n20474  data/image/13qlj64.jpg  ...   True     True    True   \n20475  data/image/13qmsn4.jpg  ...   True     True    True   \n20476  data/image/13zq92j.jpg  ...   True     True    True   \n\n                                                    tags   \n0      [person, human face, clothing, lady, smile, ch...  \\\n1      [person, human face, skin, eyelash, eyebrow, b...   \n2      [clothing, person, human face, smile, shoulder...   \n3      [person, human face, indoor, clothing, woman, ...   \n4      [person, human face, smile, clothing, woman, i...   \n...                                                  ...   \n20472                                                 []   \n20473                                                 []   \n20474                                                 []   \n20475                                                 []   \n20476                                                 []   \n\n                   azure_caption thumbnail_path thumbnail_exists   \n0        a woman taking a selfie                           False  \\\n1        a woman taking a selfie                           False   \n2      a woman smiling at camera                           False   \n3        a woman taking a selfie                           False   \n4        a woman taking a selfie                           False   \n...                          ...            ...              ...   \n20472                                                      False   \n20473                                                      False   \n20474                                                      False   \n20475                                                      False   \n20476                                                      False   \n\n      thumbnail_curated thumbnail_accept additional_captions  \n0                 False            False                      \n1                 False            False                  []  \n2                 False            False                  []  \n3                 False            False                  []  \n4                 False            False                  []  \n...                 ...              ...                 ...  \n20472             False            False                  []  \n20473             False            False                  []  \n20474             False            False                  []  \n20475             False            False                  []  \n20476             False            False                  []  \n\n[20477 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>subreddit</th>\n      <th>author</th>\n      <th>title</th>\n      <th>caption</th>\n      <th>hash</th>\n      <th>permalink</th>\n      <th>original_url</th>\n      <th>image_name</th>\n      <th>path</th>\n      <th>...</th>\n      <th>exists</th>\n      <th>curated</th>\n      <th>accept</th>\n      <th>tags</th>\n      <th>azure_caption</th>\n      <th>thumbnail_path</th>\n      <th>thumbnail_exists</th>\n      <th>thumbnail_curated</th>\n      <th>thumbnail_accept</th>\n      <th>additional_captions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1013bdt</td>\n      <td>AmIhotAF</td>\n      <td>RaulDea9286</td>\n      <td>36F - ITALIAN</td>\n      <td>arafed image of a woman in a bikini top</td>\n      <td>7c0d158cba8654ef1c635cbc5471d597</td>\n      <td>/r/AmIhotAF/comments/1013bdt/36f_italian/</td>\n      <td>https://i.redd.it/bg0wwdlt5k9a1.jpg</td>\n      <td>1013bdt.jpg</td>\n      <td>data/image/1013bdt.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[person, human face, clothing, lady, smile, ch...</td>\n      <td>a woman taking a selfie</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>105mekt</td>\n      <td>AmIhotAF</td>\n      <td>lindaniz</td>\n      <td>interesting in good forward relationship (f24)</td>\n      <td>a close up of a woman with red hair and a whit...</td>\n      <td>ba4a0962cca2266a741e1e1700589c04</td>\n      <td>/r/AmIhotAF/comments/105mekt/interesting_in_go...</td>\n      <td>https://i.redd.it/4avjshsz8naa1.jpg</td>\n      <td>105mekt.jpg</td>\n      <td>data/image/105mekt.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[person, human face, skin, eyelash, eyebrow, b...</td>\n      <td>a woman taking a selfie</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>105qvgl</td>\n      <td>AmIhotAF</td>\n      <td>CaitVLove11</td>\n      <td>Laughing is my favorite ðŸ˜†</td>\n      <td>a woman in a blue tank top and shorts is smili...</td>\n      <td>27bfe82c37314a0bcf02ab72eaf3a9e5</td>\n      <td>/r/AmIhotAF/comments/105qvgl/laughing_is_my_fa...</td>\n      <td>https://i.redd.it/2pulzr0lxmaa1.jpg</td>\n      <td>105qvgl.jpg</td>\n      <td>data/image/105qvgl.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[clothing, person, human face, smile, shoulder...</td>\n      <td>a woman smiling at camera</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105rpcj</td>\n      <td>AmIhotAF</td>\n      <td>Flashy-Desk1858</td>\n      <td>[f22] What do you think when you see me?</td>\n      <td>a woman in a blue bikini top and a blue bra top</td>\n      <td>329eb42b8267fa1cc2980da8e48bcef1</td>\n      <td>/r/AmIhotAF/comments/105rpcj/f22_what_do_you_t...</td>\n      <td>https://i.redd.it/rz68pf934naa1.jpg</td>\n      <td>105rpcj.jpg</td>\n      <td>data/image/105rpcj.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[person, human face, indoor, clothing, woman, ...</td>\n      <td>a woman taking a selfie</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>105styc</td>\n      <td>AmIhotAF</td>\n      <td>Gizzygirl127</td>\n      <td>Low keyâ€¦ still bangable?</td>\n      <td>smiling woman sitting on couch with remote con...</td>\n      <td>6d555943be4fbc21ff92417c6f582298</td>\n      <td>/r/AmIhotAF/comments/105styc/low_key_still_ban...</td>\n      <td>https://i.redd.it/aiaxxoz9uoaa1.jpg</td>\n      <td>105styc.jpg</td>\n      <td>data/image/105styc.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[person, human face, smile, clothing, woman, i...</td>\n      <td>a woman taking a selfie</td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20472</th>\n      <td>13oersw</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>angizni</td>\n      <td>Glitter</td>\n      <td>three women in sequin dresses posing for a pic...</td>\n      <td>cbd83e4de946b42ce318e93d14d78776</td>\n      <td>/r/AesPleasingAsianGirls/comments/13oersw/glit...</td>\n      <td>https://i.redd.it/zvr3dt5occ1b1.jpg</td>\n      <td>13oersw.jpg</td>\n      <td>data/image/13oersw.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n      <td></td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20473</th>\n      <td>13oxx2r</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>theowuriwufoa</td>\n      <td>Green outfit</td>\n      <td>araffe woman sitting on a couch in a green outfit</td>\n      <td>aa460440886847369e59fa8ac2b91f2b</td>\n      <td>/r/AesPleasingAsianGirls/comments/13oxx2r/gree...</td>\n      <td>https://i.redd.it/vvy28ulupg1b1.jpg</td>\n      <td>13oxx2r.jpg</td>\n      <td>data/image/13oxx2r.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n      <td></td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20474</th>\n      <td>13qlj64</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>throwaway83736365372</td>\n      <td>Habin</td>\n      <td>araffe woman in a pink bikini standing in a pool</td>\n      <td>e1244a45a5018d6d35e487217a489db2</td>\n      <td>/r/AesPleasingAsianGirls/comments/13qlj64/habin/</td>\n      <td>https://i.redd.it/29soeuf3nt1b1.jpg</td>\n      <td>13qlj64.jpg</td>\n      <td>data/image/13qlj64.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n      <td></td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20475</th>\n      <td>13qmsn4</td>\n      <td>AesPleasingAsianGirls</td>\n      <td>yummybanchan</td>\n      <td>Song Yu Qi</td>\n      <td>there is a woman with a bouquet of flowers in ...</td>\n      <td>a2189d7026d58082336ddcad3667161e</td>\n      <td>/r/AesPleasingAsianGirls/comments/13qmsn4/song...</td>\n      <td>https://i.redd.it/cdj3scvnvt1b1.jpg</td>\n      <td>13qmsn4.jpg</td>\n      <td>data/image/13qmsn4.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n      <td></td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>20476</th>\n      <td>13zq92j</td>\n      <td>SFWRedheads</td>\n      <td>Sofia_Red_Fox</td>\n      <td>Did I catch your attention?</td>\n      <td>arafed woman with long red hair posing for a p...</td>\n      <td>6eb93984fae6a72846fcd6322d3d0c91</td>\n      <td>/r/SFWRedheads/comments/13zq92j/did_i_catch_yo...</td>\n      <td>https://i.redd.it/f74fbalefv3b1.jpg</td>\n      <td>13zq92j.jpg</td>\n      <td>data/image/13zq92j.jpg</td>\n      <td>...</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n      <td></td>\n      <td></td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>20477 rows Ã— 21 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# single_caption_data = pandas.DataFrame(\n",
    "# \t{\n",
    "# \t\t'id': all_data_from_captions['id'],\n",
    "# \t\t'azure_caption': [item['text'] for item in all_data_from_captions['captionResult']],\n",
    "# \t\t'tags': [[foo['name'] for foo in item['values']] for item in all_data_from_captions['tagsResult']]\n",
    "# \t})\n",
    "#\n",
    "#\n",
    "# single_caption_data_indexed = single_caption_data.set_index(\"id\")\n",
    "#\n",
    "# accepted_indexed = accepted.set_index(\"id\")\n",
    "#\n",
    "# for index, row in accepted_indexed.iterrows():\n",
    "# \taccepted_indexed.at[index, 'azure_caption'] = \"\"\n",
    "# \taccepted_indexed.at[index, 'thumbnail_path'] = \"\"\n",
    "# \taccepted_indexed.at[index, 'thumbnail_exists'] = False\n",
    "# \taccepted_indexed.at[index, 'thumbnail_curated'] = False\n",
    "# \taccepted_indexed.at[index, 'thumbnail_accept'] = False\n",
    "#\taccepted_indexed.at[index, 'additional_captions'] = ['']\n",
    "#\n",
    "# accepted_indexed.update(single_caption_data_indexed)\n",
    "#\n",
    "# accepted_final = accepted_indexed.reset_index()\n",
    "#\n",
    "# display(\"== Updated With Basic Captions ==\")\n",
    "# display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43maccepted_final\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_parquet\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/parquet/curation_2.parquet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpyarrow\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfile_system\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtagging_schema\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m accepted_final\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\pandas\\core\\frame.py:2889\u001B[0m, in \u001B[0;36mDataFrame.to_parquet\u001B[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001B[0m\n\u001B[0;32m   2802\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2803\u001B[0m \u001B[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001B[39;00m\n\u001B[0;32m   2804\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2885\u001B[0m \u001B[38;5;124;03m>>> content = f.read()\u001B[39;00m\n\u001B[0;32m   2886\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2887\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparquet\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_parquet\n\u001B[1;32m-> 2889\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m to_parquet(\n\u001B[0;32m   2890\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   2891\u001B[0m     path,\n\u001B[0;32m   2892\u001B[0m     engine,\n\u001B[0;32m   2893\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[0;32m   2894\u001B[0m     index\u001B[38;5;241m=\u001B[39mindex,\n\u001B[0;32m   2895\u001B[0m     partition_cols\u001B[38;5;241m=\u001B[39mpartition_cols,\n\u001B[0;32m   2896\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m   2897\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2898\u001B[0m )\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:411\u001B[0m, in \u001B[0;36mto_parquet\u001B[1;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001B[0m\n\u001B[0;32m    407\u001B[0m impl \u001B[38;5;241m=\u001B[39m get_engine(engine)\n\u001B[0;32m    409\u001B[0m path_or_buf: FilePath \u001B[38;5;241m|\u001B[39m WriteBuffer[\u001B[38;5;28mbytes\u001B[39m] \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mBytesIO() \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m path\n\u001B[1;32m--> 411\u001B[0m impl\u001B[38;5;241m.\u001B[39mwrite(\n\u001B[0;32m    412\u001B[0m     df,\n\u001B[0;32m    413\u001B[0m     path_or_buf,\n\u001B[0;32m    414\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[0;32m    415\u001B[0m     index\u001B[38;5;241m=\u001B[39mindex,\n\u001B[0;32m    416\u001B[0m     partition_cols\u001B[38;5;241m=\u001B[39mpartition_cols,\n\u001B[0;32m    417\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    419\u001B[0m )\n\u001B[0;32m    421\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    422\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, io\u001B[38;5;241m.\u001B[39mBytesIO)\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:189\u001B[0m, in \u001B[0;36mPyArrowImpl.write\u001B[1;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001B[0m\n\u001B[0;32m    180\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mparquet\u001B[38;5;241m.\u001B[39mwrite_to_dataset(\n\u001B[0;32m    181\u001B[0m             table,\n\u001B[0;32m    182\u001B[0m             path_or_handle,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    185\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    186\u001B[0m         )\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    188\u001B[0m         \u001B[38;5;66;03m# write to single output file\u001B[39;00m\n\u001B[1;32m--> 189\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mparquet\u001B[38;5;241m.\u001B[39mwrite_table(\n\u001B[0;32m    190\u001B[0m             table, path_or_handle, compression\u001B[38;5;241m=\u001B[39mcompression, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    191\u001B[0m         )\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    193\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m handles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\pyarrow\\parquet\\core.py:3106\u001B[0m, in \u001B[0;36mwrite_table\u001B[1;34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, **kwargs)\u001B[0m\n\u001B[0;32m   3083\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   3084\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ParquetWriter(\n\u001B[0;32m   3085\u001B[0m             where, table\u001B[38;5;241m.\u001B[39mschema,\n\u001B[0;32m   3086\u001B[0m             filesystem\u001B[38;5;241m=\u001B[39mfilesystem,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3104\u001B[0m             store_schema\u001B[38;5;241m=\u001B[39mstore_schema,\n\u001B[0;32m   3105\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mas\u001B[39;00m writer:\n\u001B[1;32m-> 3106\u001B[0m         writer\u001B[38;5;241m.\u001B[39mwrite_table(table, row_group_size\u001B[38;5;241m=\u001B[39mrow_group_size)\n\u001B[0;32m   3107\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   3108\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path_like(where):\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\pyarrow\\parquet\\core.py:1029\u001B[0m, in \u001B[0;36mParquetWriter.__exit__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__exit__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 1029\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1030\u001B[0m     \u001B[38;5;66;03m# return false since we want to propagate exceptions\u001B[39;00m\n\u001B[0;32m   1031\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\pyarrow\\parquet\\core.py:1104\u001B[0m, in \u001B[0;36mParquetWriter.close\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1102\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata_collector\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter\u001B[38;5;241m.\u001B[39mmetadata)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1104\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile_handle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\pyarrow\\io.pxi:189\u001B[0m, in \u001B[0;36mpyarrow.lib.NativeFile.close\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\adlfs\\spec.py:1908\u001B[0m, in \u001B[0;36mAzureBlobFile.close\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1906\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Close file and azure client.\"\"\"\u001B[39;00m\n\u001B[0;32m   1907\u001B[0m asyncio\u001B[38;5;241m.\u001B[39mrun_coroutine_threadsafe(close_container_client(\u001B[38;5;28mself\u001B[39m), loop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloop)\n\u001B[1;32m-> 1908\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\fsspec\\spec.py:1789\u001B[0m, in \u001B[0;36mAbstractBufferedFile.close\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1787\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1788\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforced:\n\u001B[1;32m-> 1789\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflush\u001B[49m\u001B[43m(\u001B[49m\u001B[43mforce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1791\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1792\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39minvalidate_cache(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath)\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\fsspec\\spec.py:1660\u001B[0m, in \u001B[0;36mAbstractBufferedFile.flush\u001B[1;34m(self, force)\u001B[0m\n\u001B[0;32m   1657\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclosed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1658\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1660\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_upload_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfinal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m   1661\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moffset \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m   1662\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mBytesIO()\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\fsspec\\asyn.py:115\u001B[0m, in \u001B[0;36msync_wrapper.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m obj \u001B[38;5;129;01mor\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m sync(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloop, func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\code\\repos\\simple-collection\\venv\\lib\\site-packages\\fsspec\\asyn.py:88\u001B[0m, in \u001B[0;36msync\u001B[1;34m(loop, func, timeout, *args, **kwargs)\u001B[0m\n\u001B[0;32m     85\u001B[0m asyncio\u001B[38;5;241m.\u001B[39mrun_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# this loops allows thread to get interrupted\u001B[39;00m\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mevent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     89\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m     90\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:574\u001B[0m, in \u001B[0;36mEvent.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    572\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[1;32m--> 574\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:316\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 316\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    318\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# accepted_final.to_parquet(\"data/parquet/curation_2.parquet\", engine='pyarrow', filesystem=file_system, schema=tagging_schema)\n",
    "# del accepted_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accepted_final = pandas.read_parquet(\"data/parquet/curation_2.parquet\", engine='pyarrow', filesystem=file_system,\n",
    "\t\t\t\t\t\t\t\t\t schema=tagging_schema)\n",
    "display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_aspect_ratio(x: object):\n",
    "\treturn x['crops'][0]['aspectRatio']\n",
    "\n",
    "\n",
    "def get_bounding_box(x: object):\n",
    "\treturn x['crops'][0]['boundingBox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropping = pandas.DataFrame(\n",
    "\t{'id': filtered_data_from_captions['id'], 'crops': filtered_data_from_captions['smart_crop']}).set_index('id',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t drop=False)\n",
    "\n",
    "cropping['aspectRatio'] = cropping.progress_apply(lambda x: get_aspect_ratio(x), axis=1)\n",
    "cropping['bounding_box'] = cropping.progress_apply(lambda x: get_bounding_box(x), axis=1)\n",
    "cropping['x'] = cropping.progress_apply(lambda x: x['bounding_box']['x'], axis=1)\n",
    "cropping['y'] = cropping.progress_apply(lambda x: x['bounding_box']['y'], axis=1)\n",
    "cropping['w'] = cropping.progress_apply(lambda x: x['bounding_box']['w'], axis=1)\n",
    "cropping['h'] = cropping.progress_apply(lambda x: x['bounding_box']['h'], axis=1)\n",
    "\n",
    "display(cropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thumbnail(target_image_id: str, file_names: list, crops: pandas.DataFrame, curated_data: pandas.DataFrame):\n",
    "\t_file_system: AzureBlobFileSystem = AzureFileStorageAdapter('data').get_file_storage()\n",
    "\n",
    "\tout_path = f\"data/image/thumbnail/{target_image_id}.jpg\"\n",
    "\ttry:\n",
    "\t\tif target_image_id is None or out_path in file_names:\n",
    "\t\t\t# print(f'Image {target_image_id} already exists, skipping')\n",
    "\t\t\treturn out_path\n",
    "\n",
    "\t\tcropping_information = cropping.loc[crops['id'] == target_image_id]\n",
    "\t\tif cropping_information is None or len(cropping_information) == 0:\n",
    "\t\t\t# print(f'No cropping information for {target_image_id}, skipping')\n",
    "\t\t\treturn \"/data/nope\"\n",
    "\n",
    "\t\trecord = curated_data.loc[curated_data['id'] == target_image_id]\n",
    "\t\trecord_path = record.to_dict(orient='records')[0]['path']\n",
    "\t\timage_url = file_system.url(record_path)\n",
    "\t\toriginal_image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\t\tcopied_image = original_image.copy()\n",
    "\t\toriginal_image.close()\n",
    "\n",
    "\t\tcropped = copied_image.crop((cropping_information['x'].values[0],\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['y'].values[0],\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['x'].values[0] +\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['w'].values[0],\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['y'].values[0] +\n",
    "\t\t\t\t\t\t\t\t\t cropping_information['h'].values[0]))\n",
    "\t\tcopied_image.close()\n",
    "\n",
    "\t\tresized = cropped.resize((512, 512), 1)\n",
    "\t\tresized.save('temp.jpg')\n",
    "\t\tresized.close()\n",
    "\t\tfile_system.upload('temp.jpg', out_path, overwrite=True)\n",
    "\t\tprint(f'Thumbnail created for {target_image_id}')\n",
    "\t\treturn out_path\n",
    "\n",
    "\texcept Exception as ex:\n",
    "\t\tprint(f'Error creating thumbnail for {target_image_id}: {ex}')\n",
    "\t\treturn \"/data/nope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = file_system.ls('data/image/thumbnail')\n",
    "\n",
    "accepted_final['thumbnail_path'] = accepted_final.progress_apply(\n",
    "\tlambda x: create_thumbnail(x['id'], file_names, cropping, accepted_final), axis=1)\n",
    "\n",
    "display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accepted_final['thumbnail_exists'] = accepted_final.progress_apply(lambda x: file_system.exists(x['thumbnail_path']),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   axis=1)\n",
    "\n",
    "display(accepted_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "accepted_copy = accepted_final.copy()\n",
    "\n",
    "accepted_copy['additional_captions'] = accepted_copy.progress_apply(lambda x: [], axis=1)\n",
    "\n",
    "accepted_slice = accepted_copy.loc[accepted_copy['thumbnail_exists'] == True, tagging_schema.names]\n",
    "\n",
    "accepted_slice.dropna(inplace=True)\n",
    "\n",
    "accepted_slice.reset_index(inplace=True, drop=True)\n",
    "\n",
    "display(accepted_slice)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: Only update the this accepted slice if there are new captions, we don't want to overwrite the curated data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_system.cp('data/parquet/thumbnail_curation.parquet', 'data/parquet/thumbnail_curation.parquet.bak')\n",
    "\n",
    "# accepted_slice.to_parquet(\"data/parquet/thumbnail_curation.parquet\", engine='pyarrow', filesystem=file_system, schema=tagging_schema)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(accepted_slice)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title Initalize Helpers\n",
    "\n",
    "%%time\n",
    "\n",
    "class Functions:\n",
    "\tdef get_hash_from_path(self, in_path: str):\n",
    "\t\tif os.path.exists(in_path):\n",
    "\t\t\twith open(in_path, 'rb') as f_:\n",
    "\t\t\t\tcontent = f_.read()\n",
    "\t\t\t\tresult = hashlib.md5(content).hexdigest()\n",
    "\t\t\t\treturn result, content\n",
    "\t\telse:\n",
    "\t\t\treturn \"\"\n",
    "\n",
    "\tdef fetch_image(self, x: object, file_list__, file_system) -> object:\n",
    "\n",
    "\ttry:\n",
    "\t\turl = x['original_url']\n",
    "\t\tsubreddit = x['subreddit']\n",
    "\t\timage_id = x['id']\n",
    "\t\tos.makedirs(f\"temp\\\\image\\\\{subreddit}\", exist_ok=True)\n",
    "\t\ttemp_path = f\"temp\\\\image\\\\{subreddit}\\\\{image_id}.jpg\"\n",
    "\t\tout_path = f\"data/image/{image_id}.jpg\"\n",
    "\t\tif os.path.exists(temp_path):\n",
    "\t\t\tmd5, content = self.get_hash_from_path(temp_path)\n",
    "\t\t\tif md5 != \"f17b01901c752c1bb04928131d1661af\" or md5 != \"d835884373f4d6c8f24742ceabe74946\":\n",
    "\t\t\t\tif out_path in file_list__:\n",
    "\t\t\t\t\treturn out_path\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfile_system.upload(temp_path, out_path, overwrite=True)\n",
    "\t\t\t\t\treturn out_path\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn \"\"\n",
    "\t\telse:\n",
    "\t\t\tresponse = requests.get(url)\n",
    "\t\t\tmd5 = hashlib.md5(response.content).hexdigest()\n",
    "\t\t\tif md5 != \"f17b01901c752c1bb04928131d1661af\" or md5 != \"d835884373f4d6c8f24742ceabe74946\":\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\traw_image = Image.open(BytesIO(response.content))\n",
    "\t\t\t\t\traw_image.save(temp_path)\n",
    "\t\t\t\t\traw_image.close()\n",
    "\t\t\t\t\tif out_path in file_list__:\n",
    "\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfile_system.upload(temp_path, out_path)\n",
    "\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\texcept Exception as ex:\n",
    "\t\t\t\t\tmessage = self.write_log_message(x['id'], x['subreddit'], \"Failure in fetch_image\", ex)\n",
    "\t\t\t\t\tdisplay(message, clear=True)\n",
    "\t\t\t\t\treturn \"\"\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn \"\"\n",
    "\texcept Exception as ex:\n",
    "\t\tmessage = self.write_log_message(x['id'], x['subreddit'], \"Failure in fetch_image\", ex)\n",
    "\t\tdisplay(message, clear=True)\n",
    "\t\treturn \"\"\n",
    "\n",
    "\tdef get_name_for_image(self, x: object, file_list__) -> str:\n",
    "\t\tpath = x['path']\n",
    "\t\tif path != \"\" and path in file_list__:\n",
    "\t\t\treturn os.path.basename(path)\n",
    "\t\telse:\n",
    "\t\t\treturn \"\"\n",
    "\n",
    "\tdef set_exists(self, x: object) -> bool:\n",
    "\t\ttry:\n",
    "\t\t\tsub_reddit = x['subreddit']\n",
    "\t\t\trecord_id = x['id']\n",
    "\t\t\ttemp_path = f\"temp\\\\image\\\\{sub_reddit}\\\\{record_id}.jpg\"\n",
    "\t\t\treturn os.path.exists(temp_path)\n",
    "\t\texcept Exception as ex:\n",
    "\t\t\treturn False\n",
    "\n",
    "\tdef set_hash(self, x: object):\n",
    "\t\tsub_reddit = x['subreddit']\n",
    "\t\trecord_id = x['id']\n",
    "\t\ttemp_path = f\"temp\\\\image\\\\{sub_reddit}\\\\{record_id}.jpg\"\n",
    "\t\tif os.path.exists(temp_path):\n",
    "\t\t\treturn hashlib.md5(open(temp_path, 'rb').read()).hexdigest()\n",
    "\t\telse:\n",
    "\t\t\treturn \"\"\n",
    "\n",
    "\tdef add_source(self, x: object, source_list) -> str:\n",
    "\t\tsub_reddit = x['subreddit']\n",
    "\t\tfor source in source_list:\n",
    "\t\t\tdata_source = source['data']\n",
    "\t\t\tsource_name = source['name']\n",
    "\t\t\tif sub_reddit in data_source:\n",
    "\t\t\t\treturn source_name\n",
    "\t\treturn \"\"\n",
    "\n",
    "\tdef write_log_message(self, submission_id: str, subreddit: str, message: str, exception: Exception) -> str:\n",
    "\t\tdate_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\t\treturn f\"{date_time}\\t{subreddit}\\t{submission_id}\\t{message}\\t{exception}\\n\"\n",
    "\n",
    "\tdef apply_caption(self, x: object, caption_routine: list[BlipCaption]) -> str:\n",
    "\t\texists = x['exists']\n",
    "\t\tif not exists:\n",
    "\t\t\treturn \"\"\n",
    "\t\tsub_reddit = x['subreddit']\n",
    "\t\trecord_id = x['id']\n",
    "\t\tos.makedirs(f\"temp\\\\image\\\\{sub_reddit}\\\\\", exist_ok=True)\n",
    "\t\ttemp_path = f\"temp\\\\image\\\\{sub_reddit}\\\\{record_id}.jpg\"\n",
    "\n",
    "\t\tif os.path.exists(temp_path):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tresult = random.choice(caption_routine).caption_image(temp_path)\n",
    "\t\t\t\treturn result\n",
    "\t\t\texcept Exception as ex:\n",
    "\t\t\t\tmessage = self.write_log_message(x['id'], x['subreddit'], \"Failure in apply_caption\", ex)\n",
    "\t\t\t\tdisplay(message, clear=True)\n",
    "\t\t\t\treturn \"\"\n",
    "\t\telse:\n",
    "\t\t\tmessage = self.write_log_message(x['id'], x['subreddit'], f\"Image not found in {temp_path}\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t Exception(\"No image\"))\n",
    "\t\t\tdisplay(message, clear=True)\n",
    "\t\t\treturn \"\"\n",
    "\n",
    "\tdef fix_path(self, x: object, fl: []) -> str:\n",
    "\t\tcurrent_path = x['path']\n",
    "\t\texists = x['exists']\n",
    "\t\tif current_path in fl:\n",
    "\t\t\treturn current_path\n",
    "\t\telse:\n",
    "\t\t\timage_id = x['id']\n",
    "\t\t\tif exists:\n",
    "\t\t\t\treturn f\"data/image/{image_id}.jpg\"\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn \"\"\n",
    "\t\tcurrent_path = x['path']\n",
    "\t\texists = x['exists']\n",
    "\t\tif current_path in fl:\n",
    "\t\t\treturn current_path\n",
    "\t\telse:\n",
    "\t\t\timage_id = x['id']\n",
    "\t\t\tif exists:\n",
    "\t\t\t\treturn f\"data/image/{image_id}.jpg\"\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn \"\"\n",
    "\n",
    "\n",
    "class AzureFileStorageAdapter(object):\n",
    "\tdef __init__(self, container_name: str = \"data\"):\n",
    "\t\tself.__account_name: str = os.environ[\"AZURE_STORAGE_ACCOUNT_NAME\"]\n",
    "\t\tself.__account_key: str = os.environ[\"AZURE_STORAGE_ACCOUNT_KEY\"]\n",
    "\t\tself.container_name: str = container_name\n",
    "\n",
    "\tdef get_file_storage(self) -> AzureBlobFileSystem:\n",
    "\t\treturn AzureBlobFileSystem(\n",
    "\t\t\taccount_name=self.__account_name,\n",
    "\t\t\taccount_key=self.__account_key,\n",
    "\t\t\tcontainer_name=self.container_name)\n",
    "\n",
    "\tdef get_file_storage_root(self) -> AzureBlobFileSystem:\n",
    "\t\treturn AzureBlobFileSystem(account_name=self.__account_name, account_key=self.__account_key,\n",
    "\t\t\t\t\t\t\t\t   container_name=self.container_name)\n",
    "\n",
    "\n",
    "schema = pyarrow.schema(\n",
    "\t[\n",
    "\t\tpyarrow.field(\"id\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"subreddit\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"author\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"title\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"caption\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"hash\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"permalink\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"original_url\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"image_name\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"path\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"model\", pyarrow.string()),\n",
    "\t\tpyarrow.field(\"exists\", pyarrow.bool_()),\n",
    "\t\tpyarrow.field(\"curated\", pyarrow.bool_()),\n",
    "\t\tpyarrow.field(\"accept\", pyarrow.bool_()),\n",
    "\t\tpyarrow.field(\"tags\", pyarrow.list_(pyarrow.string()))\n",
    "\t]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\tdef fetch_image(self, x: object, file_list__, file_system__) -> object:\n",
    "\t\ttry:\n",
    "\t\t\turl = x['original_url']\n",
    "\t\t\tsubreddit = x['subreddit']\n",
    "\t\t\timage_id = x['id']\n",
    "\t\t\tos.makedirs(f\"temp/image/{subreddit}\", exist_ok=True)\n",
    "\t\t\ttemp_path = f\"temp/image/{subreddit}/{image_id}.jpg\"\n",
    "\t\t\tout_path = f\"data/image/{image_id}.jpg\"\n",
    "\t\t\tif os.path.exists(temp_path):\n",
    "\t\t\t\tmd5, content = self.get_hash_from_path(temp_path)\n",
    "\t\t\t\tif md5 != \"f17b01901c752c1bb04928131d1661af\" or md5 != \"d835884373f4d6c8f24742ceabe74946\":\n",
    "\t\t\t\t\tif out_path in file_list__:\n",
    "\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tfile_system.upload(temp_path, out_path, overwrite=True)\n",
    "\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn \"\"\n",
    "\t\t\telse:\n",
    "\t\t\t\tresponse = requests.get(url)\n",
    "\t\t\t\tmd5 = hashlib.md5(response.content).hexdigest()\n",
    "\t\t\t\tif md5 != \"f17b01901c752c1bb04928131d1661af\" or md5 != \"d835884373f4d6c8f24742ceabe74946\":\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\traw_image = Image.open(BytesIO(response.content))\n",
    "\t\t\t\t\t\traw_image.save(temp_path)\n",
    "\t\t\t\t\t\traw_image.close()\n",
    "\t\t\t\t\t\tif out_path in file_list__:\n",
    "\t\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tfile_system__.upload(temp_path, out_path)\n",
    "\t\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\t\texcept Exception as ex:\n",
    "\t\t\t\t\t\tmessage = f\"{x['id']}, {x['subreddit']}, Failure in fetch_image, {ex}\"\n",
    "\t\t\t\t\t\tdisplay(message, clear=True)\n",
    "\t\t\t\t\t\treturn \"\"\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn \"\"\n",
    "\t\texcept Exception as ex:\n",
    "\t\t\tmessage = f\"{x['id']}, {x['subreddit']}, Failure in fetch_image, {ex}\"\n",
    "\t\t\tdisplay(message, clear=True)\n",
    "\t\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
