{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-07T12:16:58.165110300Z",
     "start_time": "2023-05-07T12:16:56.581363700Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import pandas\n",
    "from dask.diagnostics import ProgressBar\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.schemas.pyarrow_schema import schema\n",
    "\n",
    "from common.storage.azure_file_storage import AzureFileStorageAdapter\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.register()\n",
    "\n",
    "tqdm.pandas()\n",
    "tqdm.pandas(desc=\"global\")\n",
    "\n",
    "from tqdm.dask import TqdmCallback\n",
    "\n",
    "cb = TqdmCallback(desc=\"global\")\n",
    "cb.register()\n",
    "\n",
    "file_system = AzureFileStorageAdapter('data').get_file_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\t# \"memes\",\n",
    "subs = [\n",
    "\t\"SFWRedheads\",\n",
    "\t\"sfwpetite\",\n",
    "\t\"SFWNextDoorGirls\",\n",
    "\t\"trippinthroughtime\",\n",
    "\t\"fatsquirrelhate\",\n",
    "\t\"itookapicture\",\n",
    "\t\"CityPorn\",\n",
    "\t\"EarthPorn\",\n",
    "\t\"spaceporn\",\n",
    "\t\"realasians\",\n",
    "\t\"KoreanHotties\",\n",
    "\t\"prettyasiangirls\",\n",
    "\t\"AsianOfficeLady\",\n",
    "\t\"mildlypenis\",\n",
    "\t\"AsianInvasion\",\n",
    "\t\"sexygirls\",\n",
    "\t\"PrettyGirls\",\n",
    "\t\"gentlemanboners\",\n",
    "\t\"hotofficegirls\",\n",
    "\t\"tightdresses\",\n",
    "\t\"DLAH\",\n",
    "\t\"bathandbodyworks\"\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T12:16:58.165110300Z",
     "start_time": "2023-05-07T12:16:58.149178700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        subreddit                author   \nid                                        \n100rn7k  AmIhotAF          veritynicole  \\\n1013bdt  AmIhotAF           RaulDea9286   \n105mekt  AmIhotAF              lindaniz   \n105qvgl  AmIhotAF           CaitVLove11   \n105rpcj  AmIhotAF       Flashy-Desk1858   \n...           ...                   ...   \n131dso7      DLAH        Wallydinger123   \n131eznp      DLAH          Long_dong111   \n131g3am      DLAH       ThrownAwayMiles   \n131jvcx      DLAH              robok212   \n131n2by      DLAH  Dependent_Secret9424   \n\n                                                  title   \nid                                                        \n100rn7k             hey, hows your new year going (23F)  \\\n1013bdt                                   36F - ITALIAN   \n105mekt  interesting in good forward relationship (f24)   \n105qvgl                       Laughing is my favorite üòÜ   \n105rpcj        [f22] What do you think when you see me?   \n...                                                 ...   \n131dso7                                     Happy B Day   \n131eznp                                         Perfect   \n131g3am                              DLAH left or right   \n131jvcx                                  Good morning üòç   \n131n2by                            Perfection (Sisters)   \n\n                                                   caption   \nid                                                           \n100rn7k  a woman in a white shirt and black pants is po...  \\\n1013bdt            arafed image of a woman in a bikini top   \n105mekt  a close up of a woman with red hair and a whit...   \n105qvgl  a woman in a blue tank top and shorts is smili...   \n105rpcj    a woman in a blue bikini top and a blue bra top   \n...                                                    ...   \n131dso7  there are three women posing for a picture in ...   \n131eznp  araffe woman in a white dress sitting on a pur...   \n131g3am  two women in short dresses posing for a pictur...   \n131jvcx      araffe in a pink dress posing on a white wall   \n131n2by  two women in shorts and sandals taking a selfi...   \n\n                                     hash   \nid                                          \n100rn7k  4bd00c19fa0ff2ade855e6d364b0760b  \\\n1013bdt  7c0d158cba8654ef1c635cbc5471d597   \n105mekt  ba4a0962cca2266a741e1e1700589c04   \n105qvgl  27bfe82c37314a0bcf02ab72eaf3a9e5   \n105rpcj  329eb42b8267fa1cc2980da8e48bcef1   \n...                                   ...   \n131dso7  ebb4b4a88dc79e2f2f57b10f32bf03c0   \n131eznp  5c944c6d62b1ae182c5a6a40c64195f4   \n131g3am  ab1f8fc33c85f4cfce12c810cf22229e   \n131jvcx  01f5058855526ef25888cff88065db4c   \n131n2by  b162dd1999dbf9ea3c7adccd34624a46   \n\n                                                 permalink   \nid                                                           \n100rn7k  /r/AmIhotAF/comments/100rn7k/hey_hows_your_new...  \\\n1013bdt          /r/AmIhotAF/comments/1013bdt/36f_italian/   \n105mekt  /r/AmIhotAF/comments/105mekt/interesting_in_go...   \n105qvgl  /r/AmIhotAF/comments/105qvgl/laughing_is_my_fa...   \n105rpcj  /r/AmIhotAF/comments/105rpcj/f22_what_do_you_t...   \n...                                                    ...   \n131dso7              /r/DLAH/comments/131dso7/happy_b_day/   \n131eznp                  /r/DLAH/comments/131eznp/perfect/   \n131g3am       /r/DLAH/comments/131g3am/dlah_left_or_right/   \n131jvcx             /r/DLAH/comments/131jvcx/good_morning/   \n131n2by       /r/DLAH/comments/131n2by/perfection_sisters/   \n\n                                original_url   image_name   \nid                                                          \n100rn7k  https://i.redd.it/n7r47s0gkh9a1.jpg  100rn7k.jpg  \\\n1013bdt  https://i.redd.it/bg0wwdlt5k9a1.jpg  1013bdt.jpg   \n105mekt  https://i.redd.it/4avjshsz8naa1.jpg  105mekt.jpg   \n105qvgl  https://i.redd.it/2pulzr0lxmaa1.jpg  105qvgl.jpg   \n105rpcj  https://i.redd.it/rz68pf934naa1.jpg  105rpcj.jpg   \n...                                      ...          ...   \n131dso7  https://i.redd.it/36gurz533jwa1.jpg  131dso7.jpg   \n131eznp  https://i.redd.it/dnbbx4zucjwa1.jpg  131eznp.jpg   \n131g3am  https://i.redd.it/zpp70oor3lwa1.jpg  131g3am.jpg   \n131jvcx  https://i.redd.it/ozmbfhjv3mwa1.jpg  131jvcx.jpg   \n131n2by  https://i.redd.it/pfg1u0aw1nwa1.jpg  131n2by.jpg   \n\n                           path                model  exists  curated accept   \nid                                                                             \n100rn7k  data/image/100rn7k.jpg        SexyDiffusion    True     True  False  \\\n1013bdt  data/image/1013bdt.jpg        SexyDiffusion    True     True   True   \n105mekt  data/image/105mekt.jpg        SexyDiffusion    True     True   True   \n105qvgl  data/image/105qvgl.jpg        SexyDiffusion    True     True   True   \n105rpcj  data/image/105rpcj.jpg        SexyDiffusion    True     True   True   \n...                         ...                  ...     ...      ...    ...   \n131dso7  data/image/131dso7.jpg  PrettyGirlDiffusion    True     True  False   \n131eznp  data/image/131eznp.jpg  PrettyGirlDiffusion    True     True   True   \n131g3am  data/image/131g3am.jpg  PrettyGirlDiffusion    True     True   True   \n131jvcx  data/image/131jvcx.jpg  PrettyGirlDiffusion    True     True  False   \n131n2by  data/image/131n2by.jpg  PrettyGirlDiffusion    True     True  False   \n\n        tags  \nid            \n100rn7k   []  \n1013bdt   []  \n105mekt   []  \n105qvgl   []  \n105rpcj   []  \n...      ...  \n131dso7   []  \n131eznp   []  \n131g3am   []  \n131jvcx   []  \n131n2by   []  \n\n[41505 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subreddit</th>\n      <th>author</th>\n      <th>title</th>\n      <th>caption</th>\n      <th>hash</th>\n      <th>permalink</th>\n      <th>original_url</th>\n      <th>image_name</th>\n      <th>path</th>\n      <th>model</th>\n      <th>exists</th>\n      <th>curated</th>\n      <th>accept</th>\n      <th>tags</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100rn7k</th>\n      <td>AmIhotAF</td>\n      <td>veritynicole</td>\n      <td>hey, hows your new year going (23F)</td>\n      <td>a woman in a white shirt and black pants is po...</td>\n      <td>4bd00c19fa0ff2ade855e6d364b0760b</td>\n      <td>/r/AmIhotAF/comments/100rn7k/hey_hows_your_new...</td>\n      <td>https://i.redd.it/n7r47s0gkh9a1.jpg</td>\n      <td>100rn7k.jpg</td>\n      <td>data/image/100rn7k.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1013bdt</th>\n      <td>AmIhotAF</td>\n      <td>RaulDea9286</td>\n      <td>36F - ITALIAN</td>\n      <td>arafed image of a woman in a bikini top</td>\n      <td>7c0d158cba8654ef1c635cbc5471d597</td>\n      <td>/r/AmIhotAF/comments/1013bdt/36f_italian/</td>\n      <td>https://i.redd.it/bg0wwdlt5k9a1.jpg</td>\n      <td>1013bdt.jpg</td>\n      <td>data/image/1013bdt.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>105mekt</th>\n      <td>AmIhotAF</td>\n      <td>lindaniz</td>\n      <td>interesting in good forward relationship (f24)</td>\n      <td>a close up of a woman with red hair and a whit...</td>\n      <td>ba4a0962cca2266a741e1e1700589c04</td>\n      <td>/r/AmIhotAF/comments/105mekt/interesting_in_go...</td>\n      <td>https://i.redd.it/4avjshsz8naa1.jpg</td>\n      <td>105mekt.jpg</td>\n      <td>data/image/105mekt.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>105qvgl</th>\n      <td>AmIhotAF</td>\n      <td>CaitVLove11</td>\n      <td>Laughing is my favorite üòÜ</td>\n      <td>a woman in a blue tank top and shorts is smili...</td>\n      <td>27bfe82c37314a0bcf02ab72eaf3a9e5</td>\n      <td>/r/AmIhotAF/comments/105qvgl/laughing_is_my_fa...</td>\n      <td>https://i.redd.it/2pulzr0lxmaa1.jpg</td>\n      <td>105qvgl.jpg</td>\n      <td>data/image/105qvgl.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>105rpcj</th>\n      <td>AmIhotAF</td>\n      <td>Flashy-Desk1858</td>\n      <td>[f22] What do you think when you see me?</td>\n      <td>a woman in a blue bikini top and a blue bra top</td>\n      <td>329eb42b8267fa1cc2980da8e48bcef1</td>\n      <td>/r/AmIhotAF/comments/105rpcj/f22_what_do_you_t...</td>\n      <td>https://i.redd.it/rz68pf934naa1.jpg</td>\n      <td>105rpcj.jpg</td>\n      <td>data/image/105rpcj.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>131dso7</th>\n      <td>DLAH</td>\n      <td>Wallydinger123</td>\n      <td>Happy B Day</td>\n      <td>there are three women posing for a picture in ...</td>\n      <td>ebb4b4a88dc79e2f2f57b10f32bf03c0</td>\n      <td>/r/DLAH/comments/131dso7/happy_b_day/</td>\n      <td>https://i.redd.it/36gurz533jwa1.jpg</td>\n      <td>131dso7.jpg</td>\n      <td>data/image/131dso7.jpg</td>\n      <td>PrettyGirlDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>131eznp</th>\n      <td>DLAH</td>\n      <td>Long_dong111</td>\n      <td>Perfect</td>\n      <td>araffe woman in a white dress sitting on a pur...</td>\n      <td>5c944c6d62b1ae182c5a6a40c64195f4</td>\n      <td>/r/DLAH/comments/131eznp/perfect/</td>\n      <td>https://i.redd.it/dnbbx4zucjwa1.jpg</td>\n      <td>131eznp.jpg</td>\n      <td>data/image/131eznp.jpg</td>\n      <td>PrettyGirlDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>131g3am</th>\n      <td>DLAH</td>\n      <td>ThrownAwayMiles</td>\n      <td>DLAH left or right</td>\n      <td>two women in short dresses posing for a pictur...</td>\n      <td>ab1f8fc33c85f4cfce12c810cf22229e</td>\n      <td>/r/DLAH/comments/131g3am/dlah_left_or_right/</td>\n      <td>https://i.redd.it/zpp70oor3lwa1.jpg</td>\n      <td>131g3am.jpg</td>\n      <td>data/image/131g3am.jpg</td>\n      <td>PrettyGirlDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>131jvcx</th>\n      <td>DLAH</td>\n      <td>robok212</td>\n      <td>Good morning üòç</td>\n      <td>araffe in a pink dress posing on a white wall</td>\n      <td>01f5058855526ef25888cff88065db4c</td>\n      <td>/r/DLAH/comments/131jvcx/good_morning/</td>\n      <td>https://i.redd.it/ozmbfhjv3mwa1.jpg</td>\n      <td>131jvcx.jpg</td>\n      <td>data/image/131jvcx.jpg</td>\n      <td>PrettyGirlDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>131n2by</th>\n      <td>DLAH</td>\n      <td>Dependent_Secret9424</td>\n      <td>Perfection (Sisters)</td>\n      <td>two women in shorts and sandals taking a selfi...</td>\n      <td>b162dd1999dbf9ea3c7adccd34624a46</td>\n      <td>/r/DLAH/comments/131n2by/perfection_sisters/</td>\n      <td>https://i.redd.it/pfg1u0aw1nwa1.jpg</td>\n      <td>131n2by.jpg</td>\n      <td>data/image/131n2by.jpg</td>\n      <td>PrettyGirlDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>41505 rows √ó 14 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 469 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "extant_data = pandas.read_parquet(\"data/processed_raw_data.parquet\", engine='pyarrow', filesystem=file_system, schema=schema)\n",
    "extant_data.set_index('id', inplace=True)\n",
    "display(extant_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T12:16:59.584708400Z",
     "start_time": "2023-05-07T12:16:58.165110300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "curated_data = pandas.read_parquet(\"data/parquet/back.parquet\", engine='pyarrow', filesystem=file_system, schema=schema)\n",
    "curated_data.set_index('id', inplace=True)\n",
    "display(curated_data.shape)\n",
    "display(curated_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-07T12:16:59.553458400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "extant_data.update(curated_data)\n",
    "updated_extant_data = extant_data.reset_index()\n",
    "\n",
    "display(updated_extant_data.shape)\n",
    "display(updated_extant_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "updated_extant_data.to_parquet(\"data/processed_raw_data.parquet\", engine='pyarrow', filesystem=file_system, schema=schema)\n",
    "\n",
    "display(updated_extant_data.shape)\n",
    "display(updated_extant_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import praw\n",
    "reddit: praw.Reddit = praw.Reddit(client_id='5hVavL0PIRyM_1JSvqT6UQ', client_secret='BjD2kS3WNLnJc59RKY-JJUuc_Z9-JA', user_agent='script:%(bot_name)s:v%(bot_version)s (by /u/%(bot_author)s)')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from praw.models import ListingGenerator\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "posts = []\n",
    "for sub in tqdm(subs, total=len(subs), desc=\"Creating Temp Dir For Subs...\"):\n",
    "\ttemp_dir_path_ = f\"temp/{sub}\"\n",
    "\tif not os.path.exists(temp_dir_path_):\n",
    "\t\tos.makedirs(temp_dir_path_)\n",
    "\texisting_data = pandas.read_parquet(temp_dir_path_)\n",
    "\tos.makedirs(temp_dir_path_, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_log_message(submission_id: str, subreddit: str, message: str, exception: Exception) -> str:\n",
    "\tdate_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\treturn f\"{date_time}\\t{subreddit}\\t{submission_id}\\t{message}\\t{exception}\\n\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('log.txt', 'a') as f:\n",
    "\tfor time_filter in ['week', 'day']:\n",
    "\t\tfor sub in tqdm(subs, desc=f\"{time_filter}\", total=len(subs)):\n",
    "\t\t\ttemp_dir_path = f\"temp/{sub}\"\n",
    "\t\t\ttry:\n",
    "\t\t\t\tsubreddit_stream: ListingGenerator = reddit.subreddit(display_name=sub).top(limit=100, time_filter=time_filter)\n",
    "\t\t\t\tsubreddit_stream = list(subreddit_stream)\n",
    "\t\t\t\tfor submission in tqdm(subreddit_stream, total=len(subreddit_stream), desc=f\"Posts - {sub} - {time_filter}\"):\n",
    "\t\t\t\t\tif submission is None:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif submission.id in extant_data.index.values:\n",
    "\t\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tauthor_name = 'Unknown'\n",
    "\t\t\t\t\t\tsubreddit_name = sub\n",
    "\t\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\t\tauthor_name = submission.author.name\n",
    "\t\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\t\tauthor_name = 'Unknown'\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\t\t\t\tp = {\n",
    "\t\t\t\t\t\t\t'id': submission.id,\n",
    "\t\t\t\t\t\t\t'subreddit': subreddit_name,\n",
    "\t\t\t\t\t\t\t'author': author_name,\n",
    "\t\t\t\t\t\t\t'title': submission.title,\n",
    "\t\t\t\t\t\t\t'caption': '',\n",
    "\t\t\t\t\t\t\t'hash': '',\n",
    "\t\t\t\t\t\t\t'permalink': submission.permalink,\n",
    "\t\t\t\t\t\t\t'original_url': submission.url,\n",
    "\t\t\t\t\t\t\t'image_name': '',\n",
    "\t\t\t\t\t\t\t'path': '',\n",
    "\t\t\t\t\t\t\t'thumbnail_path': '',\n",
    "\t\t\t\t\t\t\t'exists': False,\n",
    "\t\t\t\t\t\t\t'curated': False,\n",
    "\t\t\t\t\t\t\t'Tags': ['']\n",
    "\t\t\t\t\t\t}\n",
    "\t\t\t\t\t\tpd.DataFrame([p]).to_parquet(f\"{temp_dir_path}/{submission.id}.parquet\")\n",
    "\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\tlog = write_log_message(submission.id, sub, \"Error Writing Post\", e)\n",
    "\t\t\t\t\t\tf.write(log)\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tlog = write_log_message(submission.id, sub, f\"Error Getting Posts For SubReddit\", e)\n",
    "\t\t\t\tf.write(log)\n",
    "\t\t\t\tcontinue"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = []\n",
    "\n",
    "for sub in subs:\n",
    "\tdf = pandas.read_parquet(f\"temp/{sub}\", schema=schema, engine='pyarrow')\n",
    "\trecords = df.to_dict(orient='records')\n",
    "\tdata.extend(records)\n",
    "foo = pandas.DataFrame(data=data)\n",
    "temp_data = foo\n",
    "\n",
    "for i,r in temp_data.iterrows():\n",
    "\ttemp_data.loc[i, 'image_name'] = r.id + \".jpg\"\n",
    "\ttemp_data.loc[i, 'path'] = \"\"\n",
    "\ttemp_data.loc[i, 'hash'] = \"\"\n",
    "\ttemp_data.loc[i, 'caption'] = \"\"\n",
    "\ttemp_data.loc[i, 'model'] = \"\"\n",
    "\ttemp_data.loc[i, 'exists'] = False\n",
    "\ttemp_data.loc[i, 'curated'] = False\n",
    "\ttemp_data.loc[i, 'accept'] = False\n",
    "\ttemp_data.loc[i, 'tags'] = ['']\n",
    "\trow = temp_data.loc[i]\n",
    "\n",
    "temp_data = pandas.DataFrame(data)\n",
    "\n",
    "temp_data.set_index('id', inplace=True, drop=False)\n",
    "\n",
    "display(temp_data.shape)\n",
    "display(temp_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered = temp_data[~temp_data['id'].isin(extant_data.index.values)]\n",
    "\n",
    "display(filtered.shape)\n",
    "\n",
    "display(filtered)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sources = [\n",
    "\t{\"name\": \"CityDiffusion\", \"data\": [\"CityPorn\"]},\n",
    "\t{\"name\": \"NatureDiffusion\", \"data\": [\"EarthPorn\"]},\n",
    "\t{\"name\": \"CosmicDiffusion\", \"data\": [\"spaceporn\"]},\n",
    "\t{\"name\": \"ITAPDiffusion\", \"data\": [\"itookapicture\"]},\n",
    "\t{\"name\": \"MemeDiffusion\", \"data\": [\"memes\"]},\n",
    "\t{\"name\": \"TTTDiffusion\", \"data\": [\"trippinthroughtime\"]},\n",
    "\t{\"name\": \"WallStreetDiffusion\", \"data\": [\"wallstreetbets\"]},\n",
    "\t{\"name\": \"SexyDiffusion\", \"data\": [ \"selfies\", \"Amicute\", \"amihot\", \"AmIhotAF\", \"HotGirlNextDoor\" ]},\n",
    "\t{\"name\": \"FatSquirrelDiffusion\", \"data\": [\"fatsquirrelhate\"]},\n",
    "\t{\"name\": \"CelebrityDiffusion\", \"data\": [\"celebrities\"]},\n",
    "\t{\"name\": \"OldLadyDiffusion\", \"data\": [\"oldladiesbakingpies\"]},\n",
    "\t{\"name\": \"SWFPetite\", \"data\": [\"sfwpetite\"]},\n",
    "\t{\"name\": \"SFWMilfs\", \"data\": [\"cougars_and_milfs_sfw\"]},\n",
    "\t{\"name\": \"RedHeadDiffusion\", \"data\": [\"SFWRedheads\"]},\n",
    "\t{\"name\": \"NextDoorGirlsDiffusion\", \"data\": [\"SFWNextDoorGirls\"]},\n",
    "\t{\"name\": \"SexyAsianDiffusion\", \"data\": [\"realasians\", \"KoreanHotties\", \"prettyasiangirls\", \"AsianOfficeLady\", \"AsianInvasion\"]},\n",
    "\t{\"name\": \"MildlyPenisDiffusion\", \"data\": [\"mildlypenis\"]},\n",
    "\t{\"name\": \"PrettyGirlDiffusion\", \"data\": [\"sexygirls\", \"PrettyGirls\", \"gentlemanboners\", \"hotofficegirls\", \"tightdresses\", \"DLAH\"]},\n",
    "\t{\"name\": \"CandleDiffusion\", \"data\": [\"bathandbodyworks\"]}\n",
    "]\n",
    "sources_df = pd.DataFrame.from_records(sources)\n",
    "\n",
    "def add_source(x: object, source_list) -> str:\n",
    "\tfor source in source_list:\n",
    "\t\tif x['subreddit'] in source['data']:\n",
    "\t\t\treturn source['name']\n",
    "\treturn \"\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered['model'] = filtered.progress_apply(lambda x: add_source(x, sources), axis=1)\n",
    "\n",
    "display(filtered.shape)\n",
    "\n",
    "display(filtered)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_hash_from_path(in_path: str) -> hash:\n",
    "\tif os.path.exists(in_path):\n",
    "\t\twith open(in_path, 'rb') as f_:\n",
    "\t\t\tcontent = f_.read()\n",
    "\t\t\tresult = hashlib.md5(content).hexdigest()\n",
    "\t\t\treturn result, content\n",
    "\telse:\n",
    "\t\treturn \"\"\n",
    "\n",
    "\n",
    "\n",
    "def fetch_image(x: object, file_list_) -> object:\n",
    "\twith open('log.txt', 'a') as f_image:\n",
    "\t\ttry:\n",
    "\t\t\turl = x['original_url']\n",
    "\t\t\tsubreddit = x['subreddit']\n",
    "\t\t\timage_id = x['id']\n",
    "\t\t\tos.makedirs(f\"temp\\\\image\\\\{subreddit}\", exist_ok=True)\n",
    "\t\t\ttemp_path = f\"temp\\\\image\\\\{subreddit}\\\\{image_id}.jpg\"\n",
    "\t\t\tout_path = f\"data/image/{image_id}.jpg\"\n",
    "\t\t\tif os.path.exists(temp_path):\n",
    "\t\t\t\tmd5, content = get_hash_from_path(temp_path)\n",
    "\t\t\t\tif md5 != \"f17b01901c752c1bb04928131d1661af\" or md5 != \"d835884373f4d6c8f24742ceabe74946\":\n",
    "\t\t\t\t\tfile_system.upload(temp_path, out_path)\n",
    "\t\t\t\t\treturn out_path\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn \"\"\n",
    "\t\t\telse:\n",
    "\t\t\t\tresponse = requests.get(url)\n",
    "\t\t\t\tmd5 = hashlib.md5(response.content).hexdigest()\n",
    "\t\t\t\tif md5 != \"f17b01901c752c1bb04928131d1661af\" or md5 != \"d835884373f4d6c8f24742ceabe74946\":\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\traw_image = Image.open(BytesIO(response.content))\n",
    "\t\t\t\t\t\traw_image.save(temp_path)\n",
    "\t\t\t\t\t\traw_image.close()\n",
    "\t\t\t\t\t\tif out_path in file_list_:\n",
    "\t\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tfile_system.upload(temp_path, out_path)\n",
    "\t\t\t\t\t\t\treturn out_path\n",
    "\t\t\t\t\texcept Exception as ex:\n",
    "\t\t\t\t\t\tmessage = write_log_message(x['id'], x['subreddit'], \"Failure in fetch_image\", ex)\n",
    "\t\t\t\t\t\tf_image.write(message)\n",
    "\t\t\t\t\t\treturn \"\"\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\treturn \"\"\n",
    "\t\texcept Exception as ex:\n",
    "\t\t\tmessage = write_log_message(x['id'], x['subreddit'], \"Failure in fetch_image\", ex)\n",
    "\t\t\tf_image.write(message)\n",
    "\t\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_list = file_system.ls(\"data/image\")\n",
    "filtered['path'] = filtered.progress_apply(lambda x: fetch_image(x, file_list), axis=1)\n",
    "\n",
    "display(filtered.shape)\n",
    "\n",
    "display(filtered)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_exists(x: object):\n",
    "\tsub_reddit = x['subreddit']\n",
    "\trecord_id = x['id']\n",
    "\ttemp_path = f\"temp\\\\image\\\\{sub_reddit}\\\\{record_id}.jpg\"\n",
    "\treturn os.path.exists(temp_path)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered['exists'] = filtered.progress_apply(lambda x: set_exists(x), axis=1)\n",
    "\n",
    "display(filtered.shape)\n",
    "display(filtered)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def set_hash(x: object):\n",
    "\tsub_reddit = x['subreddit']\n",
    "\trecord_id = x['id']\n",
    "\ttemp_path = f\"temp\\\\image\\\\{sub_reddit}\\\\{record_id}.jpg\"\n",
    "\tif os.path.exists(temp_path):\n",
    "\t\treturn hashlib.md5(open(temp_path, 'rb').read()).hexdigest()\n",
    "\telse:\n",
    "\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered['hash'] = filtered.progress_apply(lambda x: set_hash(x), axis=1)\n",
    "display(filtered.shape)\n",
    "display(filtered)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from common.captioning.caption import BlipCaption\n",
    "import random\n",
    "\n",
    "def apply_caption(x: object, caption_routine: [BlipCaption, BlipCaption]) -> str:\n",
    "\twith open('log.txt', 'a') as f_3:\n",
    "\t\texists = x['exists']\n",
    "\t\tif not exists:\n",
    "\t\t\treturn \"\"\n",
    "\t\tsub_reddit = x['subreddit']\n",
    "\t\trecord_id = x['id']\n",
    "\t\ttemp_path = f\"temp\\\\image\\\\{sub_reddit}\\\\{record_id}.jpg\"\n",
    "\n",
    "\t\tif os.path.exists(temp_path):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tresult = random.choice(caption_routine).caption_image(temp_path)\n",
    "\t\t\t\treturn result\n",
    "\t\t\texcept Exception as ex:\n",
    "\t\t\t\tmessage = write_log_message(x['id'], x['subreddit'], \"Failure in apply_caption\", ex)\n",
    "\t\t\t\tf_3.write(message)\n",
    "\t\t\t\treturn \"\"\n",
    "\t\telse:\n",
    "\t\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "caption_0 = BlipCaption(\"cuda:0\")\n",
    "caption_1 = BlipCaption(\"cuda:1\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered['caption'] = filtered.progress_apply(lambda x: apply_caption(x, [caption_0, caption_1]), axis=1)\n",
    "\n",
    "display(filtered.shape)\n",
    "\n",
    "display(filtered)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "filtered_more = filtered.loc[filtered['caption'] != \"\"]\n",
    "display(filtered_more.shape)\n",
    "display(filtered_more)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dropped = filtered_more.dropna(axis=1, how='all')\n",
    "dropped.reset_index(drop=True, inplace=True)\n",
    "display(dropped)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "concat = pd.concat([f, dropped])\n",
    "display(concat.shape)\n",
    "display(concat)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fix_path(x:object, fl: []) -> str:\n",
    "\tcurrent_path = x['path']\n",
    "\texists = x['exists']\n",
    "\tif current_path in fl:\n",
    "\t\treturn current_path\n",
    "\telse:\n",
    "\t\timage_id = x['id']\n",
    "\t\tif exists:\n",
    "\t\t\treturn f\"data/image/{image_id}.jpg\"\n",
    "\t\telse:\n",
    "\t\t\treturn \"\""
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "file_list_ = file_system.ls(\"data/image\")\n",
    "concat['path'] = concat.progress_apply(lambda x: fix_path(x, file_list_), axis=1)\n",
    "display(concat)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# concat.to_parquet(\"data/parquet/back.parquet\", schema=schema, compression='gzip', filesystem=file_system)\n",
    "# new = pd.read_parquet(\"data/parquet/back.parquet\", engine='pyarrow', schema=schema, filesystem=file_system)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# display(new.shape)\n",
    "# display(new)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %%time\n",
    "#\n",
    "# display(\"== Clean Up ==\")\n",
    "# os.rmdir(\"temp\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
