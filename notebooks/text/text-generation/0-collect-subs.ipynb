{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@title Dependencies\n",
    "%%time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Imports and Definitions\n",
    "%%time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from adlfs import AzureBlobFileSystem\n",
    "import os\n",
    "from tqdm import notebook\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import praw\n",
    "import datetime\n",
    "import asyncpraw\n",
    "from pmaw import PushshiftAPI\n",
    "\n",
    "os.environ[\"AZURE_ACCOUNT_NAME\"] = \"ajdevreddit\"\n",
    "os.environ[\"AZURE_TABLE_ENDPOINT\"] = \"https://ajdevreddit.table.core.windows.net/\"\n",
    "os.environ[\"AZURE_ACCOUNT_KEY\"] = \"+9066TCgdeVignRdy50G4qjmNoUJuibl9ERiTGzdV4fwkvgdV3aSVqgLwldgZxj/UpKLkkfXg+3k+AStjFI33Q==\"\n",
    "os.environ[\"AZURE_STORAGE_CONNECTION_STRING\"] = \"DefaultEndpointsProtocol=https;AccountName=ajdevreddit;AccountKey=+9066TCgdeVignRdy50G4qjmNoUJuibl9ERiTGzdV4fwkvgdV3aSVqgLwldgZxj/UpKLkkfXg+3k+AStjFI33Q==;BlobEndpoint=https://ajdevreddit.blob.core.windows.net/;QueueEndpoint=https://ajdevreddit.queue.core.windows.net/;TableEndpoint=https://ajdevreddit.table.core.windows.net/;FileEndpoint=https://ajdevreddit.file.core.windows.net/\"\n",
    "\n",
    "class AzureFileStorageAdapter(object):\n",
    "    def __init__(self):\n",
    "        self._account_name: str = os.environ[\"AZURE_ACCOUNT_NAME\"]\n",
    "        self._account_key: str = os.environ[\"AZURE_ACCOUNT_KEY\"]\n",
    "\n",
    "    def get_file_storage_container(self, container_name: str) -> AzureBlobFileSystem:\n",
    "        return AzureBlobFileSystem(\n",
    "            account_name=self._account_name,\n",
    "            account_key=self._account_key,\n",
    "            container_name=container_name)\n",
    "\n",
    "azure_file_store = AzureFileStorageAdapter()\n",
    "\n",
    "file_system: AzureBlobFileSystem = azure_file_store.get_file_storage_container(\"data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Checking File System\n",
    "%%time\n",
    "\n",
    "file_system.ls(\"data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Reddit API Initialization\n",
    "%%time\n",
    "\n",
    "reddit: praw.Reddit = praw.Reddit(client_id='5hVavL0PIRyM_1JSvqT6UQ', client_secret='BjD2kS3WNLnJc59RKY-JJUuc_Z9-JA', user_agent='script:%(bot_name)s:v%(bot_version)s (by /u/%(bot_author)s)', check_for_async=False)\n",
    "\n",
    "api: PushshiftAPI = PushshiftAPI(praw=reddit, num_workers=12, batch_size=12, shards_down_behavior=\"none\", jitter=\"equal\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Calculate Time Intervals For Training\n",
    "%%time\n",
    "\n",
    "start_date_time_stamp: int = int(datetime.datetime.strptime('2023-03-01', '%Y-%m-%d').timestamp())\n",
    "\n",
    "end_date_time_stamp: int = int(datetime.datetime.today().timestamp())\n",
    "\n",
    "total_number_days_since_start = (end_date_time_stamp - start_date_time_stamp) // 86400\n",
    "\n",
    "temp = start_date_time_stamp\n",
    "\n",
    "intervals = []\n",
    "while temp < end_date_time_stamp:\n",
    "    temp = temp + 86400\n",
    "    intervals.append(temp)\n",
    "\n",
    "print(f\"Total Number Of Intervals: {len(intervals)}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Collect Data from PRAW\n",
    "%%time\n",
    "\n",
    "exists = file_system.ls(\"data/text/1.AskReddit.parquet\")\n",
    "\n",
    "posts = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Filtering Result And Processing To Parquet\n",
    "%%time\n",
    "\n",
    "exists = True\n",
    "if not exists:\n",
    "    columns = [\n",
    "    'id',\n",
    "    'subreddit',\n",
    "    'title',\n",
    "    'selftext',\n",
    "    'author',\n",
    "    'score',\n",
    "    'upvote_ratio',\n",
    "    'ups',\n",
    "    'subreddit_id',\n",
    "    'num_comments',\n",
    "    'permalink']\n",
    "\n",
    "    foo = df.loc[:, columns]\n",
    "\n",
    "    foo = foo.where(foo['selftext'] != '[removed]')\n",
    "    foo = foo.where(foo['selftext'] != '[deleted]')\n",
    "    foo = foo.where(foo['num_comments'] > 0)\n",
    "    foo = foo.dropna().reset_index()\n",
    "    foo = foo.drop('index', axis=1)\n",
    "\n",
    "    foo = foo.sort_values(by='score', ascending=False).reset_index()\n",
    "    foo = foo.drop('index', axis=1)\n",
    "\n",
    "    final_data = []\n",
    "    out_records = foo.to_dict(orient='records')\n",
    "\n",
    "    for record in out_records:\n",
    "        sub = record['subreddit'].__dict__['display_name']\n",
    "        record['subreddit'] = sub\n",
    "        author = record['author'].__dict__['name']\n",
    "        record['author'] = author\n",
    "        final_data.append(record)\n",
    "\n",
    "    bar = pandas.DataFrame(data=final_data)\n",
    "    bar.to_parquet(\"data/text/1.AskReddit.parquet\", engine='pyarrow', filesystem=file_system)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_data: pandas.DataFrame = pd.read_parquet(\"data/text/1.AskReddit.parquet\", engine='pyarrow', filesystem=file_system)\n",
    "display(submission_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title Obtain Comments For Each Sub\n",
    "%%time\n",
    "\n",
    "submission_id_list = list(submission_data['id'])\n",
    "\n",
    "for submission_id in notebook.tqdm(submission_id_list, desc=\"Getting Submission\"):\n",
    "    out_path = f\"/*{submission_id}.parquet\"\n",
    "    if file_system.exists(out_path):\n",
    "        continue\n",
    "    submission = reddit.submission(submission_id)\n",
    "    submission.comment_sort = 'top'\n",
    "\n",
    "    comments_for_submission = []\n",
    "    top_level_comments = submission.comments.list()\n",
    "\n",
    "    for comment in top_level_comments:\n",
    "        try:\n",
    "            comment.author.__dict__['name']\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        data = {\n",
    "             'id': comment.id,\n",
    "             'parent_id': comment.parent_id,\n",
    "             'link_id': comment.link_id,\n",
    "             'submission_id': submission_id,\n",
    "             'body': comment.body,\n",
    "             'author': comment.author.__dict__['name'],\n",
    "             'score': comment.score\n",
    "            }\n",
    "        comments_for_submission.append(data)\n",
    "    temp_df = pandas.DataFrame(data=comments_for_submission)\n",
    "    temp_df.to_parquet(out_path, engine='pyarrow', filesystem=file_system)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
