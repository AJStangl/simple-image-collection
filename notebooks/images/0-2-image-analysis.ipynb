{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:07:25.881758200Z",
     "start_time": "2023-05-17T12:07:14.520651400Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure.cognitiveservices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:18\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ajsta\\PycharmProjects\\simple-image-collection\\notebooks\\images\\../..\\common\\captioning\\azure_descriptions.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39madlfs\u001b[39;00m \u001b[39mimport\u001b[39;00m AzureBlobFileSystem\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m \u001b[39mimport\u001b[39;00m VisionServiceOptions, VisionSource, ImageAnalysisOptions, ImageAnalysisFeature, \\\n\u001b[0;32m      9\u001b[0m \tImageAnalyzer, ImageAnalysisResultReason, ImageAnalysisResultDetails, ImageAnalysisErrorDetails\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcognitiveservices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomputervision\u001b[39;00m \u001b[39mimport\u001b[39;00m ComputerVisionClientConfiguration, ComputerVisionClient\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcognitiveservices\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomputervision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDescription\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvision\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageAnalysisResult\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azure.cognitiveservices'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.schemas.pyarrow_schema import tagging_schema\n",
    "from common.storage.azure_file_storage import AzureFileStorageAdapter\n",
    "from common.captioning.azure_descriptions import AzureCaption\n",
    "from common.schemas.pyarrow_schema import schema\n",
    "from common.functions.functions import Functions\n",
    "\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "file_system: AzureBlobFileSystem = AzureFileStorageAdapter('data').get_file_storage()\n",
    "\n",
    "functions: Functions = Functions()\n",
    "\n",
    "caption: AzureCaption = AzureCaption(file_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:07:30.759991400Z",
     "start_time": "2023-05-17T12:07:25.913008400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "curated_data = pandas.read_parquet(\"data/parquet/back.parquet\", engine=\"pyarrow\", filesystem=file_system)\n",
    "\n",
    "curated_data.set_index(\"id\", inplace=True, drop=False)\n",
    "\n",
    "filtered = curated_data.loc[curated_data[\"accept\"] == True, schema.names]\n",
    "\n",
    "filtered.dropna(inplace=True)\n",
    "\n",
    "display(filtered.shape)\n",
    "\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:07:30.775618300Z",
     "start_time": "2023-05-17T12:07:30.697493900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sources = [\n",
    "\t{\"name\": \"CityDiffusion\", \"data\": [\"CityPorn\"]},\n",
    "\t{\"name\": \"NatureDiffusion\", \"data\": [\"EarthPorn\"]},\n",
    "\t{\"name\": \"CosmicDiffusion\", \"data\": [\"spaceporn\"]},\n",
    "\t{\"name\": \"ITAPDiffusion\", \"data\": [\"itookapicture\"]},\n",
    "\t{\"name\": \"MemeDiffusion\", \"data\": [\"memes\"]},\n",
    "\t{\"name\": \"TTTDiffusion\", \"data\": [\"trippinthroughtime\"]},\n",
    "\t{\"name\": \"WallStreetDiffusion\", \"data\": [\"wallstreetbets\"]},\n",
    "\t{\"name\": \"SexyDiffusion\", \"data\": [\"selfies\", \"Amicute\", \"amihot\", \"AmIhotAF\", \"HotGirlNextDoor\"]},\n",
    "\t{\"name\": \"FatSquirrelDiffusion\", \"data\": [\"fatsquirrelhate\"]},\n",
    "\t{\"name\": \"CelebrityDiffusion\", \"data\": [\"celebrities\"]},\n",
    "\t{\"name\": \"OldLadyDiffusion\", \"data\": [\"oldladiesbakingpies\"]},\n",
    "\t{\"name\": \"SWFPetite\", \"data\": [\"sfwpetite\"]},\n",
    "\t{\"name\": \"SFWMilfs\", \"data\": [\"cougars_and_milfs_sfw\"]},\n",
    "\t{\"name\": \"RedHeadDiffusion\", \"data\": [\"SFWRedheads\"]},\n",
    "\t{\"name\": \"NextDoorGirlsDiffusion\", \"data\": [\"SFWNextDoorGirls\"]},\n",
    "\t{\"name\": \"SexyAsianDiffusion\",\"data\": [\"realasians\", \"KoreanHotties\", \"prettyasiangirls\", \"AsianOfficeLady\", \"AsianInvasion\",\"AesPleasingAsianGirls\"]},\n",
    "\t{\"name\": \"MildlyPenisDiffusion\", \"data\": [\"mildlypenis\"]},\n",
    "\t{\"name\": \"PrettyGirlDiffusion\",\"data\": [\"sexygirls\", \"PrettyGirls\", \"gentlemanboners\", \"hotofficegirls\", \"tightdresses\", \"DLAH\"]},\n",
    "\t{\"name\": \"CandleDiffusion\", \"data\": [\"bathandbodyworks\"]}\n",
    "]\n",
    "sources_df = pd.DataFrame.from_records(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:07:31.494708500Z",
     "start_time": "2023-05-17T12:07:30.728859800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered['model'] = filtered.apply(lambda x: functions.add_source(x, sources), axis=1)\n",
    "foo = filtered.loc[filtered['model'] != \"\"]\n",
    "foo.dropna()\n",
    "filtered = foo\n",
    "display(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:07:51.693959300Z",
     "start_time": "2023-05-17T12:07:31.135035700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "group = filtered[[\"id\", \"subreddit\"]].groupby(\"subreddit\").count().sort_values(by=\"id\", ascending=False)\n",
    "plot = group.plot.bar(figsize=(20, 10), title=\"Subreddits with most posts\", legend=True)\n",
    "display(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:07:52.020938900Z",
     "start_time": "2023-05-17T12:07:48.733444100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "group = filtered[[\"id\", \"model\", \"subreddit\"]].groupby([\"model\"]).count().sort_values(by=\"id\", ascending=False)\n",
    "plot_1 = group.plot.bar(figsize=(20, 10), title=\"Models with most images\", legend=True)\n",
    "display(plot_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:07:52.327937900Z",
     "start_time": "2023-05-17T12:07:51.706962300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar = filtered.loc[(filtered[\"model\"] == \"SexyDiffusion\") | (filtered[\"model\"] == \"SexyAsianDiffusion\") | (filtered['model'] == \"NextDoorGirlDiffusion\") | (filtered['model'] == 'RedHeadDiffusion')]\n",
    "dropped = bar.dropna(inplace=True)\n",
    "display(bar.shape)\n",
    "display(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "from common.captioning.azure_descriptions import AzureCaption\n",
    "\n",
    "records = bar.to_dict(orient=\"records\")\n",
    "current_captions = [item.replace('\\n', '') for item in file_system.ls(\"data/caption\")]\n",
    "\n",
    "i = 0\n",
    "start_time = datetime.datetime.now()\n",
    "for elem in records:\n",
    "\top_time = datetime.datetime.now()\n",
    "\ttime_current = f\"{(op_time - start_time).total_seconds()/60} minutes\"\n",
    "\ti += 1\n",
    "\tpath = elem['path']\n",
    "\tremote_path = file_system.url(path)\n",
    "\n",
    "\tif f'data/caption/{elem[\"id\"]}.json' not in current_captions:\n",
    "\t\tdisplay(f'Processing {elem[\"id\"]} -- {i}/{len(records)}...{time_current}', clear=True)\n",
    "\t\tcaption: AzureCaption = AzureCaption(file_system)\n",
    "\t\toutput = caption.image_analysis(remote_path)\n",
    "\t\ttime.sleep(12)\n",
    "\t\tjson_result = output.json_result\n",
    "\t\tif json_result is None:\n",
    "\t\t\tdisplay(f'Error with {elem[\"id\"]} -- Empty Result -- {i}/{len(records)}...{time_current}', clear=True)\n",
    "\t\t\tcontinue\n",
    "\t\ttry:\n",
    "\t\t\tif json.loads(json_result).get('error'):\n",
    "\t\t\t\tdisplay(f'Error with {elem[\"id\"]} -- Error: {json.loads(json_result).get(\"error\")} -- {i}/{len(records)}...{time_current}', clear=True)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\thandle = open('temp.json', 'w', encoding='utf-8')\n",
    "\t\t\thandle.write(json_result)\n",
    "\t\t\thandle.close()\n",
    "\t\t\tdisplay(f'Uploading {elem[\"id\"]} -- {i}/{len(records)}...{time_current}', clear=True)\n",
    "\t\t\tfile_system.upload('temp.json', f'data/caption/{elem[\"id\"]}.json')\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tdisplay(f'Error with {elem[\"id\"]} -- Error: {e} -- {i}/{len(records)}', clear=True)\n",
    "\t\t\tcontinue\n",
    "\telse:\n",
    "\t\tdisplay(f'Skipping {elem[\"id\"]} -- Already Processed -- {i}/{len(records)}...{time_current}', clear=True)\n",
    "\t\tcontinue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:11:11.249112900Z",
     "start_time": "2023-05-17T12:11:11.051788900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !jupyter notebook stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
