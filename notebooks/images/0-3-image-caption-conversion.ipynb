{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from common.schemas.pyarrow_schema import tagging_schema\n",
    "from common.storage.azure_file_storage import AzureFileStorageAdapter\n",
    "from common.captioning.azure_descriptions import AzureCaption\n",
    "from common.schemas.pyarrow_schema import schema\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "file_system: AzureBlobFileSystem = AzureFileStorageAdapter('data').get_file_storage()\n",
    "\n",
    "from common.data_frame_functions.functions import Functions\n",
    "\n",
    "functions: Functions = Functions()\n",
    "\n",
    "caption: AzureCaption = AzureCaption(file_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 766 ms\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "curated_df = pandas.read_parquet('data/parquet/back.parquet', filesystem=file_system, engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:10:57.899842600Z",
     "start_time": "2023-05-12T22:10:56.002454900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(31180, 7)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(71153, 3)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(3509, 6)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 391 ms\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "captions = pd.read_parquet('data/parquet/image_captions.parquet', filesystem=file_system, engine='pyarrow')\n",
    "tags = pd.read_parquet('data/parquet/image_tags.parquet', filesystem=file_system, engine='pyarrow')\n",
    "crops = pd.read_parquet('data/parquet/image_cropping.parquet', filesystem=file_system, engine='pyarrow')\n",
    "\n",
    "display(captions.shape)\n",
    "display(tags.shape)\n",
    "display(crops.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:10:59.009235800Z",
     "start_time": "2023-05-12T22:10:57.899842600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "3509"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.27 s\n",
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "current_captions = file_system.ls(\"data/caption\")\n",
    "display(len(current_captions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:11:05.766693400Z",
     "start_time": "2023-05-12T22:10:59.009235800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading caption files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3509/3509 [05:38<00:00, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 29s\n",
      "Wall time: 5min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_data = []\n",
    "for caption_file in tqdm(current_captions, total=len(current_captions), desc='Reading caption files'):\n",
    "\tcaption_data = json.loads(file_system.read_text(caption_file, encoding='utf-8'))\n",
    "\tdense_caption_result = caption_data.get('denseCaptionsResult')\n",
    "\tmetadata = caption_data.get('metadata')\n",
    "\ttags_result = caption_data.get('tagsResult')\n",
    "\tsmart_crop_result = caption_data.get('smartCropsResult')\n",
    "\tbasic_caption = caption_data.get('captionResult')\n",
    "\timage_id = caption_file.split('/')[-1].split('.')[0]\n",
    "\tfiltered_data = {\n",
    "\t\t\"id\": image_id,\n",
    "\t\t'captions': [basic_caption],\n",
    "\t\t\"dense_captions\": dense_caption_result['values'],\n",
    "\t\t\"meta\": [metadata],\n",
    "\t\t\"tags\": tags_result['values'],\n",
    "\t\t\"smart_crop\": smart_crop_result['values']\n",
    "\t}\n",
    "\tall_data.append(filtered_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:44.553523Z",
     "start_time": "2023-05-12T22:11:05.766693400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.95 s\n",
      "Wall time: 7.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "new_captions = pandas.json_normalize(data=all_data, record_path=['dense_captions'], meta=['id'], record_prefix='dense_captions_')\n",
    "new_tags = pandas.json_normalize(data=all_data, record_path=['tags'], meta=['id'], record_prefix='tags_')\n",
    "new_crops = pandas.json_normalize(data=all_data, record_path=['smart_crop'], meta=['id'], record_prefix='smart_crop_')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:52.212345500Z",
     "start_time": "2023-05-12T22:16:44.537877800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 219 ms\n",
      "Wall time: 344 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "new_basic_captions = pandas.json_normalize(data=all_data, record_path=['captions'], meta=['id'], record_prefix='captions_')\n",
    "meta = pandas.json_normalize(data=all_data, record_path=['meta'], meta=['id'], record_prefix='meta_')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:52.618942900Z",
     "start_time": "2023-05-12T22:16:52.212345500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                    dense_captions_text  dense_captions_confidence   \n0               a woman taking a selfie                   0.662057  \\\n1               a woman taking a selfie                   0.665344   \n2         a woman wearing a black dress                   0.473444   \n3                   a close up of a key                   0.593095   \n4                  a close up of an eye                   0.619898   \n...                                 ...                        ...   \n31175       a close-up of a green plant                   0.453059   \n31176  a mountain range in the distance                   0.334624   \n31177     a woman smiling at the camera                   0.465720   \n31178           a woman wearing a dress                   0.548892   \n31179              a close up of a hand                   0.566506   \n\n       dense_captions_boundingBox.x  dense_captions_boundingBox.y   \n0                                 0                             0  \\\n1                                 0                           100   \n2                               185                          1443   \n3                               716                          1503   \n4                               778                           744   \n...                             ...                           ...   \n31175                           680                          1066   \n31176                           498                           277   \n31177                           244                           293   \n31178                             0                           758   \n31179                           220                           809   \n\n       dense_captions_boundingBox.w  dense_captions_boundingBox.h       id  \n0                              1468                          2608  1002cx2  \n1                              1447                          2473  1002cx2  \n2                              1265                          1150  1002cx2  \n3                                82                           140  1002cx2  \n4                               152                            84  1002cx2  \n...                             ...                           ...      ...  \n31175                           394                           280   zzxq2l  \n31176                           568                            99   zzxq2l  \n31177                           319                           530   zzxq2l  \n31178                          1048                           570   zzxq2l  \n31179                            73                            55   zzxq2l  \n\n[31180 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dense_captions_text</th>\n      <th>dense_captions_confidence</th>\n      <th>dense_captions_boundingBox.x</th>\n      <th>dense_captions_boundingBox.y</th>\n      <th>dense_captions_boundingBox.w</th>\n      <th>dense_captions_boundingBox.h</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a woman taking a selfie</td>\n      <td>0.662057</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1468</td>\n      <td>2608</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a woman taking a selfie</td>\n      <td>0.665344</td>\n      <td>0</td>\n      <td>100</td>\n      <td>1447</td>\n      <td>2473</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a woman wearing a black dress</td>\n      <td>0.473444</td>\n      <td>185</td>\n      <td>1443</td>\n      <td>1265</td>\n      <td>1150</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a close up of a key</td>\n      <td>0.593095</td>\n      <td>716</td>\n      <td>1503</td>\n      <td>82</td>\n      <td>140</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a close up of an eye</td>\n      <td>0.619898</td>\n      <td>778</td>\n      <td>744</td>\n      <td>152</td>\n      <td>84</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31175</th>\n      <td>a close-up of a green plant</td>\n      <td>0.453059</td>\n      <td>680</td>\n      <td>1066</td>\n      <td>394</td>\n      <td>280</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31176</th>\n      <td>a mountain range in the distance</td>\n      <td>0.334624</td>\n      <td>498</td>\n      <td>277</td>\n      <td>568</td>\n      <td>99</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31177</th>\n      <td>a woman smiling at the camera</td>\n      <td>0.465720</td>\n      <td>244</td>\n      <td>293</td>\n      <td>319</td>\n      <td>530</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31178</th>\n      <td>a woman wearing a dress</td>\n      <td>0.548892</td>\n      <td>0</td>\n      <td>758</td>\n      <td>1048</td>\n      <td>570</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31179</th>\n      <td>a close up of a hand</td>\n      <td>0.566506</td>\n      <td>220</td>\n      <td>809</td>\n      <td>73</td>\n      <td>55</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>31180 rows √ó 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        tags_name  tags_confidence       id\n0          person         0.998358  1002cx2\n1      human face         0.997763  1002cx2\n2        clothing         0.990993  1002cx2\n3            lady         0.981919  1002cx2\n4           smile         0.964994  1002cx2\n...           ...              ...      ...\n71148       woman         0.753262   zzxq2l\n71149       beach         0.739799   zzxq2l\n71150    standing         0.630927   zzxq2l\n71151        girl         0.556561   zzxq2l\n71152    mountain         0.544261   zzxq2l\n\n[71153 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags_name</th>\n      <th>tags_confidence</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>person</td>\n      <td>0.998358</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>human face</td>\n      <td>0.997763</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>clothing</td>\n      <td>0.990993</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lady</td>\n      <td>0.981919</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>smile</td>\n      <td>0.964994</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71148</th>\n      <td>woman</td>\n      <td>0.753262</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71149</th>\n      <td>beach</td>\n      <td>0.739799</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71150</th>\n      <td>standing</td>\n      <td>0.630927</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71151</th>\n      <td>girl</td>\n      <td>0.556561</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71152</th>\n      <td>mountain</td>\n      <td>0.544261</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>71153 rows √ó 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      smart_crop_aspectRatio  smart_crop_boundingBox.x   \n0                        1.0                         0  \\\n1                        1.0                       143   \n2                        1.0                         0   \n3                        1.0                         0   \n4                        1.0                         0   \n...                      ...                       ...   \n3504                     1.0                         0   \n3505                     1.0                         0   \n3506                     1.0                         0   \n3507                     1.0                       135   \n3508                     1.0                       101   \n\n      smart_crop_boundingBox.y  smart_crop_boundingBox.w   \n0                          140                      1462  \\\n1                          138                      1249   \n2                          355                      1948   \n3                          224                      1120   \n4                            0                      1107   \n...                        ...                       ...   \n3504                         0                      1025   \n3505                         0                       461   \n3506                         0                      2273   \n3507                         0                      1299   \n3508                       101                       970   \n\n      smart_crop_boundingBox.h       id  \n0                         1462  1002cx2  \n1                         1250  1003dod  \n2                         1948  1008ddt  \n3                         1120  100dcrd  \n4                         1107  100jl1b  \n...                        ...      ...  \n3504                      1025   zzr9nz  \n3505                       461   zzruf4  \n3506                      2273   zzu8i8  \n3507                      1299   zzvv3x  \n3508                       970   zzxq2l  \n\n[3509 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smart_crop_aspectRatio</th>\n      <th>smart_crop_boundingBox.x</th>\n      <th>smart_crop_boundingBox.y</th>\n      <th>smart_crop_boundingBox.w</th>\n      <th>smart_crop_boundingBox.h</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>1462</td>\n      <td>1462</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>143</td>\n      <td>138</td>\n      <td>1249</td>\n      <td>1250</td>\n      <td>1003dod</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>355</td>\n      <td>1948</td>\n      <td>1948</td>\n      <td>1008ddt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>224</td>\n      <td>1120</td>\n      <td>1120</td>\n      <td>100dcrd</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1107</td>\n      <td>1107</td>\n      <td>100jl1b</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3504</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1025</td>\n      <td>1025</td>\n      <td>zzr9nz</td>\n    </tr>\n    <tr>\n      <th>3505</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>461</td>\n      <td>461</td>\n      <td>zzruf4</td>\n    </tr>\n    <tr>\n      <th>3506</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2273</td>\n      <td>2273</td>\n      <td>zzu8i8</td>\n    </tr>\n    <tr>\n      <th>3507</th>\n      <td>1.0</td>\n      <td>135</td>\n      <td>0</td>\n      <td>1299</td>\n      <td>1299</td>\n      <td>zzvv3x</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>1.0</td>\n      <td>101</td>\n      <td>101</td>\n      <td>970</td>\n      <td>970</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>3509 rows √ó 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                                     captions_text  captions_confidence   \n0                          a woman taking a selfie             0.662057  \\\n1     a woman in a garment standing next to a tree             0.513081   \n2                          a woman taking a selfie             0.658102   \n3            a group of women posing for a picture             0.556227   \n4            a group of women posing for a picture             0.614969   \n...                                            ...                  ...   \n3504              two women in garments on a beach             0.529292   \n3505               a woman with tattoos on her arm             0.501798   \n3506                    a woman in a blue lingerie             0.430763   \n3507                      a woman sitting on a bed             0.584322   \n3508       a woman in a dress posing for a picture             0.460149   \n\n           id  \n0     1002cx2  \n1     1003dod  \n2     1008ddt  \n3     100dcrd  \n4     100jl1b  \n...       ...  \n3504   zzr9nz  \n3505   zzruf4  \n3506   zzu8i8  \n3507   zzvv3x  \n3508   zzxq2l  \n\n[3509 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>captions_text</th>\n      <th>captions_confidence</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a woman taking a selfie</td>\n      <td>0.662057</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a woman in a garment standing next to a tree</td>\n      <td>0.513081</td>\n      <td>1003dod</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a woman taking a selfie</td>\n      <td>0.658102</td>\n      <td>1008ddt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a group of women posing for a picture</td>\n      <td>0.556227</td>\n      <td>100dcrd</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a group of women posing for a picture</td>\n      <td>0.614969</td>\n      <td>100jl1b</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3504</th>\n      <td>two women in garments on a beach</td>\n      <td>0.529292</td>\n      <td>zzr9nz</td>\n    </tr>\n    <tr>\n      <th>3505</th>\n      <td>a woman with tattoos on her arm</td>\n      <td>0.501798</td>\n      <td>zzruf4</td>\n    </tr>\n    <tr>\n      <th>3506</th>\n      <td>a woman in a blue lingerie</td>\n      <td>0.430763</td>\n      <td>zzu8i8</td>\n    </tr>\n    <tr>\n      <th>3507</th>\n      <td>a woman sitting on a bed</td>\n      <td>0.584322</td>\n      <td>zzvv3x</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>a woman in a dress posing for a picture</td>\n      <td>0.460149</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>3509 rows √ó 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      meta_width  meta_height       id\n0           1468         2608  1002cx2\n1           1523         2030  1003dod\n2           1956         3075  1008ddt\n3           1152         1642  100dcrd\n4           1152         1152  100jl1b\n...          ...          ...      ...\n3504        1080         1350   zzr9nz\n3505         570          704   zzruf4\n3506        2309         2560   zzu8i8\n3507        1440         1800   zzvv3x\n3508        1075         1351   zzxq2l\n\n[3509 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>meta_width</th>\n      <th>meta_height</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1468</td>\n      <td>2608</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1523</td>\n      <td>2030</td>\n      <td>1003dod</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956</td>\n      <td>3075</td>\n      <td>1008ddt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1152</td>\n      <td>1642</td>\n      <td>100dcrd</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1152</td>\n      <td>1152</td>\n      <td>100jl1b</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3504</th>\n      <td>1080</td>\n      <td>1350</td>\n      <td>zzr9nz</td>\n    </tr>\n    <tr>\n      <th>3505</th>\n      <td>570</td>\n      <td>704</td>\n      <td>zzruf4</td>\n    </tr>\n    <tr>\n      <th>3506</th>\n      <td>2309</td>\n      <td>2560</td>\n      <td>zzu8i8</td>\n    </tr>\n    <tr>\n      <th>3507</th>\n      <td>1440</td>\n      <td>1800</td>\n      <td>zzvv3x</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>1075</td>\n      <td>1351</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>3509 rows √ó 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 125 ms\n",
      "Wall time: 218 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "display(new_captions)\n",
    "display(new_tags)\n",
    "display(new_crops)\n",
    "display(new_basic_captions)\n",
    "display(meta)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:53.743571100Z",
     "start_time": "2023-05-12T22:16:52.618942900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                     captions_text  captions_confidence   \n0                          a woman taking a selfie             0.662057  \\\n1     a woman in a garment standing next to a tree             0.513081   \n2                          a woman taking a selfie             0.658102   \n3            a group of women posing for a picture             0.556227   \n4            a group of women posing for a picture             0.614969   \n...                                            ...                  ...   \n3504              two women in garments on a beach             0.529292   \n3505               a woman with tattoos on her arm             0.501798   \n3506                    a woman in a blue lingerie             0.430763   \n3507                      a woman sitting on a bed             0.584322   \n3508       a woman in a dress posing for a picture             0.460149   \n\n           id  meta_width  meta_height  \n0     1002cx2        1468         2608  \n1     1003dod        1523         2030  \n2     1008ddt        1956         3075  \n3     100dcrd        1152         1642  \n4     100jl1b        1152         1152  \n...       ...         ...          ...  \n3504   zzr9nz        1080         1350  \n3505   zzruf4         570          704  \n3506   zzu8i8        2309         2560  \n3507   zzvv3x        1440         1800  \n3508   zzxq2l        1075         1351  \n\n[3509 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>captions_text</th>\n      <th>captions_confidence</th>\n      <th>id</th>\n      <th>meta_width</th>\n      <th>meta_height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a woman taking a selfie</td>\n      <td>0.662057</td>\n      <td>1002cx2</td>\n      <td>1468</td>\n      <td>2608</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a woman in a garment standing next to a tree</td>\n      <td>0.513081</td>\n      <td>1003dod</td>\n      <td>1523</td>\n      <td>2030</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a woman taking a selfie</td>\n      <td>0.658102</td>\n      <td>1008ddt</td>\n      <td>1956</td>\n      <td>3075</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a group of women posing for a picture</td>\n      <td>0.556227</td>\n      <td>100dcrd</td>\n      <td>1152</td>\n      <td>1642</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a group of women posing for a picture</td>\n      <td>0.614969</td>\n      <td>100jl1b</td>\n      <td>1152</td>\n      <td>1152</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3504</th>\n      <td>two women in garments on a beach</td>\n      <td>0.529292</td>\n      <td>zzr9nz</td>\n      <td>1080</td>\n      <td>1350</td>\n    </tr>\n    <tr>\n      <th>3505</th>\n      <td>a woman with tattoos on her arm</td>\n      <td>0.501798</td>\n      <td>zzruf4</td>\n      <td>570</td>\n      <td>704</td>\n    </tr>\n    <tr>\n      <th>3506</th>\n      <td>a woman in a blue lingerie</td>\n      <td>0.430763</td>\n      <td>zzu8i8</td>\n      <td>2309</td>\n      <td>2560</td>\n    </tr>\n    <tr>\n      <th>3507</th>\n      <td>a woman sitting on a bed</td>\n      <td>0.584322</td>\n      <td>zzvv3x</td>\n      <td>1440</td>\n      <td>1800</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>a woman in a dress posing for a picture</td>\n      <td>0.460149</td>\n      <td>zzxq2l</td>\n      <td>1075</td>\n      <td>1351</td>\n    </tr>\n  </tbody>\n</table>\n<p>3509 rows √ó 5 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_singles = pandas.merge(new_basic_captions, meta, on='id').set_index(keys=['id'], drop=False)\n",
    "merge_singles.drop_duplicates(inplace=True)\n",
    "merge_singles.reset_index(drop=True, inplace=True)\n",
    "display(merge_singles)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:53.946698800Z",
     "start_time": "2023-05-12T22:16:52.852947100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        captions_text captions_confidence   \nid                                                                          \n1002cx2                       a woman taking a selfie            0.662057  \\\n1003dod  a woman in a garment standing next to a tree            0.513081   \n1008ddt                       a woman taking a selfie            0.658102   \n100dcrd         a group of women posing for a picture            0.556227   \n100jl1b         a group of women posing for a picture            0.614969   \n...                                               ...                 ...   \n13d2hsf                                                                     \n13d661b                                                                     \n13d8s0i                                                                     \n13dagbr                                                                     \n13dbhn4                                                                     \n\n              id meta_width meta_height         subreddit   \nid                                                          \n1002cx2  1002cx2     1468.0      2608.0       SFWRedheads  \\\n1003dod  1003dod     1523.0      2030.0   HotGirlNextDoor   \n1008ddt  1008ddt     1956.0      3075.0       SFWRedheads   \n100dcrd  100dcrd     1152.0      1642.0   HotGirlNextDoor   \n100jl1b  100jl1b     1152.0      1152.0   HotGirlNextDoor   \n...          ...        ...         ...               ...   \n13d2hsf  13d2hsf                         bathandbodyworks   \n13d661b  13d661b                         bathandbodyworks   \n13d8s0i  13d8s0i                         bathandbodyworks   \n13dagbr  13dagbr                         bathandbodyworks   \n13dbhn4  13dbhn4                         bathandbodyworks   \n\n                       author   \nid                              \n1002cx2          Sayleywayley  \\\n1003dod          fairytale808   \n1008ddt   Fit_Advertising4668   \n100dcrd               angizni   \n100jl1b               angizni   \n...                       ...   \n13d2hsf           alesieoksap   \n13d661b                xeloux   \n13d8s0i  Alternative-Tea-9355   \n13dagbr                Dove04   \n13dbhn4         Thebigbooty01   \n\n                                                     title   \nid                                                           \n1002cx2  Happy New Year to every single person near and...  \\\n1003dod                             pink and blonde (iktr)   \n1008ddt               happy new year from Scotland üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø   \n100dcrd                             College hotties (iktr)   \n100jl1b                            Sorority hotties (iktr)   \n...                                                    ...   \n13d2hsf                         Ice Cream Shop Collection?   \n13d661b                             Facebook market finds!   \n13d8s0i                           Black Cherry Merlot dupe   \n13dagbr  Does anyone know how I could get rid of this r...   \n13dbhn4                               Gratis today at work   \n\n                                                   caption   \nid                                                           \n1002cx2  blonde woman with red hair and black bra top p...  \\\n1003dod  blonde woman in pink bikinisuit standing on a ...   \n1008ddt  smiling woman in a green velvet dress with a g...   \n100dcrd  three girls in bikinis posing for a picture wi...   \n100jl1b  three women in red dresses standing next to ea...   \n...                                                    ...   \n13d2hsf   someone holding a cup of ice cream in their hand   \n13d661b    three candles are sitting on a blanket on a bed   \n13d8s0i    someone holding a tube of body cream in a store   \n13dagbr  someone is holding a white device with a hole ...   \n13dbhn4  there are some bottles of bath and body produc...   \n\n                                     hash   \nid                                          \n1002cx2  1fb785ca16b10f4f7613961f0b88f369  \\\n1003dod  0849c7aafe126ad27b58cb6e6c9c6592   \n1008ddt  945b3f444ccaa79f73655fa44bd6a156   \n100dcrd  f07022ea6fac84354178a09e92dc3865   \n100jl1b  6cdfb6741d444b243542ae7d40f57b40   \n...                                   ...   \n13d2hsf  c6788074138175c661fc652bd7630e33   \n13d661b  e868289445c195815dd67dd0df1a65cb   \n13d8s0i  965bc5a58a597192700234729758101b   \n13dagbr  41732e4109a99c99c91c2181867d18e3   \n13dbhn4  f2afdcbed21cc1f44ac757bf2f797ae6   \n\n                                                 permalink   \nid                                                           \n1002cx2  /r/SFWRedheads/comments/1002cx2/happy_new_year...  \\\n1003dod  /r/HotGirlNextDoor/comments/1003dod/pink_and_b...   \n1008ddt  /r/SFWRedheads/comments/1008ddt/happy_new_year...   \n100dcrd  /r/HotGirlNextDoor/comments/100dcrd/college_ho...   \n100jl1b  /r/HotGirlNextDoor/comments/100jl1b/sorority_h...   \n...                                                    ...   \n13d2hsf  /r/bathandbodyworks/comments/13d2hsf/ice_cream...   \n13d661b  /r/bathandbodyworks/comments/13d661b/facebook_...   \n13d8s0i  /r/bathandbodyworks/comments/13d8s0i/black_che...   \n13dagbr  /r/bathandbodyworks/comments/13dagbr/does_anyo...   \n13dbhn4  /r/bathandbodyworks/comments/13dbhn4/gratis_to...   \n\n                                original_url   image_name   \nid                                                          \n1002cx2  https://i.redd.it/el3s490lzb9a1.jpg  1002cx2.jpg  \\\n1003dod  https://i.redd.it/x56eekrd8c9a1.jpg  1003dod.jpg   \n1008ddt  https://i.redd.it/rdywcwiyhd9a1.jpg  1008ddt.jpg   \n100dcrd  https://i.redd.it/bm6jpns80f9a1.jpg  100dcrd.jpg   \n100jl1b  https://i.redd.it/wfxx3uc35h9a1.jpg  100jl1b.jpg   \n...                                      ...          ...   \n13d2hsf  https://i.redd.it/uhwamoq99wya1.jpg  13d2hsf.jpg   \n13d661b  https://i.redd.it/skd10hefxwya1.jpg  13d661b.jpg   \n13d8s0i  https://i.redd.it/xt7qew9qexya1.jpg  13d8s0i.jpg   \n13dagbr  https://i.redd.it/p0j6atz6rxya1.jpg  13dagbr.jpg   \n13dbhn4  https://i.redd.it/x954qki8zxya1.jpg  13dbhn4.jpg   \n\n                           path             model  exists  curated  accept   \nid                                                                           \n1002cx2  data/image/1002cx2.jpg  RedHeadDiffusion    True     True    True  \\\n1003dod  data/image/1003dod.jpg     SexyDiffusion    True     True    True   \n1008ddt  data/image/1008ddt.jpg  RedHeadDiffusion    True     True    True   \n100dcrd  data/image/100dcrd.jpg     SexyDiffusion    True     True    True   \n100jl1b  data/image/100jl1b.jpg     SexyDiffusion    True     True    True   \n...                         ...               ...     ...      ...     ...   \n13d2hsf  data/image/13d2hsf.jpg   CandleDiffusion    True     True    True   \n13d661b  data/image/13d661b.jpg   CandleDiffusion    True     True    True   \n13d8s0i  data/image/13d8s0i.jpg   CandleDiffusion    True     True   False   \n13dagbr  data/image/13dagbr.jpg   CandleDiffusion    True     True   False   \n13dbhn4  data/image/13dbhn4.jpg   CandleDiffusion    True     True    True   \n\n        tags  \nid            \n1002cx2   []  \n1003dod   []  \n1008ddt   []  \n100dcrd   []  \n100jl1b   []  \n...      ...  \n13d2hsf   []  \n13d661b   []  \n13d8s0i   []  \n13dagbr   []  \n13dbhn4   []  \n\n[37031 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>captions_text</th>\n      <th>captions_confidence</th>\n      <th>id</th>\n      <th>meta_width</th>\n      <th>meta_height</th>\n      <th>subreddit</th>\n      <th>author</th>\n      <th>title</th>\n      <th>caption</th>\n      <th>hash</th>\n      <th>permalink</th>\n      <th>original_url</th>\n      <th>image_name</th>\n      <th>path</th>\n      <th>model</th>\n      <th>exists</th>\n      <th>curated</th>\n      <th>accept</th>\n      <th>tags</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1002cx2</th>\n      <td>a woman taking a selfie</td>\n      <td>0.662057</td>\n      <td>1002cx2</td>\n      <td>1468.0</td>\n      <td>2608.0</td>\n      <td>SFWRedheads</td>\n      <td>Sayleywayley</td>\n      <td>Happy New Year to every single person near and...</td>\n      <td>blonde woman with red hair and black bra top p...</td>\n      <td>1fb785ca16b10f4f7613961f0b88f369</td>\n      <td>/r/SFWRedheads/comments/1002cx2/happy_new_year...</td>\n      <td>https://i.redd.it/el3s490lzb9a1.jpg</td>\n      <td>1002cx2.jpg</td>\n      <td>data/image/1002cx2.jpg</td>\n      <td>RedHeadDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1003dod</th>\n      <td>a woman in a garment standing next to a tree</td>\n      <td>0.513081</td>\n      <td>1003dod</td>\n      <td>1523.0</td>\n      <td>2030.0</td>\n      <td>HotGirlNextDoor</td>\n      <td>fairytale808</td>\n      <td>pink and blonde (iktr)</td>\n      <td>blonde woman in pink bikinisuit standing on a ...</td>\n      <td>0849c7aafe126ad27b58cb6e6c9c6592</td>\n      <td>/r/HotGirlNextDoor/comments/1003dod/pink_and_b...</td>\n      <td>https://i.redd.it/x56eekrd8c9a1.jpg</td>\n      <td>1003dod.jpg</td>\n      <td>data/image/1003dod.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1008ddt</th>\n      <td>a woman taking a selfie</td>\n      <td>0.658102</td>\n      <td>1008ddt</td>\n      <td>1956.0</td>\n      <td>3075.0</td>\n      <td>SFWRedheads</td>\n      <td>Fit_Advertising4668</td>\n      <td>happy new year from Scotland üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø</td>\n      <td>smiling woman in a green velvet dress with a g...</td>\n      <td>945b3f444ccaa79f73655fa44bd6a156</td>\n      <td>/r/SFWRedheads/comments/1008ddt/happy_new_year...</td>\n      <td>https://i.redd.it/rdywcwiyhd9a1.jpg</td>\n      <td>1008ddt.jpg</td>\n      <td>data/image/1008ddt.jpg</td>\n      <td>RedHeadDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>100dcrd</th>\n      <td>a group of women posing for a picture</td>\n      <td>0.556227</td>\n      <td>100dcrd</td>\n      <td>1152.0</td>\n      <td>1642.0</td>\n      <td>HotGirlNextDoor</td>\n      <td>angizni</td>\n      <td>College hotties (iktr)</td>\n      <td>three girls in bikinis posing for a picture wi...</td>\n      <td>f07022ea6fac84354178a09e92dc3865</td>\n      <td>/r/HotGirlNextDoor/comments/100dcrd/college_ho...</td>\n      <td>https://i.redd.it/bm6jpns80f9a1.jpg</td>\n      <td>100dcrd.jpg</td>\n      <td>data/image/100dcrd.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>100jl1b</th>\n      <td>a group of women posing for a picture</td>\n      <td>0.614969</td>\n      <td>100jl1b</td>\n      <td>1152.0</td>\n      <td>1152.0</td>\n      <td>HotGirlNextDoor</td>\n      <td>angizni</td>\n      <td>Sorority hotties (iktr)</td>\n      <td>three women in red dresses standing next to ea...</td>\n      <td>6cdfb6741d444b243542ae7d40f57b40</td>\n      <td>/r/HotGirlNextDoor/comments/100jl1b/sorority_h...</td>\n      <td>https://i.redd.it/wfxx3uc35h9a1.jpg</td>\n      <td>100jl1b.jpg</td>\n      <td>data/image/100jl1b.jpg</td>\n      <td>SexyDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13d2hsf</th>\n      <td></td>\n      <td></td>\n      <td>13d2hsf</td>\n      <td></td>\n      <td></td>\n      <td>bathandbodyworks</td>\n      <td>alesieoksap</td>\n      <td>Ice Cream Shop Collection?</td>\n      <td>someone holding a cup of ice cream in their hand</td>\n      <td>c6788074138175c661fc652bd7630e33</td>\n      <td>/r/bathandbodyworks/comments/13d2hsf/ice_cream...</td>\n      <td>https://i.redd.it/uhwamoq99wya1.jpg</td>\n      <td>13d2hsf.jpg</td>\n      <td>data/image/13d2hsf.jpg</td>\n      <td>CandleDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>13d661b</th>\n      <td></td>\n      <td></td>\n      <td>13d661b</td>\n      <td></td>\n      <td></td>\n      <td>bathandbodyworks</td>\n      <td>xeloux</td>\n      <td>Facebook market finds!</td>\n      <td>three candles are sitting on a blanket on a bed</td>\n      <td>e868289445c195815dd67dd0df1a65cb</td>\n      <td>/r/bathandbodyworks/comments/13d661b/facebook_...</td>\n      <td>https://i.redd.it/skd10hefxwya1.jpg</td>\n      <td>13d661b.jpg</td>\n      <td>data/image/13d661b.jpg</td>\n      <td>CandleDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>13d8s0i</th>\n      <td></td>\n      <td></td>\n      <td>13d8s0i</td>\n      <td></td>\n      <td></td>\n      <td>bathandbodyworks</td>\n      <td>Alternative-Tea-9355</td>\n      <td>Black Cherry Merlot dupe</td>\n      <td>someone holding a tube of body cream in a store</td>\n      <td>965bc5a58a597192700234729758101b</td>\n      <td>/r/bathandbodyworks/comments/13d8s0i/black_che...</td>\n      <td>https://i.redd.it/xt7qew9qexya1.jpg</td>\n      <td>13d8s0i.jpg</td>\n      <td>data/image/13d8s0i.jpg</td>\n      <td>CandleDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>13dagbr</th>\n      <td></td>\n      <td></td>\n      <td>13dagbr</td>\n      <td></td>\n      <td></td>\n      <td>bathandbodyworks</td>\n      <td>Dove04</td>\n      <td>Does anyone know how I could get rid of this r...</td>\n      <td>someone is holding a white device with a hole ...</td>\n      <td>41732e4109a99c99c91c2181867d18e3</td>\n      <td>/r/bathandbodyworks/comments/13dagbr/does_anyo...</td>\n      <td>https://i.redd.it/p0j6atz6rxya1.jpg</td>\n      <td>13dagbr.jpg</td>\n      <td>data/image/13dagbr.jpg</td>\n      <td>CandleDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>13dbhn4</th>\n      <td></td>\n      <td></td>\n      <td>13dbhn4</td>\n      <td></td>\n      <td></td>\n      <td>bathandbodyworks</td>\n      <td>Thebigbooty01</td>\n      <td>Gratis today at work</td>\n      <td>there are some bottles of bath and body produc...</td>\n      <td>f2afdcbed21cc1f44ac757bf2f797ae6</td>\n      <td>/r/bathandbodyworks/comments/13dbhn4/gratis_to...</td>\n      <td>https://i.redd.it/x954qki8zxya1.jpg</td>\n      <td>13dbhn4.jpg</td>\n      <td>data/image/13dbhn4.jpg</td>\n      <td>CandleDiffusion</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>37031 rows √ó 19 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_to_curate = pandas.merge(merge_singles, curated_df, on='id', how='outer').set_index(keys=['id'], drop=False)\n",
    "merged_to_curate.fillna(value='', inplace=True)\n",
    "display(merged_to_curate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:54.681078100Z",
     "start_time": "2023-05-12T22:16:52.977946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'0 new rows added to captions'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                    dense_captions_text  dense_captions_confidence   \n0               a woman taking a selfie                   0.662057  \\\n1               a woman taking a selfie                   0.665344   \n2         a woman wearing a black dress                   0.473444   \n3                   a close up of a key                   0.593095   \n4                  a close up of an eye                   0.619898   \n...                                 ...                        ...   \n31175       a close-up of a green plant                   0.453059   \n31176  a mountain range in the distance                   0.334624   \n31177     a woman smiling at the camera                   0.465720   \n31178           a woman wearing a dress                   0.548892   \n31179              a close up of a hand                   0.566506   \n\n       dense_captions_boundingBox.x  dense_captions_boundingBox.y   \n0                                 0                             0  \\\n1                                 0                           100   \n2                               185                          1443   \n3                               716                          1503   \n4                               778                           744   \n...                             ...                           ...   \n31175                           680                          1066   \n31176                           498                           277   \n31177                           244                           293   \n31178                             0                           758   \n31179                           220                           809   \n\n       dense_captions_boundingBox.w  dense_captions_boundingBox.h       id  \n0                              1468                          2608  1002cx2  \n1                              1447                          2473  1002cx2  \n2                              1265                          1150  1002cx2  \n3                                82                           140  1002cx2  \n4                               152                            84  1002cx2  \n...                             ...                           ...      ...  \n31175                           394                           280   zzxq2l  \n31176                           568                            99   zzxq2l  \n31177                           319                           530   zzxq2l  \n31178                          1048                           570   zzxq2l  \n31179                            73                            55   zzxq2l  \n\n[31180 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dense_captions_text</th>\n      <th>dense_captions_confidence</th>\n      <th>dense_captions_boundingBox.x</th>\n      <th>dense_captions_boundingBox.y</th>\n      <th>dense_captions_boundingBox.w</th>\n      <th>dense_captions_boundingBox.h</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a woman taking a selfie</td>\n      <td>0.662057</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1468</td>\n      <td>2608</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a woman taking a selfie</td>\n      <td>0.665344</td>\n      <td>0</td>\n      <td>100</td>\n      <td>1447</td>\n      <td>2473</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a woman wearing a black dress</td>\n      <td>0.473444</td>\n      <td>185</td>\n      <td>1443</td>\n      <td>1265</td>\n      <td>1150</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a close up of a key</td>\n      <td>0.593095</td>\n      <td>716</td>\n      <td>1503</td>\n      <td>82</td>\n      <td>140</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>a close up of an eye</td>\n      <td>0.619898</td>\n      <td>778</td>\n      <td>744</td>\n      <td>152</td>\n      <td>84</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31175</th>\n      <td>a close-up of a green plant</td>\n      <td>0.453059</td>\n      <td>680</td>\n      <td>1066</td>\n      <td>394</td>\n      <td>280</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31176</th>\n      <td>a mountain range in the distance</td>\n      <td>0.334624</td>\n      <td>498</td>\n      <td>277</td>\n      <td>568</td>\n      <td>99</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31177</th>\n      <td>a woman smiling at the camera</td>\n      <td>0.465720</td>\n      <td>244</td>\n      <td>293</td>\n      <td>319</td>\n      <td>530</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31178</th>\n      <td>a woman wearing a dress</td>\n      <td>0.548892</td>\n      <td>0</td>\n      <td>758</td>\n      <td>1048</td>\n      <td>570</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>31179</th>\n      <td>a close up of a hand</td>\n      <td>0.566506</td>\n      <td>220</td>\n      <td>809</td>\n      <td>73</td>\n      <td>55</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>31180 rows √ó 7 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 562 ms\n",
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "merged_captions = pandas.concat([new_captions, captions])\n",
    "merged_captions.set_index(keys=['id', 'dense_captions_text', 'dense_captions_confidence'], inplace=True, drop=False)\n",
    "merged_captions.drop_duplicates(inplace=True)\n",
    "merged_captions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(f'{merged_captions.shape[0] - captions.shape[0]} new rows added to captions')\n",
    "\n",
    "merged_captions.to_parquet('data/parquet/image_captions.parquet', filesystem=file_system, engine='pyarrow')\n",
    "display(pandas.read_parquet('data/parquet/image_captions.parquet', filesystem=file_system, engine='pyarrow'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:56.407681400Z",
     "start_time": "2023-05-12T22:16:54.181073600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'0 new rows added to tags'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        tags_name  tags_confidence       id\n0          person         0.998358  1002cx2\n1      human face         0.997763  1002cx2\n2        clothing         0.990993  1002cx2\n3            lady         0.981919  1002cx2\n4           smile         0.964994  1002cx2\n...           ...              ...      ...\n71148       woman         0.753262   zzxq2l\n71149       beach         0.739799   zzxq2l\n71150    standing         0.630927   zzxq2l\n71151        girl         0.556561   zzxq2l\n71152    mountain         0.544261   zzxq2l\n\n[71153 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tags_name</th>\n      <th>tags_confidence</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>person</td>\n      <td>0.998358</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>human face</td>\n      <td>0.997763</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>clothing</td>\n      <td>0.990993</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>lady</td>\n      <td>0.981919</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>smile</td>\n      <td>0.964994</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71148</th>\n      <td>woman</td>\n      <td>0.753262</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71149</th>\n      <td>beach</td>\n      <td>0.739799</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71150</th>\n      <td>standing</td>\n      <td>0.630927</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71151</th>\n      <td>girl</td>\n      <td>0.556561</td>\n      <td>zzxq2l</td>\n    </tr>\n    <tr>\n      <th>71152</th>\n      <td>mountain</td>\n      <td>0.544261</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>71153 rows √ó 3 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 625 ms\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "merged_tags = pandas.concat([new_tags, tags])\n",
    "merged_tags.set_index(keys=['id', 'tags_name', 'tags_confidence'], inplace=True, drop=False)\n",
    "merged_tags.drop_duplicates(inplace=True)\n",
    "merged_tags.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(f'{merged_tags.shape[0] - tags.shape[0]} new rows added to tags')\n",
    "\n",
    "merged_tags.to_parquet('data/parquet/image_tags.parquet', filesystem=file_system, engine='pyarrow')\n",
    "display(pandas.read_parquet('data/parquet/image_tags.parquet', filesystem=file_system, engine='pyarrow'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:58.212716100Z",
     "start_time": "2023-05-12T22:16:56.009197700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'0 new rows added to crops'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "      smart_crop_aspectRatio  smart_crop_boundingBox.x   \n0                        1.0                         0  \\\n1                        1.0                       143   \n2                        1.0                         0   \n3                        1.0                         0   \n4                        1.0                         0   \n...                      ...                       ...   \n3504                     1.0                         0   \n3505                     1.0                         0   \n3506                     1.0                         0   \n3507                     1.0                       135   \n3508                     1.0                       101   \n\n      smart_crop_boundingBox.y  smart_crop_boundingBox.w   \n0                          140                      1462  \\\n1                          138                      1249   \n2                          355                      1948   \n3                          224                      1120   \n4                            0                      1107   \n...                        ...                       ...   \n3504                         0                      1025   \n3505                         0                       461   \n3506                         0                      2273   \n3507                         0                      1299   \n3508                       101                       970   \n\n      smart_crop_boundingBox.h       id  \n0                         1462  1002cx2  \n1                         1250  1003dod  \n2                         1948  1008ddt  \n3                         1120  100dcrd  \n4                         1107  100jl1b  \n...                        ...      ...  \n3504                      1025   zzr9nz  \n3505                       461   zzruf4  \n3506                      2273   zzu8i8  \n3507                      1299   zzvv3x  \n3508                       970   zzxq2l  \n\n[3509 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>smart_crop_aspectRatio</th>\n      <th>smart_crop_boundingBox.x</th>\n      <th>smart_crop_boundingBox.y</th>\n      <th>smart_crop_boundingBox.w</th>\n      <th>smart_crop_boundingBox.h</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>1462</td>\n      <td>1462</td>\n      <td>1002cx2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>143</td>\n      <td>138</td>\n      <td>1249</td>\n      <td>1250</td>\n      <td>1003dod</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>355</td>\n      <td>1948</td>\n      <td>1948</td>\n      <td>1008ddt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>224</td>\n      <td>1120</td>\n      <td>1120</td>\n      <td>100dcrd</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1107</td>\n      <td>1107</td>\n      <td>100jl1b</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3504</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1025</td>\n      <td>1025</td>\n      <td>zzr9nz</td>\n    </tr>\n    <tr>\n      <th>3505</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>461</td>\n      <td>461</td>\n      <td>zzruf4</td>\n    </tr>\n    <tr>\n      <th>3506</th>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2273</td>\n      <td>2273</td>\n      <td>zzu8i8</td>\n    </tr>\n    <tr>\n      <th>3507</th>\n      <td>1.0</td>\n      <td>135</td>\n      <td>0</td>\n      <td>1299</td>\n      <td>1299</td>\n      <td>zzvv3x</td>\n    </tr>\n    <tr>\n      <th>3508</th>\n      <td>1.0</td>\n      <td>101</td>\n      <td>101</td>\n      <td>970</td>\n      <td>970</td>\n      <td>zzxq2l</td>\n    </tr>\n  </tbody>\n</table>\n<p>3509 rows √ó 6 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 578 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "merged_crops = pandas.concat([new_crops, crops])\n",
    "merged_crops.set_index(keys=['id'], inplace=True, drop=False)\n",
    "merged_crops.drop_duplicates(inplace=True)\n",
    "merged_crops.reset_index(drop=True, inplace=True)\n",
    "\n",
    "display(f'{merged_crops.shape[0] - crops.shape[0]} new rows added to crops')\n",
    "\n",
    "merged_crops.to_parquet('data/parquet/image_cropping.parquet', filesystem=file_system, engine='pyarrow')\n",
    "\n",
    "display(pandas.read_parquet('data/parquet/image_cropping.parquet', filesystem=file_system, engine='pyarrow'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:58.837393300Z",
     "start_time": "2023-05-12T22:16:58.243898800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import os\n",
    "def create_thumbnail(image_id_, curated_df_, crops_, extant_files_):\n",
    "\ttry:\n",
    "\t\trecord = None\n",
    "\t\tcropping_information = None\n",
    "\t\tif image_id_ in extant_files_:\n",
    "\t\t\treturn None\n",
    "\t\ttry:\n",
    "\t\t\trecord = curated_df.loc[curated_df['id'] == image_id_]\n",
    "\t\t\tcropping_information = crops.loc[crops['id'] == image_id_]\n",
    "\t\texcept KeyError or IndexError:\n",
    "\t\t\treturn None\n",
    "\t\tif record is None and cropping_information is None and len(record) == 0 and len(cropping_information) == 0:\n",
    "\t\t\treturn None\n",
    "\t\tif record is not None and cropping_information is not None:\n",
    "\t\t\trecord = curated_df_.loc[curated_df_['id'] == image_id_]\n",
    "\t\t\tcropping_information = crops_.loc[crops['id'] == image_id_]\n",
    "\t\t\ttry:\n",
    "\t\t\t\timage_url = file_system.url(record.path.values[0])\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tdisplay(f'Error creating thumbnail for {image_id_}: {e}', clear=True)\n",
    "\t\t\t\treturn None\n",
    "\t\t\toriginal_image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\t\t\tcopied_image = original_image.copy()\n",
    "\t\t\toriginal_image.close()\n",
    "\t\t\ttry:\n",
    "\t\t\t\tcropped = copied_image.crop((cropping_information['smart_crop_boundingBox.x'].values[0], cropping_information['smart_crop_boundingBox.y'].values[0], cropping_information['smart_crop_boundingBox.x'].values[0] + cropping_information['smart_crop_boundingBox.w'].values[0], cropping_information['smart_crop_boundingBox.y'].values[0] + cropping_information['smart_crop_boundingBox.h'].values[0]))\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tdisplay(f'Error creating thumbnail for {image_id_}: {e}', clear=True)\n",
    "\t\t\t\treturn None\n",
    "\t\t\tcopied_image.close()\n",
    "\t\t\tresized = cropped.resize((512, 512), 1)\n",
    "\t\t\tcropped.close()\n",
    "\t\t\tresized.save('temp.jpg')\n",
    "\t\t\tfile_system.upload('temp.jpg', f'data/image/thumbnail/{image_id_}.jpg', overwrite=True)\n",
    "\t\t\tdisplay(f'Thumbnail created for {image_id_}', clear=True)\n",
    "\t\t\treturn None\n",
    "\t\telse:\n",
    "\t\t\treturn None\n",
    "\texcept Exception as e:\n",
    "\t\tdisplay(f'Error creating thumbnail for {image_id_}: {e}', clear=True)\n",
    "\t\treturn None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:16:58.962378900Z",
     "start_time": "2023-05-12T22:16:58.837393300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "['1011gjo',\n '1013bdt',\n '1019kyo',\n '101w7lh',\n '1027i9a',\n '1032j8y',\n '1035nya',\n '103h4hd',\n '103nm31',\n '103zqoc',\n '104it0i',\n '105dxeb',\n '105mekt',\n '105qvgl',\n '105rpcj',\n '105styc',\n '105tw6t',\n '106673i',\n '106hchf',\n '106lsw4',\n '106mh03',\n '108e7ml',\n '1096qs1',\n '109n66u',\n '109x870',\n '10bdmd2',\n '10bpm50',\n '10ce95f',\n '10cywc7',\n '10dgnk2',\n '10f78ow',\n '10gliq7',\n '10gzlqt',\n '10ht3qh',\n '10i05he',\n '10i1flv',\n '10i1qkq',\n '10i56sz',\n '10i8he7',\n '10iuhd0',\n '10jefuk',\n '10jvfeb',\n '10lhpa1',\n '10mabxc',\n '10nyadr',\n '10o96va',\n '10odumt',\n '10ok9gc',\n '10olva7',\n '10onw06',\n '10osnnk',\n '10pl8zt',\n '10pq54f',\n '10prtpi',\n '10q17m7',\n '10q1t59',\n '10q46tx',\n '10q6wg2',\n '10q8gj9',\n '10q97um',\n '10qddse',\n '10qdfml',\n '10qizmn',\n '10rrt8z',\n '10s97lu',\n '10v8oqk',\n '10vqm17',\n '110xnuk',\n '112nsvw',\n '115h657',\n '116vz5e',\n '11gpbyp',\n '11jmesr',\n '11lk9x2',\n '11pgiwg',\n '11v9eir',\n '1213x1h',\n '124poau',\n '1271iyi',\n '1282v0e',\n '128n9ri',\n '129m4ch',\n '129z5l8',\n '12ag6n1',\n '12c14gw',\n '12e5wtg',\n '12em94b',\n '12f7rgw',\n '12g1ip4',\n '12gk9cx',\n '12hjo1f',\n '12hrfjj',\n '12ispa4',\n '12j61te',\n '12jrcj3',\n '12kq7eh',\n '12lsqqz',\n '12ly8fn',\n '12n3cmy',\n '12rcsp5',\n '12szmth',\n '12tifon',\n '12u2nyx',\n '12v27qb',\n '12vm0v4',\n '12vrljn',\n '12w4kvz',\n '12wyxah',\n '12xbi1u',\n '12xgrad',\n '12ygbgq',\n '12zih7h',\n '1306lqa',\n '130n2np',\n '131egj6',\n 'ovjlv5',\n 'owf3s1',\n 'p1fpjz',\n 'panwn2',\n 'pdmm4y',\n 'pfuh8t',\n 'pgvp4h',\n 'ph5q2d',\n 'phiook',\n 'pi4awt',\n 'pidleo',\n 'pkb2n3',\n 'pkyd6m',\n 'po3chf',\n 'ppr179',\n 'pqdma0',\n 'pv7ag5',\n 'q1wyg7',\n 'qnrbfd',\n 'qpu7kp',\n 'qq5i1h',\n 'qqkgvq',\n 'qqwagg',\n 'qrb7vg',\n 'qsczom',\n 'qsrrjz',\n 'qwrkke',\n 'qx6lrn',\n 'qz1170',\n 'r0370j',\n 'r0f30g',\n 'r17403',\n 'r1m8sl',\n 'r4xngm',\n 'r5p39b',\n 'r7omrf',\n 'rc80m5',\n 'rfhlq5',\n 'rjyeo4',\n 'rl4h65',\n 'rmxga7',\n 'ro0yq5',\n 'ronq8i',\n 'rppalm',\n 'rsjpf2',\n 'rt9yt6',\n 'rvwanf',\n 'rxwsks',\n 'rztg0h',\n 's1vgzb',\n 's9sf2n',\n 'scvj30',\n 'sd7w5e',\n 'sdo13c',\n 'sfjsu2',\n 'sh35zl',\n 'shk8bp',\n 'sidlkn',\n 'siqpjp',\n 'slyn5f',\n 'smffs6',\n 'sms7eq',\n 'sofldd',\n 'sq1cq8',\n 'sqtcc5',\n 'stl5nc',\n 'sycifr',\n 'sypm8x',\n 'sz6eqz',\n 'szjgor',\n 't3558y',\n 't5hgxe',\n 't5tg7f',\n 't6ktt2',\n 't7ph0b',\n 't96vhk',\n 'tbry1x',\n 'tdnjcs',\n 'tdzfsx',\n 'tef2y0',\n 'tg0c94',\n 'tjdr7s',\n 'tkkd95',\n 'trvmnw',\n 'ts732c',\n 'tsp3t9',\n 'ttrdj4',\n 'tvqba6',\n 'tydqh1',\n 'u0wqvx',\n 'u48oz1',\n 'u5ctfw',\n 'u8ob3l',\n 'uak9vn',\n 'ubltiy',\n 'ucd7yf',\n 'udvo1p',\n 'ugqaap',\n 'ujcvfc',\n 'ul2c40',\n 'upvqea',\n 'uud6pl',\n 'uxww5r',\n 'uzdbpw',\n 'v01c06',\n 'v0pocd',\n 'v2607q',\n 'v401ku',\n 'v4pgsb',\n 'v6wdeo',\n 'v8wsk9',\n 'v98eiv',\n 'vamkno',\n 'vc44x4',\n 'vedupb',\n 'vevsdo',\n 'vf6uh6',\n 'vgaand',\n 'vlw6ho',\n 'vngi28',\n 'vnwlwf',\n 'vop36i',\n 'vr829v',\n 'vvgvix',\n 'vwzhrq',\n 'vy3xch',\n 'w0w9hx',\n 'w181qg',\n 'w1nltk',\n 'w3n2au',\n 'w4ycew',\n 'w64p23',\n 'w6w9ln',\n 'w7pphj',\n 'w91wqk',\n 'wblx1m',\n 'wby6l4',\n 'wcpeha',\n 'wecfo5',\n 'whozvs',\n 'wk420n',\n 'wkl61z',\n 'wm8vt6',\n 'wmlzn3',\n 'wp0er7',\n 'wphp67',\n 'wpv382',\n 'wr6v9q',\n 'ws1fzo',\n 'wser0x',\n 'wsvc7q',\n 'wt7swe',\n 'wu0afd',\n 'wxwc1t',\n 'wzjnee',\n 'x2v8nr',\n 'x38f5f',\n 'x3p6w8',\n 'x6409n',\n 'x7sjjm',\n 'xad1jo',\n 'xaq42q',\n 'xc0b0q',\n 'xcuwep',\n 'xdpd1f',\n 'xe2r0s',\n 'xexlkr',\n 'xfehhq',\n 'xgn9pv',\n 'xhhf1f',\n 'xicvg5',\n 'xivtvf',\n 'xmfyvn',\n 'xmtmgr',\n 'xnaj64',\n 'xp36c1',\n 'xphkp1',\n 'xqdim7',\n 'xqv71d',\n 'xtcjhu',\n 'xtpj5l',\n 'xu6e8s',\n 'xvfvev',\n 'xytitd',\n 'xz9qq2',\n 'y02km0',\n 'y0fizf',\n 'y0wmyr',\n 'y19t9e',\n 'y1r2bo',\n 'y2mbzc',\n 'y83i87',\n 'y8l5rc',\n 'y8z1yr',\n 'y9goeq',\n 'yab5nb',\n 'ybz8d7',\n 'ycszxo',\n 'yfoyhd',\n 'ygke9l',\n 'yh2vv0',\n 'yhgdu1',\n 'yk7ilk',\n 'ym19dx',\n 'ymlcfe',\n 'ymvhze',\n 'yn2irc',\n 'ynlbt6',\n 'yns5re',\n 'yo71q9',\n 'ypopeq',\n 'yqlbf7',\n 'yr3im1',\n 'yrzgo8',\n 'ysgkjg',\n 'yt9cf6',\n 'ytjs2s',\n 'ytttbp',\n 'yu41iq',\n 'yugsit',\n 'ywiv0k',\n 'ywvpen',\n 'yxhlpc',\n 'yxt6t9',\n 'yy9c8j',\n 'z067ks',\n 'z1ije6',\n 'z1vq39',\n 'z2dgvl',\n 'z4rzpq',\n 'z4u1xz',\n 'z6gu0e',\n 'z6kwo6',\n 'z6ypt0',\n 'z7fn51',\n 'z7heou',\n 'z8f6ex',\n 'z8tmwj',\n 'za5a21',\n 'zawc2b',\n 'zb5w7e',\n 'zbn64p',\n 'zbvyyg',\n 'zbymej',\n 'zcuwn3',\n 'ze8wp5',\n 'ze9wml',\n 'zg1c7f',\n 'zhulkb',\n 'zitlo7',\n 'zk1dkz',\n 'zlfjr6',\n 'zlt6qz',\n 'zngm4y',\n 'znqjpa',\n 'zo81z2',\n 'zp0hnk',\n 'zp68ea',\n 'zp99sa',\n 'zqccx0',\n 'zqyw7y',\n 'zrkhhb',\n 'ztia01',\n 'zu01nq',\n 'zubhcc',\n 'zup562',\n 'zuzmss',\n 'zvdglz',\n 'zy7e2q',\n 'zyscw8',\n 'zz2jkp']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 656 ms\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "extant = [os.path.basename(item.replace('\\n', '').split('.')[0]) for item in file_system.ls('data/image/thumbnail')]\n",
    "display(extant)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T22:17:00.538339400Z",
     "start_time": "2023-05-12T22:16:58.899876900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'Thumbnail created for zsv66h'"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating thumbnails:  28%|‚ñà‚ñà‚ñä       | 10341/37031 [1:37:25<3:21:42,  2.21it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for elem in tqdm(curated_df.id.values, total=len(curated_df.id.values), desc='Creating thumbnails'):\n",
    "\tcreate_thumbnail(elem, curated_df, crops, extant)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
